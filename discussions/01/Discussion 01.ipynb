{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Discussion 1\n",
    "\n",
    "### Due Saturday April 3, 11:59 PM\n",
    "\n",
    "**Discussions will be due by the end of the day on Saturday**\n",
    "\n",
    "* Lecture Review: models and the data science life-cycle.\n",
    "* Overview: How to work on homework.\n",
    "* Tutorial: `numpy` review and an example HW problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Lecture Review\n",
    "\n",
    "The terminology of modeling:\n",
    "* A **data generating process (DGP)** is the real-world phenomenon under consideration.\n",
    "* The **true (probability) model** is a mathematical representation of the random phenomenon that generates any representative observations.\n",
    "* The **observations** are data representing the data generating process.\n",
    "* A **(fit) statistical model** of the data is the best approximation of the data generating process under the probability model.\n",
    "\n",
    "The data science life-cycle:\n",
    "* Researching domain\n",
    "* Questions and hypotheses\n",
    "* Finding and cleaning data\n",
    "* Data modeling\n",
    "* Predictions and Inference\n",
    "* Decisions\n",
    "\n",
    "Where does each term describing the modeling process fit into the data science life-cycle?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Researching domain tells us what we care about and how relevant data is generated, allowing us to formulate questions and hypotheses as well as identify and clean data sets. Questions and hypotheses can lead to us finding and cleaning even more data, as this is the step where we narrow the scope of what we want to know, the problem we're looking to solve, and the metrics we will use for measuring. Finding and cleaning the data tells us what data exists and whether or not we need to collect our own data, but it also helps us understand how well data sets represent the domain we're interested in. Next, we can proceed to data modeling, where we identify biases or anomalies in the data, simplify the data for use in predictions and inference, and use data-informed assumptions to draw conclusions. Lastly, we use these models to tell stories and answer our questions by predicting and inferring."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example:** Suppose you want to predict the outcome of the next presidential election.\n",
    "1. What is the DGP?\n",
    "2. What observations might you collect? Are they representative of the DGP?\n",
    "3. What measurements do you care about? (i.e. what do your observations look like?)\n",
    "4. What is the probability model? what statistical model might you use?\n",
    "5. How might you assess the quality of your fit model?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "1. We're considering the outcome of the next presidential election, or in other words, which candidate is most likely going to win the most electoral votes. The population we're seeking to sample from would be the US electorate.\n",
    "2. Observations we can gather include poll information on the general public's political affiliation on a state-by-state level by aggregating from public online polls. Census data might also be useful to predict election results if we're interested in using demographic information as proxy measures or if we want to conduct PCA to predict political ideology. Both of these are very representative of the DGP.\n",
    "3. Each observation would represent either a household or individual, depending on whether it's information gathered from a poll on the individual level or household information gathered from the census.\n",
    "4. We might want to rely on traditional election forecasting models that use time-series data, demographic, or biographical data. Alternatively, we can use artificial neural networks and support vector regression models based on a select few datapoints from aggregating poll data.\n",
    "5. We would test it on poll data from previous elections  and run many iterations comparing predicted results against actual results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**: Suppose we want to understand the pay disparity between men and women among city of SD employees.\n",
    "1. What is the DGP?\n",
    "2. Does the dataset in lecture adequately represent the DGP?\n",
    "3. What is the probability model?\n",
    "4. Address the questions above with the applicability to other years and cities?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "1. The DGP in this example would be the wage gap between men and women in San Diego. The population we're seeking to sample from would be the San Diego workforce.\n",
    "2. Yes, it contains thousands of observations of SD employees, including both men and women.\n",
    "3. We would likely want to conduct a Student T-Test for Difference of Means here to determine if there's a significant difference between the wages that men and women earn in SD.\n",
    "4. If there is a similarly formatted dataset for other cities in other years, the same answers apply. However, if the datasets are too small or if they don't contain enough information regarding employees, the same answers do not hold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Overview: working on assignments\n",
    "\n",
    "The class assignments are available on the class git repository; they consist of a notebook with the problems statements, starter code in a `.py` file, and any required supplementary files (e.g. data). After pulling the HW material, you will develop your solutions using a combination of jupyter notebooks and your favorite IDE (e.g. sublime text, or the jupyterhub server). Once finished, you will submit your assignment to gradescope.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Obtaining course materials (assignments)\n",
    "\n",
    "Git is a version control system that is used to with the development of the course materials. For an introduction to using git in the course, see this [tutorial](https://drive.google.com/open?id=1m6mXfhjFInHPeJyaHdAwfiakcFYh73HC8TeAB9E9Xeo) and this hands-on [tutorial](https://docs.google.com/document/d/1E2Zg0pC8S3cyT564jug6rqAhSNraR_7Yy_4AnvHaGu4/edit?usp=sharing). To use git on a Mac, you will need to open the terminal; on Windows, you should download [git-bash](https://gitforwindows.org/).\n",
    "\n",
    "The course materials are stored in a git repository on *github* (a git server) -- you can view it in a browser [here](https://github.com/ucsd-ets/dsc80-sp19). To obtain the course files, follow the directions in the tutorial above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The notebook / IDE balance\n",
    "\n",
    "Now that your assignment is on your computer, you are ready to work. You will be using two different tools to develop the code and create the analyses that the assignments require of you. Generally, these are:\n",
    "1. Jupyter notebooks contains the problems statements themselves; they also provide a place to test out code, understand data, and produce reports/summaries of conclusions.\n",
    "2. An IDE for developing re-usable and testable python code. Abstracting your notebook code into python library code avoids common mistakes in notoriously error prone notebook environments. Luckily, once a function is in your `.py` file, you can still import/use it in a notebook!\n",
    "\n",
    "Both of these environments are essential in the data scientist toolkit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checking your work\n",
    "\n",
    "An effective environment for testing and understanding your work is essential to success in the class. The notebook and the IDE play different roles in checking your work.\n",
    "\n",
    "* The notebook provides a place to understand the output of your function and test it against your intuition and understanding of what the correct output should be. When working with data, you should always check the correctness of your work using your understanding of that data (i.e. is my conclusion reasonable given what I know about the data?). This is typically the ultimate goal for a problem, so you should *always* interpret your answer on the data in a notebook.\n",
    "\n",
    "* Abstracting your code to library functions/classes in a `.py` file encourages using software development best-practices in your data processing and analyses. While expressive, notebooks are error-prone, manual, and hard to debug. Moving useful code to a `.py` file makes your code more clear, encourages code reuse, and makes debugging easier. Once you have moved any work from your notebook to a `.py` file, you should check the correctness of your work in two ways:\n",
    "    - Run the doctests. The doctests ensure your code *meets the contract* specified in the question (or by you, in your own projects). That is, is your code expecting the correct inputs and outputs? **Doctests do not check more than if your code is acting on the correct types**.\n",
    "    - Import your function into the notebook and test it on data as above. Use your understanding of the data to assess the correctness of your code!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HW submission\n",
    "\n",
    "Once you have finished the assignment, log into Gradescope and submit the `.py` file to the appropriate assignment. \n",
    "* Upon submission, the autograder will run the doctests and make visible if they tests passed or not. These are worth *zero* points; the purpose is to check that the autograder environment is consistent with the environment on which you developed your HW.\n",
    "* The results of the \"correctness tests\" that you will be ultimately graded on will not be visible until after the due date.\n",
    "* The autograder will tell you if your code failed to run, though generally will not tell you why. The most common reasons are listed below.\n",
    "    - **Timeout**: the autograder *will* tell you if your code failed to run after 20 minutes. If this occurs, you should try to isolate which problem is causing the timeout and either fix it or comment it out!\n",
    "    - **Syntax Errors**: Any syntax errors (e.g. bad code indentation) will cause gradescope to fail (giving a 0 on the assignment). Always double check your code passes doctests *on the commandline* (just as the autograder runs it). Further, pulling your code (from github) onto DataHub and running the tests there is a good debugging technique, as the environment is very similar to gradescope. \n",
    "    - **OOM (out of memory)**: The autograder runs a 1GB server, which is smaller than your computer. Assignments should never require more memory than this; you should think about how to simplify your code!\n",
    "\n",
    "If the problem persists, ask course staff why the autograder is failing.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A remark on DataHub\n",
    "\n",
    "UCSD Educational Technology Services has made servers available for use at [DataHub](datahub.ucsd.edu). Once logged in, you have not only a jupyter notebook server running, but an entire unix environment. To make best use of this environment, once logged in, replace the `/tree` in the URL with `/lab` and you can use the JupyterLab IDE/notebook environment. Here, you can use (1) jupyter notebooks, (2) terminals, and (3) a simple text editor for editing python files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tutorial: `numpy` review as a HW problem\n",
    "\n",
    "Work on this tutorial like an assignment. **Complete the questions 1 and 8, and turn them into gradescope by midnight on Saturday**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is this? (discuss imports)\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import disc01 as disc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is this?\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a review of working with Numpy arrays, see the [arrays chapter]https://www.inferentialthinking.com/chapters/05/1/Arrays.html of Inferential Thinking (DSC10). The most relevant concepts are:\n",
    "* element-wise array operations, that avoid loops ('vectorization')\n",
    "* the functions and methods for performing array arithmetic (see the tables in the page referenced above)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 1** Write a function that takes in a file-path that points to a data file like `restaurants.csv` and returns an array of values of restaurant bills."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Notes*: Where is the file? What values? Look at the starter code documentation in `disc.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data\\\\restaurant.csv'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'restaurant.csv')\n",
    "fp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data2array(filepath):\n",
    "    \"\"\"\n",
    "    data2array takes in the filepath of a \n",
    "    data file like `restaurant.csv` in \n",
    "    data directory, and returns a 1d array\n",
    "    of data.\n",
    "\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'restaurant.csv')\n",
    "    >>> arr = data2array(fp)\n",
    "    >>> isinstance(arr, np.ndarray)\n",
    "    True\n",
    "    >>> arr.dtype == np.dtype('float64')\n",
    "    True\n",
    "    >>> arr.shape[0]\n",
    "    100000\n",
    "    \"\"\"\n",
    "    fh = open(filepath)\n",
    "    fh.readline()\n",
    "    \n",
    "    data = [float(line.strip()) for line in fh]\n",
    "    \n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "100000\n"
     ]
    }
   ],
   "source": [
    "arr = disc.data2array(fp)\n",
    "print(isinstance(arr, np.ndarray))\n",
    "print(arr.dtype == np.dtype('float64'))\n",
    "print(arr.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2:** How many restaurant bills are there?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3:** Suppose everyone leaves an 18% tip. Create an array of tip amounts. What is the total amount of tips in the array?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.0366, 3.1338, 1.8324, ..., 2.8962, 2.7504, 5.3496])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tips = arr * 0.18\n",
    "tips"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 4:** What is the average/median/min/max restaurant bills? Give answer in an array, in the order listed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.9644172, 13.09     ,  3.       , 77.91     ])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centers = np.array([np.mean(arr), np.median(arr), np.min(arr), np.max(arr)])\n",
    "centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5:** How many restaurant bills are greater than $15?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42347"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grt_than_15 = arr[arr>15].size\n",
    "grt_than_15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 6:** How much total money for the restaurant is there? What proportion of that comes from bills less than $5?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1496441.7200000002"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total = np.sum(arr)\n",
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6654181560776051"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "proportion = np.sum(arr[arr>15]) / total\n",
    "proportion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7:** What proportion of bills have at least one other bill within $0.05 of the given amount?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-66-7014c12466b4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m==\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m             \u001b[1;32mcontinue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mchecklow\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0marr\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mcheckhigh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m             \u001b[0mcount\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[1;33m/\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# count = 0\n",
    "# for i in range(len(arr)):\n",
    "#     check = arr[i]\n",
    "#     checklow = check - 0.05\n",
    "#     checkhigh = check + 0.05\n",
    "#     for j in range(len(arr)):\n",
    "#         if i==j:\n",
    "#             continue\n",
    "#         elif arr[j] >= checklow or arr[j] <= checkhigh:\n",
    "#             count += 1\n",
    "# print(count/len(arr))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8:** What proportion of restaurant bills end in 9?\n",
    "\n",
    "*Hint:* Use the remainder function `%`, but be careful of floating point operations! (What sort of data types have remainders?)\n",
    "\n",
    "Create a function `ends_in_9` that takes in an array of dollar amounts (like the output of Question 1) and returns the proportion of values that end in 9 in the hundredths place."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def ends_in_9(arr):\n",
    "    \"\"\"\n",
    "    ends_in_9 takes in an array of dollar amounts \n",
    "    and returns the proprtion of values that end \n",
    "    in 9 in the hundredths place.\n",
    "\n",
    "    :Example:\n",
    "    >>> arr = np.array([23.04, 45.00, 0.50, 0.09])\n",
    "    >>> out = ends_in_9(arr)\n",
    "    >>> 0 <= out <= 1\n",
    "    True\n",
    "    \"\"\"\n",
    "    rounded = np.round((arr * 100).astype(int))\n",
    "    return np.count_nonzero(rounded % 100 % 10 == 9) / len(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ends_in_9(arr):\n",
    "    \"\"\"\n",
    "    ends_in_9 takes in an array of dollar amounts \n",
    "    and returns the proprtion of values that end \n",
    "    in 9 in the hundredths place.\n",
    "\n",
    "    :Example:\n",
    "    >>> arr = np.array([23.04, 45.00, 0.50, 0.09])\n",
    "    >>> out = ends_in_9(arr)\n",
    "    >>> 0 <= out <= 1\n",
    "    True\n",
    "    \"\"\"\n",
    "    rounded = (arr * 100)\n",
    "    return np.count_nonzero(rounded % 100 % 10 == 9) / len(rounded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1019"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ends_in_9(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "test = np.array([23.04, 45.00, 0.50, 0.09])\n",
    "out = ends_in_9(test)\n",
    "print(0 <= out <= 1)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0.25\n"
     ]
    }
   ],
   "source": [
    "test = np.array([23.04, 45.00, 0.50, 0.595])\n",
    "out = ends_in_9(test)\n",
    "print(0 <= out <= 1)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
