{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC 80: Lab 06\n",
    "\n",
    "### Due Date: Tuesday May 11th, 11:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding work will be developed in an accompanying `lab*.py` file, that will be imported into the current notebook.\n",
    "\n",
    "Labs and programming assignments will be graded in (at most) two ways:\n",
    "1. The functions and classes in the accompanying python file will be tested (a la DSC 20),\n",
    "2. The notebook will be graded (for graphs and free response questions).\n",
    "\n",
    "**Do not change the function names in the `*.py` file**\n",
    "- The functions in the `*.py` file are how your assignment is graded, and they are graded by their name. The dictionary at the end of the file (`GRADED FUNCTIONS`) contains the \"grading list\". The final function in the file allows your doctests to check that all the necessary functions exist.\n",
    "- If you changed something you weren't supposed to, just use git to revert!\n",
    "\n",
    "**Tips for working in the Notebook**:\n",
    "- The notebooks serve to present you the questions and give you a place to present your results for later review.\n",
    "- The notebook on *lab assignments* are not graded (only the `.py` file).\n",
    "- Notebooks for PAs will serve as a final report for the assignment, and contain conclusions and answers to open ended questions that are graded.\n",
    "- The notebook serves as a nice environment for 'pre-development' and experimentation before designing your function in your `.py` file.\n",
    "\n",
    "**Tips for developing in the .py file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are encouraged to write your own additional functions to solve the lab! \n",
    "    - Developing in python usually consists of larger files, with many short functions.\n",
    "    - You may write your other functions in an additional `.py` file that you import in `lab**.py` (much like we do in the notebook).\n",
    "- Always document your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing code from `lab**.py`\n",
    "\n",
    "* We import our `.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab**.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab**.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab**.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab**` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lab06 as lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import bs4\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic HTML tags practice\n",
    "\n",
    "**Question 1**\n",
    "\n",
    "Create a very basic `html` file that satisfies the following properties:\n",
    "\n",
    "1. Has `<head>` and `<body>` tags.\n",
    "2. Has a title\n",
    "3. Inside the body tags:\n",
    "    * At least two headers\n",
    "    * At least three images:\n",
    "        * At least one image must be a local file;\n",
    "        * At least one image must be linked to online source; \n",
    "        * At least one image has to have default text when it cannot be displayed.\n",
    "    * At least three references (hyperlinks) to different web pages;\n",
    "    * At least one table with two columns.\n",
    "    \n",
    "        \n",
    "   \n",
    "4. Save your work as `lab06_1.html` in the same directory as `lab06.py`, make sure it loads in the browser and do not forget to submit it.\n",
    "5. **Do not forget to submit all data files needed to display your page.**\n",
    "\n",
    "**Note:** You can toy with (basic) HTML in the cells of a notebook, using either a \"markdown cell\" or by using the `IPython.display.HTML` function. However, be sure to open your saved file in a browser to be sure the page displays properly!\n",
    "\n",
    "**Note:** If you work within Jupyter Notebook, you can later copy your text into a text editor and save it with the .html extension."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question1():\n",
    "    \"\"\"\n",
    "    NOTE: You do NOT need to do anything with this function.\n",
    "\n",
    "    The function for this question makes sure you\n",
    "    have a correctly named HTML file in the right\n",
    "    place. Note: This does NOT check if the supplementary files\n",
    "    needed for your page are there!\n",
    "\n",
    "    >>> os.path.exists('lab06_1.html')\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    # Don't change this function body!\n",
    "    # No python required; create the HTML file.\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.path.exists('lab06_1.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "\t<head>\n",
       "\t\t<title> Title 1 </title>\n",
       "\t<head>\n",
       "\n",
       "\t<body>\n",
       "\t\t<h1> Header 1 </h1>\n",
       "\t<img src=\"jujutsu2.png\", alt=\"jujutsu kaisen main character\", title=\"anime guy\">\t\n",
       "\t\t<h1> Header 2 </h1>\n",
       "\t\t\t<img src=\"https://img.wattpad.com/9573e4df3775e6e7e808df7d9b7e054c18f76b98/68747470733a2f2f73332e616d617a6f6e6177732e636f6d2f776174747061642d6d656469612d736572766963652f53746f7279496d6167652f6f735f5045424e796d69583445413d3d2d313033323038343832342e313636373338383138396530323435643335393733393436303430372e6a7067?s=fit&w=720&h=720\">\n",
       "\t\n",
       "\t\t\t<br> <a href=\"https://eldridgejm.github.io/dsc80-sp21/\"> I love data science! </a> <br>\n",
       "\t\n",
       "\t\t\t<a href=\"https://datascience.ucsd.edu/\"> I love the Halicioglu Institute! </a> <br>\n",
       "\t\n",
       "\t\t\t<a href=\"https://ucsd.edu/\"> I love UCSD! </a> <br>\n",
       "\t<table>\n",
       "  \t\t<tr>\n",
       "    \t\t\t<th>First Name</th>\n",
       "    \t\t\t<th>Last Name</th>\n",
       " \t\t</tr>\n",
       "  \t\t<tr>\n",
       "    \t\t\t<td>Joe</td>\n",
       "    \t\t\t<td>Mama</td>\n",
       "  \t\t</tr>\n",
       "  \t\t<tr>\n",
       "    \t\t\t<td>John</td>\n",
       "\t\t\t<td>Deer</td>\n",
       " \t\t</tr>\n",
       "\t\t<tr>\n",
       "    \t\t\t<td>Jane</td>\n",
       "\t\t\t<td>Doe</td>\n",
       " \t\t </tr>\n",
       "\t</table>\n",
       "\t</body>\n",
       "</html>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "IPython.display.HTML('lab06_1.html')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping an Online Bookstore\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 2**\n",
    "\n",
    "Browse through the following fake on-line bookstore: http://books.toscrape.com/. This website is meant for toying with scraping.\n",
    "\n",
    "Scrape the website, collecting data on all books that have **at least a four-star rating**, with a price **under £50** and belong to the book categories you want. You should collect the data in a dataframe as below (if you get an encoding error on your prices columns, like you see in the table below, don't worry about it):\n",
    "<img src=\"data/bookdata.png\">\n",
    "\n",
    "\n",
    "Do this using the following steps:\n",
    "1. Create a function `extract_book_links` that takes in the content of a book-listing page (a string of html), and returns a list of urls of book-detail pages that satisfy the requirements on \"*at least* a four-star rating, and prices are *under* £50\". \n",
    "\n",
    "\n",
    "*Note:* Your function should take under 180 seconds to run through the entire bookstore.\n",
    "\n",
    "*Note:* Don't worry about type casting (ie changing number of reviews to an int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'products.html')\n",
    "text = open(fp, encoding='utf-8').read()\n",
    "#text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from bs4 import BeautifulSoup\n",
    "books = bs4.BeautifulSoup(text).find_all('article',attrs={'class':'product_pod'})\n",
    "#print(soup.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'£52.33'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#soup#.find('div')\n",
    "books[0].find('p',attrs={'class':'price_color'}).text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_book_links(text):\n",
    "    \"\"\"\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'products.html')\n",
    "    >>> out = extract_book_links(open(fp, encoding='utf-8').read())\n",
    "    >>> url = 'scarlet-the-lunar-chronicles-2_218/index.html'\n",
    "    >>> out[1] == url\n",
    "    True\n",
    "    \"\"\"\n",
    "    ratings = ['four','five']\n",
    "    urls = []\n",
    "    books = bs4.BeautifulSoup(text,features=\"lxml\").find_all('article',attrs={'class':'product_pod'})\n",
    "    for book in books:\n",
    "        if (book.find('p').attrs['class'][1].lower() in ratings) and (float(book.find('p',attrs={'class':'price_color'}).text.strip('£').strip('Â').strip('£')) < 50):\n",
    "            urls.append(book.find('a').attrs['href'].replace('catalogue/',''))\n",
    "    return urls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['seven-brief-lessons-on-physics_219/index.html',\n",
       " 'scarlet-the-lunar-chronicles-2_218/index.html',\n",
       " 'saga-volume-3-saga-collected-editions-3_216/index.html',\n",
       " 'running-with-scissors_215/index.html',\n",
       " 'rise-of-the-rocket-girls-the-women-who-propelled-us-from-missiles-to-the-moon-to-mars_213/index.html',\n",
       " 'ready-player-one_209/index.html']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'products.html')\n",
    "out = extract_book_links(open(fp, encoding='utf-8').read())\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "url = 'scarlet-the-lunar-chronicles-2_218/index.html'\n",
    "out[1] == url"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Create a function `get_product_info` that takes in the content of a book-detail page (a string of html), a variable `categories` that is a list of book categories you want. If this input book is in the categories you want, returns a dictionary corresponding to a row in the dataframe in the image above (where the keys are the column names and the values are the row values); else, skip this book since this is not the book you want (ie. return None)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tr>\n",
       " <th>UPC</th><td>a492f49a3e2b6a71</td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <th>Product Type</th><td>Books</td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <th>Price (excl. tax)</th><td>£38.00</td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <th>Price (incl. tax)</th><td>£38.00</td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <th>Tax</th><td>£0.00</td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <th>Availability</th>\n",
       " <td>In stock (1 available)</td>\n",
       " </tr>,\n",
       " <tr>\n",
       " <th>Number of reviews</th>\n",
       " <td>0</td>\n",
       " </tr>]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'Frankenstein.html')\n",
    "categories = ['Default']\n",
    "\n",
    "book = bs4.BeautifulSoup(open(fp, encoding='utf-8').read())\n",
    "cat = book.find('ul',attrs={'class':'breadcrumb'}).find_all('a')[2].text\n",
    "table_entries = book.find('table',attrs={'class':'table table-striped'}).find_all('tr')\n",
    "#get_entry = lambda x: table_entries[x].find('tr').text\n",
    "table_entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Mary Shelley began writing Frankenstein when she was only eighteen. At once a Gothic thriller, a passionate romance, and a cautionary tale about the dangers of science, Frankenstein tells the story of committed science student Victor Frankenstein. Obsessed with discovering the cause of generation and life and bestowing animation upon lifeless matter, Frankenstein assembles Mary Shelley began writing Frankenstein when she was only eighteen. At once a Gothic thriller, a passionate romance, and a cautionary tale about the dangers of science, Frankenstein tells the story of committed science student Victor Frankenstein. Obsessed with discovering the cause of generation and life and bestowing animation upon lifeless matter, Frankenstein assembles a human being from stolen body parts but; upon bringing it to life, he recoils in horror at the creature's hideousness. Tormented by isolation and loneliness, the once-innocent creature turns to evil and unleashes a campaign of murderous revenge against his creator, Frankenstein.Frankenstein, an instant bestseller and an important ancestor of both the horror and science fiction genres, not only tells a terrifying story, but also raises profound, disturbing questions about the very nature of life and the place of humankind within the cosmos: What does it mean to be human? What responsibilities do we have to each other? How far can we go in tampering with Nature? In our age, filled with news of organ donation genetic engineering, and bio-terrorism, these questions are more relevant than ever. ...more\""
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book.find('article', attrs={'class':'product_page'}).find_all('p')[3].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "main = book.find('div', attrs={'class':'col-sm-6 product_main'})\n",
    "#main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['star-rating', 'Two']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.find_all('p')[2].attrs['class']#[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Frankenstein'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "main.find('h1').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#book"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Default'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "book.find('ul',attrs={'class':'breadcrumb'}).find_all('a')[2].text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_product_info(text, categories):\n",
    "    \"\"\"\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'Frankenstein.html')\n",
    "    >>> out = get_product_info(open(fp, encoding='utf-8').read(), ['Default'])\n",
    "    >>> isinstance(out, dict)\n",
    "    True\n",
    "    >>> 'Category' in out.keys()\n",
    "    True\n",
    "    >>> out['Rating']\n",
    "    'Two'\n",
    "    \"\"\"\n",
    "    \n",
    "    book = bs4.BeautifulSoup(text,features=\"lxml\")\n",
    "    cat = book.find('ul',attrs={'class':'breadcrumb'}).find_all('a')[2].text\n",
    "    \n",
    "    if cat not in categories:\n",
    "        return None\n",
    "    else:\n",
    "        table_entries = book.find('table',attrs={'class':'table table-striped'}).find_all('tr')\n",
    "        entries = []\n",
    "        for x in table_entries:\n",
    "            cut1 = str(x).find('<td>') + 4\n",
    "            cut2= str(x).find('</td>')\n",
    "            entries.append(str(x)[cut1:cut2])\n",
    "        \n",
    "        description = book.find('article', attrs={'class':'product_page'}).find_all('p')[3].text\n",
    "\n",
    "        main = book.find('div', attrs={'class':'col-sm-6 product_main'})\n",
    "        title = main.find('h1').text\n",
    "        rating = main.find_all('p')[2].attrs['class'][1]\n",
    "        \n",
    "        df_dict = {'Availability':entries[5], 'Category':cat, 'Description':description, \n",
    "                   'Number of reviews':entries[6], 'Price (excl. tax)':entries[2], 'Price (incl. tax)':entries[3],\n",
    "                   'Product Type':entries[1], 'Rating':rating, 'Tax':entries[4], 'Title':title, 'UPC':entries[0]}\n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Availability': 'In stock (1 available)',\n",
       " 'Category': 'Default',\n",
       " 'Description': \"Mary Shelley began writing Frankenstein when she was only eighteen. At once a Gothic thriller, a passionate romance, and a cautionary tale about the dangers of science, Frankenstein tells the story of committed science student Victor Frankenstein. Obsessed with discovering the cause of generation and life and bestowing animation upon lifeless matter, Frankenstein assembles Mary Shelley began writing Frankenstein when she was only eighteen. At once a Gothic thriller, a passionate romance, and a cautionary tale about the dangers of science, Frankenstein tells the story of committed science student Victor Frankenstein. Obsessed with discovering the cause of generation and life and bestowing animation upon lifeless matter, Frankenstein assembles a human being from stolen body parts but; upon bringing it to life, he recoils in horror at the creature's hideousness. Tormented by isolation and loneliness, the once-innocent creature turns to evil and unleashes a campaign of murderous revenge against his creator, Frankenstein.Frankenstein, an instant bestseller and an important ancestor of both the horror and science fiction genres, not only tells a terrifying story, but also raises profound, disturbing questions about the very nature of life and the place of humankind within the cosmos: What does it mean to be human? What responsibilities do we have to each other? How far can we go in tampering with Nature? In our age, filled with news of organ donation genetic engineering, and bio-terrorism, these questions are more relevant than ever. ...more\",\n",
       " 'Number of Reviews': '0',\n",
       " 'Price (excl. tax)': '£38.00',\n",
       " 'Price (incl. tax)': '£38.00',\n",
       " 'Product Type': 'Books',\n",
       " 'Rating': 'Two',\n",
       " 'Tax': '£0.00',\n",
       " 'Title': 'Frankenstein',\n",
       " 'UPC': 'a492f49a3e2b6a71'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'Frankenstein.html')\n",
    "out = get_product_info(open(fp, encoding='utf-8').read(), ['Default'])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(out, dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Category' in out.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Two'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['Rating']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Create a function `scrape_books` of a single variable `k` that scrapes the first `k` pages of the bookstore (as determined by starting at the url above and clicking on the 'next' button),a variable `categories` that is a list of book categories you want, and returns a dataframe of books as the picture above. (Note: make sure the books returned satisfy the requirements set in part 1 about rating and price)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_books(k, categories):\n",
    "    \"\"\"\n",
    "    :param k: number of book-listing pages to scrape.\n",
    "    :returns: a dataframe of information on (certain) books\n",
    "    on the k pages (as described in the question).\n",
    "\n",
    "    :Example:\n",
    "    >>> out = scrape_books(1, ['Mystery'])\n",
    "    >>> out.shape\n",
    "    (1, 11)\n",
    "    >>> out['Rating'][0] == 'Four'\n",
    "    True\n",
    "    >>> out['Title'][0] == 'Sharp Objects'\n",
    "    True\n",
    "    \"\"\"\n",
    "    pages = []\n",
    "    df = pd.DataFrame()\n",
    "    for i in range (1,k+1):\n",
    "        pages.append('http://books.toscrape.com/catalogue/page-{}.html'.format(i))\n",
    "    for fp in pages:\n",
    "        page = requests.get(fp).text\n",
    "        books = extract_book_links(page)\n",
    "        for book in books:\n",
    "            link = 'http://books.toscrape.com/catalogue/' + book\n",
    "            book_page = requests.get(link).text\n",
    "            book_dict = get_product_info(book_page,categories)\n",
    "            if book_dict is not None:\n",
    "                book_df = pd.DataFrame([book_dict])\n",
    "                df = df.append(book_df)\n",
    "    return df.reindex(sorted(df.columns),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Availability</th>\n",
       "      <th>Category</th>\n",
       "      <th>Description</th>\n",
       "      <th>Number of Reviews</th>\n",
       "      <th>Price (excl. tax)</th>\n",
       "      <th>Price (incl. tax)</th>\n",
       "      <th>Product Type</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Tax</th>\n",
       "      <th>Title</th>\n",
       "      <th>UPC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In stock (20 available)</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>WICKED above her hipbone, GIRL across her hear...</td>\n",
       "      <td>0</td>\n",
       "      <td>Â£47.82</td>\n",
       "      <td>Â£47.82</td>\n",
       "      <td>Books</td>\n",
       "      <td>Four</td>\n",
       "      <td>Â£0.00</td>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>e00eb4fd7b871a48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Availability Category  \\\n",
       "0  In stock (20 available)  Mystery   \n",
       "\n",
       "                                         Description Number of Reviews  \\\n",
       "0  WICKED above her hipbone, GIRL across her hear...                 0   \n",
       "\n",
       "  Price (excl. tax) Price (incl. tax) Product Type Rating     Tax  \\\n",
       "0           Â£47.82           Â£47.82        Books   Four  Â£0.00   \n",
       "\n",
       "           Title               UPC  \n",
       "0  Sharp Objects  e00eb4fd7b871a48  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = scrape_books(1, ['Mystery'])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Availability</th>\n",
       "      <th>Category</th>\n",
       "      <th>Description</th>\n",
       "      <th>Number of Reviews</th>\n",
       "      <th>Price (excl. tax)</th>\n",
       "      <th>Price (incl. tax)</th>\n",
       "      <th>Product Type</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Tax</th>\n",
       "      <th>Title</th>\n",
       "      <th>UPC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>In stock (20 available)</td>\n",
       "      <td>Mystery</td>\n",
       "      <td>WICKED above her hipbone, GIRL across her hear...</td>\n",
       "      <td>0</td>\n",
       "      <td>Â£47.82</td>\n",
       "      <td>Â£47.82</td>\n",
       "      <td>Books</td>\n",
       "      <td>Four</td>\n",
       "      <td>Â£0.00</td>\n",
       "      <td>Sharp Objects</td>\n",
       "      <td>e00eb4fd7b871a48</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Availability Category  \\\n",
       "0  In stock (20 available)  Mystery   \n",
       "\n",
       "                                         Description Number of Reviews  \\\n",
       "0  WICKED above her hipbone, GIRL across her hear...                 0   \n",
       "\n",
       "  Price (excl. tax) Price (incl. tax) Product Type Rating     Tax  \\\n",
       "0           Â£47.82           Â£47.82        Books   Four  Â£0.00   \n",
       "\n",
       "           Title               UPC  \n",
       "0  Sharp Objects  e00eb4fd7b871a48  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = scrape_books2(1, ['Mystery'])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 11)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['Rating'][0] == 'Four'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out['Title'][0] == 'Sharp Objects'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# API Requests\n",
    "**Question 3**\n",
    "\n",
    "You trade stocks as a hobby. As an avid pandas coder, you figured it is best to calculate some statistics by pulling data from a public API (https://financialmodelingprep.com/developer/docs/#Stock-Historical-Price). Specifically, \"Historical price with change and volume interval\".\n",
    "\n",
    "Some definitions (these are the ones you need to know):\n",
    "- open: The opening price of a stock at the beginning of a trading day\n",
    "- close: The closing price of a stock at the end of a trading day\n",
    "- volume: The total number of shares being traded in a day\n",
    "- percent change: difference in price with respect to the original price (in percentages)\n",
    "\n",
    "\n",
    "1. Create a function `stock_history` which takes in the stock code (`ticker`) as a string, `year` and `month` as integers, and return a dataframe which has the price history for that stock in that month (include all columns).\n",
    "\n",
    "2. Create a function `stock_stats` that takes in the output dataframe from `stock_history` and output the stock price change as a percentage and a rough total transaction volume **in billion dollars** for that month. Assume that on average, shares are traded at the midpoint price of high and low for that day. Return these two values as a tuple in a readable format: reserve 2 decimal points for both values and add a plus or minus sign at the front of the percent change. \n",
    "$$ \\text{Total Transaction Volume (in dollars)} = \\text{Volume (number of shares traded)} \\times \\text{Price} $$\n",
    "\n",
    "*Example*: If \\\\$BYND opens at \\\\$80 and closes at \\\\$120 with a volume of 1 million, its percent change for the day is $(\\$120-\\$80) \\div \\$80 = +50.00\\%$. And the estimated total transaction volume is: $(\\$80+\\$120) / 2 \\times 10^6 = 0.10\\text{B}$.\n",
    "\n",
    "\n",
    "Hint: [pd.date_range](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.date_range.html), \n",
    "\n",
    "*Note:* Make sure you read the API documentation if you get stuck!\n",
    "\n",
    "*Note 2:* In order to make successful requests, you will need an API key. In order to get one, you will need to sign up to the website. Once signed up, you can use the API key that comes with the free plan. It has a limit of 250 requests per day, which should be more than enough. In the code below, replace `your_key` when making requests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stock_endpoint = 'https://financialmodelingprep.com/api/v3/historical-price-full/AAPL?apikey=fe8f70fbc0359ff10974537662eb687f'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#response = requests.get(\"https://financialmodelingprep.com/developer/docs/#Stock-Historical-Price\")\n",
    "#response = requests.get(stock_endpoint)\n",
    "#print(response.status_code)\n",
    "#print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#json_load = json.loads(response.content)\n",
    "#df = pd.json_normalize(json_load['historical'])\n",
    "#df['date'] = pd.to_datetime(df['date'])\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#start = datetime.datetime(2019, 6,1)\n",
    "#end = datetime.datetime(2019, 7,1)\n",
    "#date_range = pd.date_range(start,end)[:-1].to_pydatetime()\n",
    "#date_range"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df[df['date'].isin(date_range)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def stock_history(ticker, year, month):\n",
    "#     \"\"\"\n",
    "#     Given a stock code and month, return the stock price details for that month\n",
    "#     as a dataframe\n",
    "\n",
    "#     >>> history = stock_history('BYND', 2019, 6)\n",
    "#     >>> history.shape == (20, 13)\n",
    "#     True\n",
    "#     >>> history.label.iloc[-1]\n",
    "#     'June 03, 19'\n",
    "#     \"\"\"\n",
    "#     key = 'fe8f70fbc0359ff10974537662eb687f'\n",
    "#     stock_endpoint = 'https://financialmodelingprep.com/api/v3/historical-price-full/{}?apikey={}'.format(ticker,key)\n",
    "#     response = requests.get(stock_endpoint)\n",
    "    \n",
    "#     json_load = json.loads(response.content)\n",
    "#     pd.json_normalize(json_load['historical'])\n",
    "#     json_load = json.loads(response.content)\n",
    "    \n",
    "#     df = pd.json_normalize(json_load['historical'])\n",
    "#     df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "#     start = datetime.datetime(year, month, 1)\n",
    "#     #print(start)\n",
    "#     end = datetime.datetime(year, month+1, 1)\n",
    "#     #print(end)\n",
    "#     date_range = pd.date_range(start,end)[:-1].to_pydatetime()\n",
    "    \n",
    "#     return df[df['date'].isin(date_range)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_history(ticker, year, month):\n",
    "    \"\"\"\n",
    "    Given a stock code and month, return the stock price details for that month\n",
    "    as a dataframe\n",
    "\n",
    "    >>> history = stock_history('BYND', 2019, 6)\n",
    "    >>> history.shape == (20, 13)\n",
    "    True\n",
    "    >>> history.label.iloc[-1]\n",
    "    'June 03, 19'\n",
    "    \"\"\"\n",
    "    date_range = pd.date_range(start = f'{str(year)}-{str(month)}', end = f'{str(year)}-{str(int(month) + 1)}')[:-1]\n",
    "    key = 'fe8f70fbc0359ff10974537662eb687f'\n",
    "    stock_endpoint = f'https://financialmodelingprep.com/api/v3/historical-price-full/{ticker}?from={date_range[0].strftime(\"%Y-%m-%d\")}-1&to={date_range[-1].strftime(\"%Y-%m-%d\")}&apikey={key}'\n",
    "    response = requests.get(stock_endpoint).json()\n",
    "    stock_info = response['historical']\n",
    "    return pd.DataFrame(stock_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# history = stock_history('BYND', 2019, 6)\n",
    "# history.sort_values('date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.shape == (20, 13)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'June 03, 19'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.label.iloc[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'-10'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stock_stats(history):\n",
    "    \"\"\"\n",
    "    Given a stock's trade history, return the percent change and transactions\n",
    "    in billion dollars.\n",
    "\n",
    "    >>> history = stock_history('BYND', 2019, 6)\n",
    "    >>> stats = stock_stats(history)\n",
    "    >>> len(stats[0]), len(stats[1])\n",
    "    (7, 6)\n",
    "    >>> float(stats[0][1:-1]) > 30\n",
    "    True\n",
    "    >>> float(stats[1][:-1]) > 1\n",
    "    True\n",
    "    \"\"\"\n",
    "    df = history.sort_values('date')\n",
    "    \n",
    "    pc = (df.iloc[-1]['close'] - df.iloc[0]['open']) / df.iloc[0]['open'] * 100\n",
    "    if pc > 0:\n",
    "        pc = '+' + str(f\"{pc:.2f}\") + '%'\n",
    "    else:\n",
    "        pc = str(f\"{percent:.2f}\") + '%'\n",
    "    \n",
    "    ttv_series = df.apply(lambda row : (row.low + row.high) / 2 * row.volume, axis=1)\n",
    "    ttv = ttv_series.sum() / 1000000000\n",
    "    ttv = str(f\"{ttv:.2f}\") + 'B'\n",
    "    return pc,ttv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('+54.29%', '33.64B')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = stock_history('BYND', 2019, 6)\n",
    "stats = stock_stats(history)\n",
    "stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.2009893994459"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(stock_history('BYND', 2019, 6).iloc[0]['low'] + stock_history('BYND', 2019, 6).iloc[0]['high']) / 2 * stock_history('BYND', 2019, 6).iloc[0]['volume'] / 1000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33.63798630907855"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dummy = stock_history('BYND', 2019, 6)\n",
    "tv1 = dummy.apply(lambda row : (row.low + row.high) / 2 * row.volume / 1000000000, axis=1)#.sum() \n",
    "tv1.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dummy2 = stock_history('BYND', 2019, 6)\n",
    "#dummy2 = dummy2.assign(mid=(dummy2['high'] + dummy2['low'])/2,)\n",
    "#tv2 = (dummy2['mid']*dummy2['volume']) / 1000000000\n",
    "#tv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(tv1.sum())\n",
    "#print(tv2.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(stats[0]), len(stats[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(stats[0][1:-1]) > 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "float(stats[1][:-1]) > 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comment Threads\n",
    "\n",
    "**Question 4**\n",
    "\n",
    "As a hacker, you get your daily dose of tech news on [Hacker News](https://news.ycombinator.com/). The problem now is that you don't have internet access on your phone in your morning commute to work, so you want to save the interesting stories' comments thread beforehand in a flat file source like csv. You find their API documentation ( https://github.com/HackerNews/API) and implement the following task:\n",
    "\n",
    "1. Write a function `get_comments` that takes `storyid` as a parameter and returns a dataframe of all the comments below the news story. You can ignore 'dead' comments (you will know it when you see it). **Make sure the order of the comments in your dataframe is from top to bottom just as you see on the website**. You are allowed to use loops in this function. Addtional requirement: write at least one helper method\n",
    "\n",
    "You only want these information for the comments:\n",
    "1. `id`: the unique ids\n",
    "2. `by`: the author of the comment\n",
    "3. `parent`: who (also in unique ids) they are replying to\n",
    "4. `text`: the actual comment\n",
    "5. `time`: when the comment is created (in `pd.datetime` format)\n",
    "\n",
    "Hints:\n",
    "1. Use depth-first-search when traversing the comments tree.\n",
    "2. https://docs.python.org/3/tutorial/datastructures.html#using-lists-as-stacks.\n",
    "3. Check the size of your dataframe to the story's `descendants` attribute (number of comments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#news_endpoint = \"https://hacker-news.firebaseio.com/v0/item/18344932.json\"\n",
    "#load = requests.get(news_endpoint).json()\n",
    "#load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load['kids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#L = {x for x in load}\n",
    "#df = pd.read_json(load)\n",
    "#pd.DataFrame(load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load = requests.get(news_endpoint)\n",
    "#pd.read_json(load.content, orient='columns')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_dict = {'id':[], 'by':[], 'parent':[], 'text':[], 'time':[]}\n",
    "#comment_df = pd.DataFrame(df_dict)\n",
    "#comment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#requests.get(\"https://hacker-news.firebaseio.com/v0/item/18348631.json\").json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\"https://hacker-news.firebaseio.com/v0/item/{}.json\".format(18348631)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_kids(visited,loaded,kids):\n",
    "#     if kids not in visited:\n",
    "#         visited.add(kid)\n",
    "#         if 'kid' in visited['kids']\n",
    "#         for kid in loaded['kids']:\n",
    "#             get_kids(visited,loaded,kid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# story_endpoint = \"https://hacker-news.firebaseio.com/v0/item/{}.json\".format('18344932')\n",
    "# load = requests.get(story_endpoint).json()\n",
    "# story_df = pd.DataFrame(load).sort_values(by='time')\n",
    "# story_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def kids_dfs(comment_id,cols):\n",
    "    link = \"https://hacker-news.firebaseio.com/v0/item/{}.json\".format(comment_id)\n",
    "    load = requests.get(link).json()\n",
    "    link_series = pd.Series(load)\n",
    "    \n",
    "    if 'kids' in link_series.index:\n",
    "        kids = list(link_series['kids'])\n",
    "        if 'dead' in link_series.index:\n",
    "            return pd.concat([kids_dfs(kid,cols) for kid in kids], ignore_index=True)\n",
    "        else:\n",
    "            link_df = [pd.DataFrame([link_series[cols]])] + [kids_dfs(kid,cols) for kid in kids]\n",
    "            return pd.concat(link_df, ignore_index=True)\n",
    "    else:\n",
    "        if 'dead' in link_series.index:\n",
    "            return pd.DataFrame(columns=cols)\n",
    "        else:\n",
    "            return pd.DataFrame([link_series[cols]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(storyid):\n",
    "    \"\"\"\n",
    "    Returns a dataframe of all the comments below a news story\n",
    "    >>> out = get_comments(18344932)\n",
    "    >>> out.shape\n",
    "    (18, 5)\n",
    "    >>> out.loc[5, 'by']\n",
    "    'RobAtticus'\n",
    "    >>> out.loc[5, 'time'].day\n",
    "    31\n",
    "    \"\"\"\n",
    "    story_endpoint = \"https://hacker-news.firebaseio.com/v0/item/{}.json\".format(storyid)\n",
    "    load = requests.get(story_endpoint).json()\n",
    "    story_df = pd.DataFrame(load)\n",
    "    \n",
    "    cols = ['id','by','parent','text','time']\n",
    "    comment_df = pd.DataFrame(columns=cols)\n",
    "\n",
    "    for comment_id in story_df['kids']:\n",
    "        #comment_endpoint = \"https://hacker-news.firebaseio.com/v0/item/{}.json\".format(comment_id)\n",
    "        comments = kids_dfs(comment_id,cols)\n",
    "        comment_df = pd.concat([comment_df,comments],ignore_index=True)\n",
    "    \n",
    "    comment_df['time'] = pd.to_datetime(comment_df['time'], unit='s')\n",
    "    comment_df = comment_df.astype({'id':'int','parent':'int'})\n",
    "    \n",
    "    return comment_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = get_comments(18344932)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.loc[5, 'by']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out.loc[5, 'time'].day"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You're done!\n",
    "\n",
    "* Submit the lab on Gradescope"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
