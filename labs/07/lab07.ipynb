{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC 80: Lab 07\n",
    "\n",
    "### Due Date: Tuesday, May 18th 11:59PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Instructions\n",
    "Much like in DSC 10, this Jupyter Notebook contains the statements of the problems and provides code and markdown cells to display your answers to the problems. Unlike DSC 10, the notebook is *only* for displaying a readable version of your final answers. The coding work will be developed in an accompanying `lab*.py` file, that will be imported into the current notebook.\n",
    "\n",
    "Labs and programming assignments will be graded in (at most) two ways:\n",
    "1. The functions and classes in the accompanying python file will be tested (a la DSC 20),\n",
    "2. The notebook will be graded (for graphs and free response questions).\n",
    "\n",
    "**Do not change the function names in the `*.py` file**\n",
    "- The functions in the `*.py` file are how your assignment is graded, and they are graded by their name. The dictionary at the end of the file (`GRADED FUNCTIONS`) contains the \"grading list\". The final function in the file allows your doctests to check that all the necessary functions exist.\n",
    "- If you changed something you weren't supposed to, just use git to revert!\n",
    "\n",
    "**Tips for working in the Notebook**:\n",
    "- The notebooks serve to present you the questions and give you a place to present your results for later review.\n",
    "- The notebook on *lab assignments* are not graded (only the `.py` file).\n",
    "- Notebooks for PAs will serve as a final report for the assignment, and contain conclusions and answers to open ended questions that are graded.\n",
    "- The notebook serves as a nice environment for 'pre-development' and experimentation before designing your function in your `.py` file.\n",
    "\n",
    "**Tips for developing in the .py file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are encouraged to write your own additional functions to solve the lab! \n",
    "    - Developing in python usually consists of larger files, with many short functions.\n",
    "    - You may write your other functions in an additional `.py` file that you import in `lab**.py` (much like we do in the notebook).\n",
    "- Always document your code!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing code from `lab**.py`\n",
    "\n",
    "* We import our `.py` file that's contained in the same directory as this notebook.\n",
    "* We use the `autoreload` notebook extension to make changes to our `lab**.py` file immediately available in our notebook. Without this extension, we would need to restart the notebook kernel to see any changes to `lab**.py` in the notebook.\n",
    "    - `autoreload` is necessary because, upon import, `lab**.py` is compiled to bytecode (in the directory `__pycache__`). Subsequent imports of `lab**` merely import the existing compiled python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import lab07 as lab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import os\n",
    "import time\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Practice with regular expressions (Regex)\n",
    "\n",
    "**Question 1**\n",
    "\n",
    "You start with some basic regular expression exercises to get some practice using them. You will find function stubs and related doctests in the starter code. \n",
    "\n",
    "**Exercise 1:** A string that has a `[` as the third character and `]` as the sixth character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_1(string):\n",
    "    \"\"\"\n",
    "    >>> match_1(\"abcde]\")\n",
    "    False\n",
    "    >>> match_1(\"ab[cde\")\n",
    "    False\n",
    "    >>> match_1(\"a[cd]\")\n",
    "    False\n",
    "    >>> match_1(\"ab[cd]\")\n",
    "    True\n",
    "    >>> match_1(\"1ab[cd]\")\n",
    "    False\n",
    "    >>> match_1(\"ab[cd]ef\")\n",
    "    True\n",
    "    >>> match_1(\"1b[#d] _\")\n",
    "    True\n",
    "    \"\"\"\n",
    "    #Your Code Here\n",
    "    #pattern = '(.+)(.+)\\[(.+)(.+)\\]'\n",
    "    pattern = '^..\\[(.+)(.+)\\]'\n",
    "    \n",
    "    #Do not edit following code\n",
    "    prog = re.compile(pattern)\n",
    "    return prog.search(string) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_1(\"abcde]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_1(\"ab[cde\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_1(\"a[cd]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_1(\"ab[cd]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_1(\"1ab[cd]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_1(\"ab[cd]ef\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_1(\"1b[#d] _\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 2:** Phone numbers that start with '(858)' and follow the format '(xxx) xxx-xxxx' (x represents a digit).\n",
    "\n",
    "*Notice: There is a space between (xxx) and xxx-xxxx*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_2(string):\n",
    "    \"\"\"\n",
    "    Phone numbers that start with '(858)' and\n",
    "    follow the format '(xxx) xxx-xxxx' (x represents a digit)\n",
    "    Notice: There is a space between (xxx) and xxx-xxxx\n",
    "\n",
    "    >>> match_2(\"(123) 456-7890\")\n",
    "    False\n",
    "    >>> match_2(\"858-456-7890\")\n",
    "    False\n",
    "    >>> match_2(\"(858)45-7890\")\n",
    "    False\n",
    "    >>> match_2(\"(858) 456-7890\")\n",
    "    True\n",
    "    >>> match_2(\"(858)456-789\")\n",
    "    False\n",
    "    >>> match_2(\"(858)456-7890\")\n",
    "    False\n",
    "    >>> match_2(\"a(858) 456-7890\")\n",
    "    False\n",
    "    >>> match_2(\"(858) 456-7890b\")\n",
    "    False\n",
    "    \"\"\"\n",
    "    #Your Code Here\n",
    "    pattern = '^\\([8][5][8]\\) [0-9]{3}-[0-9]{4}$'\n",
    "\n",
    "    #Do not edit following code\n",
    "    prog = re.compile(pattern)\n",
    "    return prog.search(string) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_2(\"(123) 456-7890\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_2(\"858-456-7890\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_2(\"(858)45-7890\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_2(\"(858) 456-7890\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_2(\"(858)456-789\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_2(\"(858)456-7890\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_2(\"a(858) 456-7890\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_2(\"(858) 456-7890b\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 3:** A string whose length is between 6 to 10 and contains only word characters, white spaces and `?`. This string must have `?` as its last character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_3(string):\n",
    "    \"\"\"\n",
    "    Find a pattern whose length is between 6 to 10\n",
    "    and contains only word character, white space and ?.\n",
    "    This string must have ? as its last character.\n",
    "\n",
    "    >>> match_3(\"qwertsd?\")\n",
    "    True\n",
    "    >>> match_3(\"qw?ertsd?\")\n",
    "    True\n",
    "    >>> match_3(\"ab c?\")\n",
    "    False\n",
    "    >>> match_3(\"ab   c ?\")\n",
    "    True\n",
    "    >>> match_3(\" asdfqwes ?\")\n",
    "    False\n",
    "    >>> match_3(\" adfqwes ?\")\n",
    "    True\n",
    "    >>> match_3(\" adf!qes ?\")\n",
    "    False\n",
    "    >>> match_3(\" adf!qe? \")\n",
    "    False\n",
    "    \"\"\"\n",
    "    #Your Code Here\n",
    "\n",
    "    #pattern = '(\\w|[a-zA-Z]){5,9}\\?'\n",
    "    pattern = '^[a-zA-Z\\s\\?]{5,9}\\?$'\n",
    "\n",
    "    #Do not edit following code\n",
    "    prog = re.compile(pattern)\n",
    "    return prog.search(string) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_3(\"qwertsd?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_3(\"qw?ertsd?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_3(\"ab c?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_3(\"ab   c ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_3(\" asdfqwes ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_3(\" adfqwes ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_3(\" adf!qes ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_3(\" adf!qe? \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 4:** A string that begins with '\\\\$' and with another '\\\\$' within, where:\n",
    "   - Characters between the two '\\\\$' can be anything (including nothing) except the letters 'a', 'b', 'c' (lower case).\n",
    "   - Characters after the second '\\\\$' can only have any number of the letters 'a', 'b', 'c' (upper or lower case), with every 'a' before every 'b', and every 'b' before every 'c'.\n",
    "       - E.g. 'AaBbbC' works, 'ACB' doesn't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_4(string):\n",
    "    \"\"\"\n",
    "    A string that begins with '$' and with another '$' within, where:\n",
    "        - Characters between the two '$' can be anything except the \n",
    "        letters 'a', 'b', 'c' (lower case).\n",
    "        - Characters after the second '$' can only have any number \n",
    "        of the letters 'a', 'b', 'c' (upper or lower case), with every \n",
    "        'a' before every 'b', and every 'b' before every 'c'.\n",
    "            - E.g. 'AaBbbC' works, 'ACB' doesn't.\n",
    "\n",
    "    >>> match_4(\"$$AaaaaBbbbc\")\n",
    "    True\n",
    "    >>> match_4(\"$!@#$aABc\")\n",
    "    True\n",
    "    >>> match_4(\"$a$aABc\")\n",
    "    False\n",
    "    >>> match_4(\"$iiuABc\")\n",
    "    False\n",
    "    >>> match_4(\"123$Abc\")\n",
    "    False\n",
    "    >>> match_4(\"$$Abc\")\n",
    "    True\n",
    "    >>> match_4(\"$qw345t$AAAc\")\n",
    "    False\n",
    "    >>> match_4(\"$s$Bca\")\n",
    "    False\n",
    "    \"\"\"\n",
    "    #Your Code Here\n",
    "    pattern = r'\\$[^abc]*\\$+([Aa]+[Bb]+[Cc])]*'\n",
    "    \n",
    "    #Do not edit following code\n",
    "    prog = re.compile(pattern)\n",
    "    return prog.search(string) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_4(\"$$AaaaaBbbbc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_4(\"$!@#$aABc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_4(\"$a$aABc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_4(\"$iiuABc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_4(\"123$Abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_4(\"$$Abc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_4(\"$qw345t$AAAc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_4(\"$s$Bca\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 5:** A string that represents a valid Python file name including the extension. \n",
    "\n",
    "*Notice*: For simplicity, assume that the file name contains only letters, numbers and an underscore `_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_5(string):\n",
    "    \"\"\"\n",
    "    A string that represents a valid Python file name including the extension.\n",
    "    *Notice*: For simplicity, assume that the file name contains only letters, numbers and an underscore `_`.\n",
    "\n",
    "    >>> match_5(\"dsc80.py\")\n",
    "    True\n",
    "    >>> match_5(\"dsc80py\")\n",
    "    False\n",
    "    >>> match_5(\"dsc80..py\")\n",
    "    False\n",
    "    >>> match_5(\"dsc80+.py\")\n",
    "    False\n",
    "    \"\"\"\n",
    "\n",
    "    #Your Code Here\n",
    "    pattern = '^[\\w\\_]*.py'\n",
    "\n",
    "    #Do not edit following code\n",
    "    prog = re.compile(pattern)\n",
    "    return prog.search(string) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_5(\"dsc80.py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_5(\"dsc80py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_5(\"dsc80..py\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_5(\"dsc80+.py\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 6:** Find patterns of lowercase letters joined with an underscore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_6(string):\n",
    "    \"\"\"\n",
    "    Find patterns of lowercase letters joined with an underscore.\n",
    "    >>> match_6(\"aab_cbb_bc\")\n",
    "    False\n",
    "    >>> match_6(\"aab_cbbbc\")\n",
    "    True\n",
    "    >>> match_6(\"aab_Abbbc\")\n",
    "    False\n",
    "    >>> match_6(\"abcdef\")\n",
    "    False\n",
    "    >>> match_6(\"ABCDEF_ABCD\")\n",
    "    False\n",
    "    \"\"\"\n",
    "\n",
    "    #Your Code Here\n",
    "    pattern = '^[a-z]*_[a-z]*$'\n",
    "\n",
    "    #Do not edit following code\n",
    "    prog = re.compile(pattern)\n",
    "    return prog.search(string) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_6(\"aab_cbb_bc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_6(\"aab_cbbbc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_6(\"aab_Abbbc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_6(\"abcdef\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_6(\"ABCDEF_ABCD\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 7:** Find patterns that start with and end with a `_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_7(string):\n",
    "    \"\"\"\n",
    "    Find patterns that start with and end with a _\n",
    "    >>> match_7(\"_abc_\")\n",
    "    True\n",
    "    >>> match_7(\"abd\")\n",
    "    False\n",
    "    >>> match_7(\"bcd\")\n",
    "    False\n",
    "    >>> match_7(\"_ncde\")\n",
    "    False\n",
    "    \"\"\"\n",
    "\n",
    "    pattern = '^_.*_$'\n",
    "\n",
    "    #Do not edit following code\n",
    "    prog = re.compile(pattern)\n",
    "    return prog.search(string) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_7(\"_abc_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_7(\"abd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_7(\"bcd\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_7(\"_ncde\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 8:**  Apple registration numbers and Apple hardware product serial numbers might have the number '0' (zero), but never the letter 'O'. Serial numbers don't have the number '1' (one) or the letter 'i'. Write a line of regex expression that checks if the given Serial number belongs to a genuine Apple product."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_8(string):\n",
    "    \"\"\"\n",
    "    Apple registration numbers and Apple hardware product serial numbers\n",
    "    might have the number \"0\" (zero), but never the letter \"O\".\n",
    "    Serial numbers don't have the number \"1\" (one) or the letter \"i\".\n",
    "\n",
    "    Write a line of regex expression that checks\n",
    "    if the given Serial number belongs to a genuine Apple product.\n",
    "\n",
    "    >>> match_8(\"ASJDKLFK10ASDO\")\n",
    "    False\n",
    "    >>> match_8(\"ASJDKLFK0ASDo\")\n",
    "    True\n",
    "    >>> match_8(\"JKLSDNM01IDKSL\")\n",
    "    False\n",
    "    >>> match_8(\"ASDKJLdsi0SKLl\")\n",
    "    False\n",
    "    >>> match_8(\"ASDJKL9380JKAL\")\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    pattern = '^((?!O)(?!i).)*$'\n",
    "\n",
    "    #Do not edit following code\n",
    "    prog = re.compile(pattern)\n",
    "    return prog.search(string) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_8(\"ASJDKLFK10ASDO\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_8(\"ASJDKLFK0ASDo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_8(\"JKLSDNM01IDKSL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_8(\"ASDKJLdsi0SKLl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_8(\"ASDJKL9380JKAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 9:** Check if a given ID number is from Los Angeles (LAX), San Diego(SAN) or the state of New York (NY). ID numbers have the following format `SC-NN-CCC-NNNN`. \n",
    "   - SC represents state code in uppercase \n",
    "   - NN represents a number with 2 digits \n",
    "   - CCC represents a three letter city code in uppercase\n",
    "   - NNNN represents a number with 4 digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_9(string):\n",
    "    '''\n",
    "    >>> match_9('NY-32-NYC-1232')\n",
    "    True\n",
    "    >>> match_9('ca-23-SAN-1231')\n",
    "    False\n",
    "    >>> match_9('MA-36-BOS-5465')\n",
    "    False\n",
    "    >>> match_9('CA-56-LAX-7895')\n",
    "    True\n",
    "    '''\n",
    "\n",
    "    pattern = '^[A-Z]{2}-[0-9]{2}-(NYC|LAX|SAN)-[0-9]{4}$'\n",
    "\n",
    "    #Do not edit following code\n",
    "    prog = re.compile(pattern)\n",
    "    return prog.search(string) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_9('NY-32-NYC-1232')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_9('ca-23-SAN-1231')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_9('MA-36-BOS-5465')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_9('CA-56-LAX-7895')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise 10:**  Given an input string, cast it to lower case, remove spaces/punctuation, and return a list of every 3-character substring following this logic:\n",
    "   - The first character doesn't start with 'a' or 'A'\n",
    "   - The last substring (and only the last substring) can be shorter than 3 characters, depending on the length of the input string.\n",
    "   - The substrings cannot overlap\n",
    "   \n",
    "Here's an example with one of the doctests:\n",
    "\n",
    "`>>> match_10(\"Ab..DEF\")`\n",
    "`['def']`\n",
    "\n",
    "1. convert it to a lowercase string resulting in \"ab..def\"\n",
    "2. delete any 3 letter sequence that starts with the letter 'a', so delete \"ab.\" from the string, leaving using with \".def\"\n",
    "3. delete the punctuation resulting in \"def\"\n",
    "4. finally, we get `[\"def\"]`\n",
    "\n",
    "(Only split in the last step, everything else is removing from the string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['abd', 'ef']"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = re.sub('[\\W]','',\"Ab..DEF\").lower()\n",
    "re.findall('[\\w]{1,3}',s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def match_10(string):\n",
    "    '''\n",
    "    Given an input string, cast it to lower case, remove spaces/punctuation, \n",
    "    and return a list of every 3-character substring that satisfy the following:\n",
    "        - The first character doesn't start with 'a' or 'A'\n",
    "        - The last substring (and only the last substring) can be shorter than \n",
    "        3 characters, depending on the length of the input string.\n",
    "    \n",
    "    >>> match_10('ABCdef')\n",
    "    ['def']\n",
    "    >>> match_10(' DEFaabc !g ')\n",
    "    ['def', 'cg']\n",
    "    >>> match_10('Come ti chiami?')\n",
    "    ['com', 'eti', 'chi']\n",
    "    >>> match_10('and')\n",
    "    []\n",
    "    >>> match_10( \"Ab..DEF\")\n",
    "    ['def']\n",
    "    '''\n",
    "    s = re.sub(r'[Aa].{2}', '', string.lower())\n",
    "    #s = re.sub('[\\W]','',s)\n",
    "    s = re.sub(r'[\\s|.!?\\\\-]','',s)\n",
    "    chunks = re.findall(r'.{1,3}',s)\n",
    "    return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def']"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_10('ABCdef')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def', 'cg']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_10(' DEFaabc !g ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['com', 'eti', 'chi']"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_10('Come ti chiami?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_10('and')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['def']"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "match_10( \"Ab..DEF\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regex groups: extracting personal information from messy data\n",
    "\n",
    "**Question 2**\n",
    "\n",
    "The file in `data/messy.txt` contains personal information from a fictional website that a user scraped from webserver logs. Within this dataset, there are four fields that interest you:\n",
    "1. Email Addresses (assume they are alphanumeric user-names and domain-names),\n",
    "2. [Social Security Numbers](https://en.wikipedia.org/wiki/Social_Security_number#Structure)\n",
    "3. Bitcoin Addresses (alpha-numeric strings of long length)\n",
    "4. Street Addresses\n",
    "\n",
    "Create a function `extract_personal` that takes in a string like `open('data/messy.txt').read()` and returns a tuple of four separate lists containing values of the 4 pieces of information listed above (in the order given). Do **not** keep empty values.\n",
    "\n",
    "*Hint*: There are multiple \"delimiters\" in use in the file; there are few enough of them that you can safely determine what they are.\n",
    "\n",
    "*Note:* Since this data is messy/corrupted, your function will be allowed to miss ~5% of the records in each list. Good spot checking using certain useful substrings (e.g. `@` for emails) should help assure correctness! Your function will be tested on a sample of the file `messy.txt`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'messy.txt')\n",
    "s = open(fp, encoding='utf8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1\\t4/12/2018\\tLorem ipsum dolor sit amet, consectetuer adipiscing elit. Proin risus. Praesent lectus.\\n\\nVestibulum quam sapien| varius ut, blandit non, interdum in, ante. Vestibulum ante ipsum primis in faucibus orci luctus et ultrices posuere cubilia Curae; Duis faucibus accumsan odio. Curabitur convallis.|dottewell0@gnu.org\\toR1mOq,!@#$%^&*(),[{bitcoin:18A8rBU3wvbLTSxMjqrPNc9mvonpA4XMiv\\tIP:192.232.9.210\\tccn:3563354617955160|ssn:380-09-9403}]|05-6609813,814 Monterey Court\\n2\\t12/18/2018\\tSuspendisse potenti. In eleifend quam a odio. In hac habitasse platea dictumst.\\n\\nMaecenas ut massa quis augue luctus tincidunt. Nulla mollis molestie lorem. Quisque ut erat.,bassiter1@sphinn.com\\tc5KvmarHX3o,test\\u2060test\\u202b,[{bitcoin:1EB7kYpnfJSqS7kUFpinsmPF3uiH9sfRf1,IP:20.73.13.197|ccn:3542723823957010\\tssn:118-12-8276}#{bitcoin:1E5fev4boabWZmXvHGVkHcNJZ2tLnpM6Zv*IP:238.206.212.148\\tccn:337941898369615,ssn:427-22-9352}#{bitcoin:1DqG3WcmGw74PjptjzcAmxGFuQdvWL7RCC,IP:171.241.15.98\\tccn:3574672962323693,ssn:649-16-224'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s[:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_personal(s):\n",
    "    \"\"\"\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'messy.test.txt')\n",
    "    >>> s = open(fp, encoding='utf8').read()\n",
    "    >>> emails, ssn, bitcoin, addresses = extract_personal(s)\n",
    "    >>> emails[0] == 'test@test.com'\n",
    "    True\n",
    "    >>> ssn[0] == '423-00-9575'\n",
    "    True\n",
    "    >>> bitcoin[0] == '1BvBMSEYstWetqTFn5Au4m4GFg7xJaNVN2'\n",
    "    True\n",
    "    >>> addresses[0] == '530 High Street'\n",
    "    True\n",
    "    \"\"\"\n",
    "    email_pattern = '[\\w]*@[^.]+\\.[a-z]{3}'\n",
    "    emails = re.findall(email_pattern,s)\n",
    "    \n",
    "    ssns_pattern = '[0-9]{3}-[]0-9]{2}-[0-9]{4}'\n",
    "    ssns = re.findall(ssns_pattern,s)\n",
    "    \n",
    "    btc_pattern = '(?<=bitcoin:)\\w*'\n",
    "    bcs = re.findall(btc_pattern,s)\n",
    "    \n",
    "    address_pattern = '[0-9]+ [A-Za-z]+ [A-Za-z]+'\n",
    "    addresses = re.findall(address_pattern,s)\n",
    "    \n",
    "    return emails,ssns,bcs,addresses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'messy.test.txt')\n",
    "s = open(fp, encoding='utf8').read()\n",
    "emails, ssn, bitcoin, addresses = extract_personal(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emails[0] == 'test@test.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ssn[0] == '423-00-9575'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bitcoin[0] == '1BvBMSEYstWetqTFn5Au4m4GFg7xJaNVN2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "addresses[0] == '530 High Street'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Content in Amazon review data\n",
    "\n",
    "**Question 3**\n",
    "\n",
    "The dataset `reviews.txt` contains [Amazon reviews](http://jmcauley.ucsd.edu/data/amazon/) for ~200k phones and phone accessories. This dataset has been \"cleaned\" for you. The goal of this section is to create a function that takes in the review dataset and a review and returns the word that \"best summarizes the review\" using TF-IDF.'\n",
    "\n",
    "1. Create a function `tfidf_data(review, reviews)` that takes a review as well as the review data and returns a dataframe:\n",
    "    - indexed by the words in `review`,\n",
    "    - with columns given by (a) the number of times each word is found in the review (`cnt`), (b) the term frequency for each word (`tf`), (c) the inverse document frequency for each word (`idf`), and (d) the TF-IDF for each word (`tfidf`).\n",
    "    \n",
    "2. Create a function `relevant_word(tfidf_data)` which takes in a dataframe as above and returns the word that \"best summarizes the review\" described by `tfidf_data`.\n",
    "\n",
    "\n",
    "*Note:* Use this function to \"cluster\" review types -- run it on a sample of reviews and see which words come up most. Unfortunately, you will likely have to change your code from your answer above to run it on the entire dataset (to do this, you should compute as many of the frequencies \"ahead of time\" and look them up when needed; you should also likely filter out words that occur \"rarely\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'reviews.txt')\n",
    "reviews = pd.read_csv(fp, header=None, squeeze=True)\n",
    "review = open(os.path.join('data', 'review.txt'), encoding='utf8').read().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a great new case design that i have not seen before it has a slim silicone skin that really locks in the phone to cover and protect your phone from spills and such and also a hard polycarbonate outside shell cover to guard it against damage  this case also comes with different interchangeable skins and covers to create multiple color combinations  this is a different kind of case than the usual chunk of plastic  it is innovative and suits the iphone 5 perfectly'"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#list(set(review.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['this', 'is', 'a', 'great', 'new', 'case', 'design', 'that', 'i',\n",
       "       'have', 'not', 'seen', 'before', 'it', 'has', 'slim', 'silicone',\n",
       "       'skin', 'really', 'locks', 'in', 'the', 'phone', 'to', 'cover',\n",
       "       'and', 'protect', 'your', 'from', 'spills', 'such', 'also', 'hard',\n",
       "       'polycarbonate', 'outside', 'shell', 'guard', 'against', 'damage',\n",
       "       'comes', 'with', 'different', 'interchangeable', 'skins', 'covers',\n",
       "       'create', 'multiple', 'color', 'combinations', 'kind', 'of',\n",
       "       'than', 'usual', 'chunk', 'plastic', 'innovative', 'suits',\n",
       "       'iphone', '5', 'perfectly'], dtype=object)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(review.split()).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        works great  i called t mobile and had this si...\n",
       "1        these items looked to be of good quality and h...\n",
       "2        this product arrive faster than i expected  i ...\n",
       "3        i brought this for my sister who has a g2 but ...\n",
       "4         i am both delighted and disappointed with del...\n",
       "                               ...                        \n",
       "58297    bought i for my husband's phone a week ago  ni...\n",
       "58298    the spring loaded adjustable holder looks nift...\n",
       "58299    received on time  everything working less spea...\n",
       "58300    i bought this battery pack with the mindset of...\n",
       "58301              that work    but thats not the original\n",
       "Name: 0, Length: 58302, dtype: object"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame([[1,2,3],[1,2,3],[1,2,3]],index=['a','b','c'])[0]['a']#[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tfidf_data(review, reviews):\n",
    "#     \"\"\"\n",
    "#     :Example:\n",
    "#     >>> fp = os.path.join('data', 'reviews.txt')\n",
    "#     >>> reviews = pd.read_csv(fp, header=None, squeeze=True)\n",
    "#     >>> review = open(os.path.join('data', 'review.txt'), encoding='utf8').read().strip()\n",
    "#     >>> out = tfidf_data(review, reviews)\n",
    "#     >>> out['cnt'].sum()\n",
    "#     85\n",
    "#     >>> 'before' in out.index\n",
    "#     True\n",
    "#     \"\"\"\n",
    "#     words = reviews.str.lower().str.split().sum().unique()\n",
    "#     df_dict = {'cnt':[],'tf':[],'idf':[]}\n",
    "#     df = pd.DataFrame(index=words)\n",
    "    \n",
    "#     for w in words:\n",
    "#         re_pat = '\\\\b%s\\\\b' % w\n",
    "         \n",
    "#         cnt = review.count(re_pat) \n",
    "#         df['cnt'][word] = cnt\n",
    "        \n",
    "#         tf = cnt / (review.count(' ') + 1)\n",
    "#         df['tf'][word] = tf\n",
    "        \n",
    "#         idf = np.log(len(reviews) / reviews.str.contains(word).sum())\n",
    "#         df['idf'][word] = idf\n",
    "#     df['tfidf'] = df['tf'] * df['idf']\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "w_dict = {}\n",
    "split = review.split()\n",
    "for w in split:\n",
    "    if w in w_dict.keys():\n",
    "        w_dict[w] += 1\n",
    "    else:\n",
    "        w_dict[w] = 1\n",
    "#pd.DataFrame.from_dict(w_dict,orient='index',columns=['cnt'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def tfidf_data(review, reviews):\n",
    "    \"\"\"\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'reviews.txt')\n",
    "    >>> reviews = pd.read_csv(fp, header=None, squeeze=True)\n",
    "    >>> review = open(os.path.join('data', 'review.txt'), encoding='utf8').read().strip()\n",
    "    >>> out = tfidf_data(review, reviews)\n",
    "    >>> out['cnt'].sum()\n",
    "    85\n",
    "    >>> 'before' in out.index\n",
    "    True\n",
    "    \"\"\"\n",
    "    w_dict = {}\n",
    "    split = review.split()\n",
    "    for w in split:\n",
    "        if w in w_dict.keys():\n",
    "            w_dict[w] += 1\n",
    "        else:\n",
    "            w_dict[w] = 1\n",
    "    df = pd.DataFrame.from_dict(w_dict,columns=['cnt'],orient='index')\n",
    "    \n",
    "    keys = list(w_dict.keys())\n",
    "    vals = list(w_dict.values())\n",
    "    \n",
    "    df = df.assign(tf = np.array(vals) / sum(w_dict.values()))\n",
    "    df = df.assign(idf = [np.log(len(reviews) / reviews.str.contains(w).sum()) for w in keys])\n",
    "    df = df.assign(tfidf = df['tf'] * df['idf'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tfidf_data(review, reviews):\n",
    "    \"\"\"\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'reviews.txt')\n",
    "    >>> reviews = pd.read_csv(fp, header=None, squeeze=True)\n",
    "    >>> review = open(os.path.join('data', 'review.txt'), encoding='utf8').read().strip()\n",
    "    >>> out = tfidf_data(review, reviews)\n",
    "    >>> out['cnt'].sum()\n",
    "    85\n",
    "    >>> 'before' in out.index\n",
    "    True\n",
    "    \"\"\"\n",
    "    split = review.split()\n",
    "    words = list(set(split))\n",
    "    cnts = []\n",
    "    tfs = []\n",
    "    idfs = []\n",
    "    for w in words:\n",
    "        re_pat = '\\\\b%s\\\\b' % w\n",
    "        cnt = split.count(w)\n",
    "        cnts.append(cnt)\n",
    "        \n",
    "        tf = cnt / (review.count(' ') + 1)\n",
    "        tfs.append(tf) \n",
    "        \n",
    "        idf = np.log(len(reviews) / reviews.str.lower().str.contains(w).sum())\n",
    "        idfs.append(idf)\n",
    "    df_dict = {'cnt':cnts,'tf':tfs,'idf':idfs}\n",
    "    df = pd.DataFrame(df_dict,index=words)\n",
    "    df['tfidf'] = df['tf'] * df['idf']\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'reviews.txt')\n",
    "reviews = pd.read_csv(fp, header=None, squeeze=True)\n",
    "review = open(os.path.join('data', 'review.txt'), encoding='utf8').read().strip()\n",
    "out = tfidf_data(review, reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cnt</th>\n",
       "      <th>tf</th>\n",
       "      <th>idf</th>\n",
       "      <th>tfidf</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>and</th>\n",
       "      <td>5</td>\n",
       "      <td>0.056818</td>\n",
       "      <td>0.219198</td>\n",
       "      <td>0.012454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>1</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>2.444468</td>\n",
       "      <td>0.027778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plastic</th>\n",
       "      <td>1</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>2.725910</td>\n",
       "      <td>0.030976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>i</th>\n",
       "      <td>1</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>0.002679</td>\n",
       "      <td>0.000030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covers</th>\n",
       "      <td>1</td>\n",
       "      <td>0.011364</td>\n",
       "      <td>3.742829</td>\n",
       "      <td>0.042532</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         cnt        tf       idf     tfidf\n",
       "and        5  0.056818  0.219198  0.012454\n",
       "new        1  0.011364  2.444468  0.027778\n",
       "plastic    1  0.011364  2.725910  0.030976\n",
       "i          1  0.011364  0.002679  0.000030\n",
       "covers     1  0.011364  3.742829  0.042532"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "85"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " out['cnt'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'before' in out.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'spills'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.sort_values('tfidf',ascending=False).index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relevant_word(out):\n",
    "    \"\"\"\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'reviews.txt')\n",
    "    >>> reviews = pd.read_csv(fp, header=None, squeeze=True)\n",
    "    >>> review = open(os.path.join('data', 'review.txt'), encoding='utf8').read().strip()\n",
    "    >>> out = tfidf_data(review, reviews)\n",
    "    >>> relevant_word(out) in out.index\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    return out.sort_values('tfidf',ascending=False).index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'reviews.txt')\n",
    "reviews = pd.read_csv(fp, header=None, squeeze=True)\n",
    "review = open(os.path.join('data', 'review.txt'), encoding='utf8').read().strip()\n",
    "out = tfidf_data(review, reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relevant_word(out) in out.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweet Analysis: Internet Research Agency\n",
    "\n",
    "The dataset `data/ira.csv` contains tweets tagged by Twitter as likely being posted by the *Internet Research Angency* (the tweet factory facing allegations for attempting to influence US political elections).\n",
    "\n",
    "The questions in this section will focus on the following:\n",
    "1. We will look at the hashtags present in the text and trends in their makeup.\n",
    "2. We will prepare this dataset for modeling by creating features out of the text fields.\n",
    "\n",
    "**Question 4 (HashTags)**\n",
    "\n",
    "You may assume that a hashtag is any string without whitespace following a `#` (this is more permissive than Twitters rules for hashtags; you are encouraged to go down this rabbit-hole to better figure out how to clean your data!).\n",
    "\n",
    "* Create a function `hashtag_list` that takes in a column of tweet-text and returns a column containing the list of hashtags present in the tweet text. If a tweet doesn't contain a hashtag, the function should return an empty list.\n",
    "\n",
    "* Create a function `most_common_hashtag` that takes in a column of hashtag-lists (the output above) and returns a column consisting a single hashtag from the tweet-text. \n",
    "    - If the text has no hashtags, the entry should be `NaN`,\n",
    "    - If the text has one distinct hashtag, the entry should contain that hashtag,\n",
    "    - If the text has more than one hashtag, the entry should be the most common hashtag (among all hashtags in the column). If there is a tie for most common, any of the most common can be returned.\n",
    "        - E.g. if the input column was: `pd.Series([[1, 2, 2], [3, 2, 3]])`, the output would be: `pd.Series([2, 2])`. Even though `3` was more common in the second list, `2` is the most common among all hashtags in the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'ira.csv')\n",
    "ira = pd.read_csv(fp, names=['id', 'name', 'date', 'text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3906258</td>\n",
       "      <td>ea85ac8be1e8ab479064ca4c0fe3ac6587f76b1ef97452...</td>\n",
       "      <td>2016-11-16 09:04</td>\n",
       "      <td>The Best Exercise To Lose Belly Fat In 2 weeks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1051443</td>\n",
       "      <td>8e58ab0f46d273103d9e71aa92cdaffb6e330ec7d15ae5...</td>\n",
       "      <td>2016-12-24 04:31</td>\n",
       "      <td>RT @Philanthropy: Dozens of hate groups have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2823399</td>\n",
       "      <td>Room Of Rumor</td>\n",
       "      <td>2016-08-18 20:26</td>\n",
       "      <td>Artificial intelligence can find, map poverty,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>272878</td>\n",
       "      <td>San Francisco Daily</td>\n",
       "      <td>2016-03-18 19:28</td>\n",
       "      <td>Uber balks at rules proposed by worlds busies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7697802</td>\n",
       "      <td>41bb9ae5991f53996752a0ab8dd36b543821abca8d5aed...</td>\n",
       "      <td>2016-07-30 15:44</td>\n",
       "      <td>RT @dirtroaddiva1: #IHatePokemonGoBecause he  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               name  \\\n",
       "0  3906258  ea85ac8be1e8ab479064ca4c0fe3ac6587f76b1ef97452...   \n",
       "1  1051443  8e58ab0f46d273103d9e71aa92cdaffb6e330ec7d15ae5...   \n",
       "2  2823399                                      Room Of Rumor   \n",
       "3   272878                                San Francisco Daily   \n",
       "4  7697802  41bb9ae5991f53996752a0ab8dd36b543821abca8d5aed...   \n",
       "\n",
       "               date                                               text  \n",
       "0  2016-11-16 09:04  The Best Exercise To Lose Belly Fat In 2 weeks...  \n",
       "1  2016-12-24 04:31  RT @Philanthropy: Dozens of hate groups have...  \n",
       "2  2016-08-18 20:26  Artificial intelligence can find, map poverty,...  \n",
       "3  2016-03-18 19:28  Uber balks at rules proposed by worlds busies...  \n",
       "4  2016-07-30 15:44  RT @dirtroaddiva1: #IHatePokemonGoBecause he  ...  "
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ira.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Best Exercise To Lose Belly Fat In 2 weeks  https://t.co/oHFToG7rh6 #Exercise #LoseBellyFat #CatTV #TeenWolf https://t.co/b4pr9gEx38RT @Philanthropy: Dozens of hate groups have charity status, Chronicle study finds https://t.co/FxUBBHNlKyArtificial intelligence can find, map poverty, researchers say  #techUber balks at rules proposed by worlds busiest airport  #newsRT @dirtroaddiva1: #IHatePokemonGoBecause he  didn\\'t let me do \"that\" for a Klondike bar.    Screw you Pokemon.  #PokesAreJokes. https://t.'"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ira.iloc[:5]['text'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ht_grabber(row):\n",
    "    hashtags = re.findall('(?<=#)+?([^\\s]+)',row)\n",
    "    return hashtags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hashtag_list(tweet_text):\n",
    "    \"\"\"\n",
    "    :Example:\n",
    "    >>> testdata = [['RT @DSC80: Text-cleaning is cool! #NLP https://t.co/xsfdw88d #NLP1 #NLP1']]\n",
    "    >>> test = pd.DataFrame(testdata, columns=['text'])\n",
    "    >>> out = hashtag_list(test['text'])\n",
    "    >>> (out.iloc[0] == ['NLP', 'NLP1', 'NLP1'])\n",
    "    True\n",
    "    \"\"\"\n",
    "    \n",
    "    return tweet_text.apply(ht_grabber)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [NLP, NLP1, NLP1]\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata = [['RT @DSC80: Text-cleaning is cool! #NLP https://t.co/xsfdw88d #NLP1 #NLP1']]\n",
    "test = pd.DataFrame(testdata, columns=['text'])\n",
    "out = hashtag_list(test['text'])\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out.iloc[0] == ['NLP', 'NLP1', 'NLP1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NLP1'"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(['NLP', 'NLP1', 'NLP1']).value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common_hashtag(tweet_lists):\n",
    "    \"\"\"\n",
    "    :Example:\n",
    "    >>> testdata = [['RT @DSC80: Text-cleaning is cool! #NLP https://t.co/xsfdw88d #NLP1 #NLP1']]\n",
    "    >>> test = hashtag_list(pd.DataFrame(testdata, columns=['text'])['text'])\n",
    "    >>> most_common_hashtag(test).iloc[0]\n",
    "    'NLP1'\n",
    "    \"\"\"  \n",
    "    hashtags = [tag for ht in tweet_lists for tag in ht]\n",
    "    hashtags = pd.Series(hashtags)\n",
    "    hashtags = hashtags.value_counts()\n",
    "    def assign_helper(data):\n",
    "        if len(data) == 0:\n",
    "            return np.NaN\n",
    "        elif len(data) == 1:\n",
    "            return data[0]\n",
    "        else:\n",
    "            return hashtags.loc[data].idxmax()\n",
    "    \n",
    "    return tweet_lists.apply(assign_helper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NLP1'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata = [['RT @DSC80: Text-cleaning is cool! #NLP https://t.co/xsfdw88d #NLP1 #NLP1']]\n",
    "test = hashtag_list(pd.DataFrame(testdata, columns=['text'])['text'])\n",
    "most_common_hashtag(test).iloc[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 5 (Features)**\n",
    "\n",
    "Now create a dataframe of features from the `ira` data.  That is create a function `create_features` that takes in the `ira` data and returns a dataframe with the same index as `ira` (i.e. the rows correspond to the same tweets) and the following columns:\n",
    "* `num_hashtags` gives the number of hashtags present in a tweet,\n",
    "* `mc_hashtags` gives the most common hashtag associated to a tweet (as given by the problem above),\n",
    "* `num_tags` gives the number of tags a given tweet has (look for the presence of `@`),\n",
    "* `num_links` gives the number of hyper-links present in a given tweet \n",
    "    - (a hyper-link is a string starting with `http(s)://` not followed by whitespaces),\n",
    "* A boolean column `is_retweet` that describes if the given tweet is a retweet (i.e. `RT`),\n",
    "* A 'clean' text field `text` that contains the tweet text with:\n",
    "    - The non-alphanumeric characters removed (except spaces),\n",
    "    - All words should be separated by exactly one space,\n",
    "    - The characters all lowercase,\n",
    "    - All the meta-information above (Retweet info, tags, hyperlinks, hashtags) removed.\n",
    "\n",
    "*Note:* You should make a helper function for each column.\n",
    "\n",
    "*Note:* This will take a while to run on the entire dataset -- test it on a small sample first!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>name</th>\n",
       "      <th>date</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3906258</td>\n",
       "      <td>ea85ac8be1e8ab479064ca4c0fe3ac6587f76b1ef97452...</td>\n",
       "      <td>2016-11-16 09:04</td>\n",
       "      <td>The Best Exercise To Lose Belly Fat In 2 weeks...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1051443</td>\n",
       "      <td>8e58ab0f46d273103d9e71aa92cdaffb6e330ec7d15ae5...</td>\n",
       "      <td>2016-12-24 04:31</td>\n",
       "      <td>RT @Philanthropy: Dozens of hate groups have...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2823399</td>\n",
       "      <td>Room Of Rumor</td>\n",
       "      <td>2016-08-18 20:26</td>\n",
       "      <td>Artificial intelligence can find, map poverty,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>272878</td>\n",
       "      <td>San Francisco Daily</td>\n",
       "      <td>2016-03-18 19:28</td>\n",
       "      <td>Uber balks at rules proposed by worlds busies...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7697802</td>\n",
       "      <td>41bb9ae5991f53996752a0ab8dd36b543821abca8d5aed...</td>\n",
       "      <td>2016-07-30 15:44</td>\n",
       "      <td>RT @dirtroaddiva1: #IHatePokemonGoBecause he  ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               name  \\\n",
       "0  3906258  ea85ac8be1e8ab479064ca4c0fe3ac6587f76b1ef97452...   \n",
       "1  1051443  8e58ab0f46d273103d9e71aa92cdaffb6e330ec7d15ae5...   \n",
       "2  2823399                                      Room Of Rumor   \n",
       "3   272878                                San Francisco Daily   \n",
       "4  7697802  41bb9ae5991f53996752a0ab8dd36b543821abca8d5aed...   \n",
       "\n",
       "               date                                               text  \n",
       "0  2016-11-16 09:04  The Best Exercise To Lose Belly Fat In 2 weeks...  \n",
       "1  2016-12-24 04:31  RT @Philanthropy: Dozens of hate groups have...  \n",
       "2  2016-08-18 20:26  Artificial intelligence can find, map poverty,...  \n",
       "3  2016-03-18 19:28  Uber balks at rules proposed by worlds busies...  \n",
       "4  2016-07-30 15:44  RT @dirtroaddiva1: #IHatePokemonGoBecause he  ...  "
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ira.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prog = re.compile('^RT')\n",
    "prog.search('RT @DSC80: Text-cleaning is cool! #NLP https://t.co/xsfdw88d #NLP1 #NLP1') is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT @DSC80: Text-cleaning is cool! #NLP  #NLP1 #NLP1'"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('http(s)?://[^\\s]+','','RT @DSC80: Text-cleaning is cool! #NLP https://t.co/xsfdw88d #NLP1 #NLP1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT  Text-cleaning is cool! #NLP  #NLP1 #NLP1'"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('@+?([^\\s]+)', '', 'RT @DSC80: Text-cleaning is cool! #NLP  #NLP1 #NLP1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RT  Text-cleaning is cool!    '"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('#+?([^\\s]+)', '', 'RT  Text-cleaning is cool! #NLP  #NLP1 #NLP1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Text-cleaning is cool!    '"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub('^RT','','RT  Text-cleaning is cool!    ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  Text cleaning is cool     '"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "re.sub(r'[^\\w\\s]', ' ', '  Text-cleaning is cool!    ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text cleaning is cool'"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'  Text cleaning is cool     '.lower().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ht_cnt(row):\n",
    "    hashtags = re.findall('(?<=#)+?([^\\s])',row)\n",
    "    return len(hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mc_ht(row):\n",
    "    ht = re.findall('(?<=#)+?([^\\s]+)',row)\n",
    "    data = pd.Series(ht)\n",
    "    if len(data) == 0:\n",
    "        return np.NaN\n",
    "    elif len(data.unique()) == 1:\n",
    "        return data[0]\n",
    "    else:\n",
    "        return data.value_counts().index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_cnt(row):\n",
    "    tags = re.findall('(?<=@)+?([^\\s]+)',row)\n",
    "    return len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_cnt(row):\n",
    "    tags = re.findall('http(s)?://[^\\s]+',row)\n",
    "    return len(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rt_helper(row):\n",
    "    prog = re.compile('^RT')\n",
    "    return prog.search(row) is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cleaner(row):\n",
    "    s = re.sub('http(s)?://[^\\s]+', '', row)\n",
    "    s = re.sub('@+?([^\\s]+)', '', s)\n",
    "    s = re.sub('#+?([^\\s]+)', '', s)\n",
    "    s = re.sub('^RT', '', s)\n",
    "    s = re.sub(r'[^\\w\\s]', ' ', s)\n",
    "    s = s.lower().strip()\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_features(ira):\n",
    "    \"\"\"\n",
    "    :Example:\n",
    "    >>> testdata = [['RT @DSC80: Text-cleaning is cool! #NLP https://t.co/xsfdw88d #NLP1 #NLP1']]\n",
    "    >>> test = pd.DataFrame(testdata, columns=['text'])\n",
    "    >>> out = create_features(test)\n",
    "    >>> anscols = ['text', 'num_hashtags', 'mc_hashtags', 'num_tags', 'num_links', 'is_retweet']\n",
    "    >>> ansdata = [['text cleaning is cool', 3, 'NLP1', 1, 1, True]]\n",
    "    >>> ans = pd.DataFrame(ansdata, columns=anscols)\n",
    "    >>> (out == ans).all().all()\n",
    "    True\n",
    "    \"\"\"\n",
    "    \n",
    "    num_hashtags = ira['text'].apply(ht_cnt)\n",
    "    mc_hashtags = ira['text'].apply(mc_ht)\n",
    "    num_tags = ira['text'].apply(tag_cnt)\n",
    "    num_links = ira['text'].apply(link_cnt)\n",
    "    is_retweet = ira['text'].apply(rt_helper)\n",
    "    text = ira['text'].apply(cleaner)\n",
    "    \n",
    "    df_dict = {'text':text, 'num_hashtags':num_hashtags, 'mc_hashtags':mc_hashtags, 'num_tags':num_tags, 'num_links':num_links, 'is_retweet':is_retweet}\n",
    "    df = pd.DataFrame(df_dict)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RT @DSC80: Text-cleaning is cool! #NLP https:/...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  RT @DSC80: Text-cleaning is cool! #NLP https:/..."
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testdata = [['RT @DSC80: Text-cleaning is cool! #NLP https://t.co/xsfdw88d #NLP1 #NLP1']]\n",
    "test = pd.DataFrame(testdata, columns=['text'])\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>num_hashtags</th>\n",
       "      <th>mc_hashtags</th>\n",
       "      <th>num_tags</th>\n",
       "      <th>num_links</th>\n",
       "      <th>is_retweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>text cleaning is cool</td>\n",
       "      <td>3</td>\n",
       "      <td>NLP1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    text  num_hashtags mc_hashtags  num_tags  num_links  \\\n",
       "0  text cleaning is cool             3        NLP1         1          1   \n",
       "\n",
       "   is_retweet  \n",
       "0        True  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = create_features(test)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "anscols = ['text', 'num_hashtags', 'mc_hashtags', 'num_tags', 'num_links', 'is_retweet']\n",
    "ansdata = [['text cleaning is cool', 3, 'NLP1', 1, 1, True]]\n",
    "ans = pd.DataFrame(ansdata, columns=anscols)\n",
    "(out == ans).all().all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Congratulations! You're done!\n",
    "\n",
    "* Submit the lab on Gradescope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "toc-autonumbering": true
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
