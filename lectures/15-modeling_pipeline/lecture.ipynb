{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# set defaults\n",
    "plt.style.use('seaborn-white')   # seaborn custom plot style\n",
    "plt.rc('figure', dpi=100, figsize=(7, 5))   # set default size/resolution\n",
    "plt.rc('font', size=12)   # font size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The modeling pipeline\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"imgs/image_0.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### The steps of the modeling pipeline\n",
    "\n",
    "1. Create features to best reflect the meaning behind data\n",
    "2. Create model appropriate to capture relationships between features\n",
    "    - e.g. linear, non-linear\n",
    "3. Select a loss function and fit the model (determine $\\hat{\\theta}$).\n",
    "4. Evaluate model (e.g. using RMSE)\n",
    "\n",
    "After these steps, use the model for prediction and/or inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Software development and the modeling pipeline \n",
    "\n",
    "* Each step may contain complicated transformations and logic\n",
    "* The pipeline above represents a single attempt at a model\n",
    "    - May have thousands of feature/model/paramater combinations to choose from!\n",
    "    - Remember the Data Science Life Cycle!\n",
    "* ML pipelines: [the high interest credit card of technical debt](https://ai.google/research/pubs/pub43146)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Features and Models using `Scikit Learn`\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "    \n",
    "* Scikit-Learn implements many common steps in the feature/model creation pipeline.\n",
    "* Interfaces with `numpy` arrays and Pandas dataframes (somewhat)\n",
    "    - Some work required keeping track of columns in scikit\n",
    "    \n",
    "    \n",
    "<img src=\"imgs/sklearn.png\" width=\"50%\"/>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scikit-Learn feature transformers\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "\n",
    "<img src=\"imgs/feature_part.png\" width=\"50%\">\n",
    "\n",
    "<img src=\"imgs/image_1.png\" width=\"50%\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Scikit-Learn (linear) models\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "\n",
    "<img src=\"imgs/model_part.png\" width=\"50%\">\n",
    "\n",
    "\n",
    "<img src=\"imgs/image_2.png\" width=\"50%\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Note...\n",
    "\n",
    "- `sklearn` documentation is (usually) very, *very* good\n",
    "- there's a lot to learn, but lots of examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scikit-Learn Transformer Classes\n",
    "\n",
    "* Transformers process data and output features (transformed data).\n",
    "    - Input data should be a (multi-column) Numpy Array (`sklearn` coerces a dataframe using `.values`).\n",
    "    - Output data is also a Numpy Array.\n",
    "\n",
    "|Property|Example|Description|\n",
    "|---|---|---|\n",
    "|Initialize with parameters| `binar = Binarizer(thresh)` | 'set x=0 if x < thresh, else 1'|\n",
    "|Transform data in a dataset | `feat = binar.transform(data)` | Binarize all columns in `data`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>tip</th>\n",
       "      <th>sex</th>\n",
       "      <th>smoker</th>\n",
       "      <th>day</th>\n",
       "      <th>time</th>\n",
       "      <th>size</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>1.01</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>1.66</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3.50</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>3.31</td>\n",
       "      <td>Male</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>3.61</td>\n",
       "      <td>Female</td>\n",
       "      <td>No</td>\n",
       "      <td>Sun</td>\n",
       "      <td>Dinner</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill   tip     sex smoker  day    time  size\n",
       "0       16.99  1.01  Female     No  Sun  Dinner     2\n",
       "1       10.34  1.66    Male     No  Sun  Dinner     3\n",
       "2       21.01  3.50    Male     No  Sun  Dinner     3\n",
       "3       23.68  3.31    Male     No  Sun  Dinner     2\n",
       "4       24.59  3.61  Female     No  Sun  Dinner     4"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initialize the transformer and use it in the dataset\n",
    "from sklearn.preprocessing import Binarizer\n",
    "\n",
    "tips = sns.load_dataset('tips')\n",
    "tips.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.],\n",
       "       [0.],\n",
       "       [1.],\n",
       "       [1.],\n",
       "       [1.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bi = Binarizer(threshold = 20)                     # initialize with the parameter\n",
    "binarized = bi.transform(tips[['total_bill']])     # called transform on a data \n",
    "binarized[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 700x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# check if works\n",
    "# \n",
    "(\n",
    "    pd.concat([tips.total_bill, pd.DataFrame(binarized, columns=['binarized'])], axis=1)\n",
    "    .sort_values('total_bill')\n",
    "    .plot(x='total_bill', y='binarized')\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Some transformer classes require fitting\n",
    "\n",
    "* Transformation logic often requires some knowledge of the dataset before transforming.\n",
    "    - z-score: z = (x-μ)/σ, where x is the raw score, μ is the population mean, and σ is the population standard deviation.\n",
    "* These transformers must be *fit* to the data before use.\n",
    "* Typical usage: fit transformer on a sample; use that fit transformer to transform future data.\n",
    "\n",
    "\n",
    "|Property|Example|Description|\n",
    "|---|---|---|\n",
    "|Initialize with parameters| `stdscaler = StandardScaler()` | z-scale the data (no parameters) |\n",
    "|Fit the transformer| `stdscaler.fit(data)` | compute the mean and std-dev of `data`|\n",
    "|Transform data in a dataset | `feat = stdscaler.transform(newdata)` | z-scale `newdata` with mean/stdev of `data`|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_bill</th>\n",
       "      <th>size</th>\n",
       "      <th>tip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16.99</td>\n",
       "      <td>2</td>\n",
       "      <td>1.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10.34</td>\n",
       "      <td>3</td>\n",
       "      <td>1.66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>21.01</td>\n",
       "      <td>3</td>\n",
       "      <td>3.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23.68</td>\n",
       "      <td>2</td>\n",
       "      <td>3.31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>24.59</td>\n",
       "      <td>4</td>\n",
       "      <td>3.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   total_bill  size   tip\n",
       "0       16.99     2  1.01\n",
       "1       10.34     3  1.66\n",
       "2       21.01     3  3.50\n",
       "3       23.68     2  3.31\n",
       "4       24.59     4  3.61"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "tips = sns.load_dataset('tips')\n",
    "quantcols = ['total_bill', 'size', 'tip']\n",
    "tips[quantcols].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNotFittedError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-7-c1b9e8b546dc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# This doesn't work!\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mstdscaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtips\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mquantcols\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\jwang\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\preprocessing\\_data.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m    878\u001b[0m             \u001b[0mTransformed\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m         \"\"\"\n\u001b[1;32m--> 880\u001b[1;33m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m         \u001b[0mcopy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mcopy\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jwang\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\jwang\\appdata\\local\\programs\\python\\python39\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_is_fitted\u001b[1;34m(estimator, attributes, msg, all_or_any)\u001b[0m\n\u001b[0;32m   1096\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1097\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1098\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mNotFittedError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'name'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1099\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1100\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNotFittedError\u001b[0m: This StandardScaler instance is not fitted yet. Call 'fit' with appropriate arguments before using this estimator."
     ]
    }
   ],
   "source": [
    "# This doesn't work!\n",
    "stdscaler.transform(tips[quantcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stdscaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler.fit(tips[quantcols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler.mean_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stdscaler.var_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# z-scaled data\n",
    "stdscaler.transform(tips[quantcols])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Example: One-Hot Encoding\n",
    "\n",
    "- `sklearn` provides a preprocessor to compute One-Hot encoding for categoricals\n",
    "- last time, we code to do this by hand : ("
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# just categoricals\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "tips_cat = ['sex', 'smoker', 'day', 'time']\n",
    "regdata = tips[tips_cat]\n",
    "regdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder()  # create\n",
    "ohe.fit(regdata)       # fit to data\n",
    "ohe.categories_        # you can look into created categories ="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ohe.transform(regdata)  # why toarray()? to avoid sparse matrix!\n",
    "features[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe.inverse_transform(features[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Scikit-Learn Model Classes\n",
    "\n",
    "`Sklearn` model classes (estimators) behave like transformers, but use outcomes (target variables, dependent variables that you train your model on) to fit and evaluate.\n",
    "\n",
    "|Property|Example|Description|\n",
    "|---|---|---|\n",
    "|Initialize model parameters| `lr = LinearRegression()` | Create (empty) linear regression model|\n",
    "|Fit the model to the data | `lr.fit(data, outcomes)` | Determines regression coefficients|\n",
    "|Use model for prediction |`lr.predict(newdata)`| Use regression line make predictions|\n",
    "|Evaluate the model| `lr.score(data, outcomes)` | Calculate the $R^2$ of the LR model|\n",
    "|Access model attributes| `lr.coef_` | Access the regression coefficients|\n",
    "\n",
    "*Note:* Once `fit`, estimators are just transformers (`predict` <-> `transform`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(tips[['total_bill', 'size']], tips.tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can predict with it\n",
    "lr.predict(tips[['total_bill', 'size']])[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression coefficients, why 2 slopes?\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Building models with transformers and estimators\n",
    "\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "    \n",
    "1. Define your transformations; models.\n",
    "1. Transform input data to features.\n",
    "1. Use (transformed) features to fit model.\n",
    "1. Predict outcomes from features using fit model.\n",
    "\n",
    "<img src=\"imgs/image_0.png\" width=\"50%\"/>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.toarray()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# multicollinearity\n",
    "# which variables should be dropped?\n",
    "ohe.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(features, tips.tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# higher dim. plane of best fit in 10 dim  (slopes)\n",
    "lr.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lr.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RMSE: terrible model! (why?)\n",
    "np.sqrt(np.mean((preds - tips.tip.values)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add predictions to original data\n",
    "tips.assign(preds=preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Redundant Features\n",
    "\n",
    "- For any categorical feature, can always leave out one of the categories (inferred from the rest).\n",
    "- E.g., \"Yes\" and \"No\". Just have binary feature: \"Yes\".\n",
    "- Done with `drop='first'` in `OneHotEncoder`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_better = OneHotEncoder(drop='first')\n",
    "features = ohe_better.fit_transform(tips[tips_cat])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_better.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(features, tips.tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = lr.predict(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# doesn't affect RMSE, but makes the individual weights on features more stable\n",
    "np.sqrt(np.mean((preds - tips.tip.values)**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The \"entire model\"\n",
    "\n",
    "- The \"entire\" model is the combination of all preprocessing + estimation done to the raw data.\n",
    "- `sklearn` allows you to combine your preprocessing + estimation into a single \"pipeline\" object."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Putting it together: Scikit-Learn Pipelines\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "\n",
    "* Put together transformers and models using `sklearn.Pipeline`.\n",
    "* Create a pipeline: `pl = Pipeline([feat_trans, mdl])`\n",
    "* Fit *all* the transformer(s)/model(s) in the pipeline using `pl.fit(data, target)`\n",
    "* Predict from *raw* input data through the pipeline using `pl.predict`.\n",
    "* Note: a fit pipeline is also a transformer!\n",
    "\n",
    "<img src=\"imgs/image_0.png\" width=\"50%\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pass a list of feature trans. and models, in sequence.\n",
    "# does all fitting and transforming\n",
    "\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pipelines are lists of steps: each is a transformation/estimator\n",
    "# each transformation is a tuple: the 'name' for the step name, and the transformer/estimator object.\n",
    "pl = Pipeline([\n",
    "    ('one-hot', OneHotEncoder()),\n",
    "    ('lin-reg', LinearRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regdata.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.fit(regdata, tips.tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inspect the 'steps' of the pipeline using .named_steps\n",
    "# gives a dictionary\n",
    "# key: name you gave\n",
    "# values: fit pipleline objects\n",
    "pl.named_steps['one-hot'].transform(regdata).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.named_steps['one-hot'].categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.predict(regdata)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# R^2 -- still terrible! (1 is good, 0 is bad)\n",
    "pl.score(regdata, tips.tip)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### (Realistic) Sklearn Pipelines\n",
    "<div class=\"image-txt-container\">\n",
    "    \n",
    "* `ColumnTransformer` was a recent addition (2018).\n",
    "* Transforms using multiple transformers, each on different columns.\n",
    "* `ColumnTransformer` performs the transformations and concatenates the output (axis=1).\n",
    "\n",
    "<img src=\"imgs/image_3.png\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import sklearn.preprocessing as pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. split data up into quant. and cat. features\n",
    "# 2. z-scale for quant features\n",
    "# 3. One-hot encode for cat. features\n",
    "# 4. Two pipelines\n",
    "# 5. Use column transformer to put everything back\n",
    "# 6. Apply the model => predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tips.drop(['tip', 'total_bill', 'size'], axis=1).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numeric columns and associated transformers\n",
    "num_feat = ['total_bill', 'size']\n",
    "num_transformer = Pipeline(steps=[\n",
    "    ('scaler', pp.StandardScaler())   # z-scale\n",
    "])\n",
    "\n",
    "# Categorical columns and associated transformers\n",
    "cat_feat = ['sex', 'smoker', 'day', 'time']\n",
    "cat_transformer = Pipeline(steps=[\n",
    "    ('onehot', pp.OneHotEncoder())     # output from Ordinal becomes input to OneHot\n",
    "])\n",
    "\n",
    "# preprocessing pipeline (put them together)\n",
    "preproc = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_transformer, num_feat),\n",
    "        ('cat', cat_transformer, cat_feat)\n",
    "    ])\n",
    "\n",
    "pl = Pipeline(steps=[('preprocessor', preproc), ('regressor', LinearRegression())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.fit(tips.drop('tip', axis=1), tips.tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = pl.predict(tips.drop('tip', axis=1))\n",
    "preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sqrt(np.mean((preds - tips.tip)**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.score(tips.drop('tip', axis=1), tips.tip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.named_steps['preprocessor'].transform(tips.drop('tip', axis=1)).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating the fit model\n",
    "\n",
    "\n",
    "\n",
    "<img src=\"imgs/image_4.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating the quality of a model\n",
    "\n",
    "* Given a fit regressor on dataset, calculate e.g. the root-mean-square error.\n",
    "* If the error is low, do you think it's a good model?\n",
    "    - It fits the given *data* well, but is it a good model? (Is the sample representative?)\n",
    "    - Will it give good predictions on similar, unknown, data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Fundamental Concepts of the quality of a 'fit model'\n",
    "\n",
    "* **Bias**: the expected deviation between the predicted value and true value\n",
    "* **Variance**: \n",
    "    - **Observation Variance**: the variability of the random noise in the process we are trying to model. \n",
    "    - **Estimated Model Variance**: the variability in the predicted value across different datasets. (Does the model generalize?)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Model Quality: Bias and Variance\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "    \n",
    "* The red bulls-eye: the true behavior of DGP\n",
    "* Each dart: a specific function that models/predicts the DGP\n",
    "* The model parameters $\\theta$ select these functions.\n",
    "* Credit: Scott Fortmann-Roe\n",
    "    \n",
    "<img src=\"imgs/image_5.png\" width=\"100%\">\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating the quality of a linear model\n",
    "\n",
    "Given a dataset on which to fit the regression coefficients:\n",
    "1. Calculate the RMSE to test for bias.\n",
    "2. To test for variance, bootstrap estimate the regression coefficients:\n",
    "    - sample the data.\n",
    "    - For each sample, calculate the linear predictor.\n",
    "    - For each input feature, calculate the CI for the distribution of predictions.\n",
    "    - Large \"prediction intervals\" imply the model is susceptible to noise (e.g. outliers)\n",
    "    \n",
    "Still, this relies on a \"representative sample\" for generalization to new data!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lmplot(data=tips, x='total_bill', y='tip');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating the quality of a (general) model\n",
    "\n",
    "* Given a fit (non-linear) model, there are three possibilities for quality:\n",
    "    - The model doesn't fit the given data well (high bias; underfit)\n",
    "    - Does it reflect the process of interest? (good fit; robust)\n",
    "    - Does it just fit the data (noise and all)? (high variance; overfit)\n",
    "\n",
    "* How can we ascertain the quality on similar, out-of-sample data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Evaluating the quality of a (general) model\n",
    "\n",
    "* Given a quadratic process, a linear model has high bias.\n",
    "* \"Connecting-the-dots\" will fail to generalize (high variance).\n",
    "* Balance model complexity with complexity of DGP.\n",
    "\n",
    "![overfit](imgs/under-over-fit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example: predicting survival on the Titanic with Decision Trees\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "\n",
    "* Did a given passenger survive the Titanic distaster?\n",
    "* The (simple) tree below has mediocre accuracy\n",
    "\n",
    "<img src=\"imgs/image_6.png\" width=\"50%\">\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Reducing Bias with more complicated models\n",
    "\n",
    "* Improve performance by \"growing\" the decision tree model.\n",
    "* Decrease the number of passengers required in leaf nodes.\n",
    "* Effect: \"Learn\" individual passengers?\n",
    "* How do the know your model generalizes?\n",
    "\n",
    "<img src=\"imgs/Titanic_Decision_Tree.png\" width=\"100%\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Train-Test Split\n",
    "\n",
    "To assess your model for overfitting to the data, randomly split the data into a \"training set\" and a \"test set\".\n",
    "\n",
    "<div class=\"image-txt-container\">\n",
    "\n",
    "* The training set is used to fit the model (train the predictor).\n",
    "* The test set is used to test the goodness-of-fit of the fit model.\n",
    "* *similar* to bootstrap estimating a regression model.\n",
    "\n",
    "<img src=\"imgs/train-test.png\">\n",
    "\n",
    "</div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## The machine learning training pipeline:\n",
    "\n",
    "<img src=\"imgs/train-test.png\" width=\"50%\">\n",
    "\n",
    "Scikit-Learn has functions that help us do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Using Scikit-Learn for train-test split\n",
    "\n",
    "* Splitting a dataset using `sklearn.model_selection.train_test_split` \n",
    "* Given features `X` and a target array `y`,\n",
    "```\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "```\n",
    "randomly splits the features and target into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = tips.drop('tip', axis=1)\n",
    "y = tips.tip\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\n",
    "    len(X_train)/len(X),\n",
    "    len(X_test)/len(X)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Example Prediction Pipeline\n",
    "\n",
    "* Train a simple linear regression model on the tips data\n",
    "* Split the data into a training and test set:\n",
    "    - fit the model on the training set\n",
    "    - compute the error on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = tips.drop(['tip', 'sex', 'smoker', 'day', 'time' ], axis=1)\n",
    "y = tips.tip\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n",
    "\n",
    "\n",
    "pl = Pipeline([\n",
    "   ('lin-reg', LinearRegression())\n",
    "])\n",
    "\n",
    "pl.fit(X_train, y_train)\n",
    "\n",
    "# performance on training data\n",
    "pred_train = pl.predict(X_train)\n",
    "rmse_train = np.sqrt(np.mean((pred_train - y_train)**2))\n",
    "\n",
    "# performance on test data -- what we really care about\n",
    "pred_test = pl.predict(X_test)\n",
    "rmse_test = np.sqrt(np.mean((pred_test - y_test)**2))\n",
    "\n",
    "print (\"train RMSE: %s\" % rmse_train)\n",
    "print (\"test RMSE: %s\" % rmse_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "### Conclusion: evaluating model fit\n",
    "\n",
    "* Complex models are required to model complex phenomena.\n",
    "* How can you tell a complex model isn't over-fitting to the data?\n",
    "    - Answer: split into a training set and a test set.\n",
    "- If test performance is << train performance, you've overfit"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  },
  "livereveal": {
   "scroll": true,
   "transition": "none"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
