{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DSC 80: Project 02\n",
    "\n",
    "### Checkpoint Due Date: Thursday, April 22 11:59:59 PM (Q1-5)\n",
    "\n",
    "### Final Due Date: Thursday, April 29 11:59:59 PM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Instructions\n",
    "\n",
    "This Jupyter Notebook contains the statements of the problems and provides code and markdown cells to display your answers to the problems.  \n",
    "* Like the lab, your coding work will be developed in the accompanying `projectXX.py` file, that will be imported into the current notebook. This code will be autograded.\n",
    "\n",
    "**Do not change the function names in the `*.py` file**\n",
    "- The functions in the `*.py` file are how your assignment is graded, and they are graded by their name. The dictionary at the end of the file (`GRADED FUNCTIONS`) contains the \"grading list\". The final function in the file allows your doctests to check that all the necessary functions exist.\n",
    "- If you changed something you weren't supposed to, just use git to revert!\n",
    "\n",
    "**Tips for developing in the .py file**:\n",
    "- Do not change the function names in the starter code; grading is done using these function names.\n",
    "- Do not change the docstrings in the functions. These are there to tell you if your work is on the right track!\n",
    "- You are encouraged to write your own additional functions to solve the HW! \n",
    "    - Developing in python usually consists of larger files, with many short functions.\n",
    "    - You may write your other functions in an additional `.py` file that you import in `projectXX.py` (much like we do in the notebook).\n",
    "- Always document your code!\n",
    "\n",
    "## Checkpoint Instructions\n",
    "\n",
    "* The checkpoint requires you to turn in **questions 1-5**; \n",
    "* **The checkpoint will be graded for *approximate* correctness: easier than the final tests; harder than the doctests.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T01:51:24.832772Z",
     "start_time": "2019-10-14T01:51:24.805738Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T01:51:25.681889Z",
     "start_time": "2019-10-14T01:51:24.834879Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import project02 as proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T01:51:26.042046Z",
     "start_time": "2019-10-14T01:51:25.685618Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# An Investigation into Flight Delays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The flights dataset\n",
    "\n",
    "The department of transportation has all flight delays for listed years on their [website](https://catalog.data.gov/dataset/airline-on-time-performance-and-causes-of-flight-delays-on-time-data). There are data for the years 1987 - 2018. See the description of columns in `data/columns.txt`.\n",
    "\n",
    "This project will look at a single year (2015) to keep the analysis \"simple\", which is available at the URL below (*NOT* on the data.gov site).\n",
    "\n",
    "\n",
    "* To download the flights dataset to your computer, use [this link](https://dsc80-fa19-data.s3-us-west-2.amazonaws.com/project02/flight-delays.zip), unzip the file, and place `flights.csv` in your project directory.\n",
    "\n",
    "* To download the dataset on `datahub.ucsd.edu` (this works on your computer as well!):\n",
    "    - Open the terminal in datahub (\"new > Terminal\")\n",
    "    - Change the directory to where you want your data (e.g. `cd [ASSIGNMENT_PATH]/data`)\n",
    "    - Download the unzipped dataset using these commands:\n",
    "        1. `wget https://dsc80-fa19-data.s3-us-west-2.amazonaws.com/project02/flight-delays.zip`\n",
    "        2. `unzip flight-delays.zip`\n",
    "    - `flights.csv` should be in the directory.\n",
    "    \n",
    "**NOTE: The unzipped files must be in the `project02/data` directory in order for the doctests to work!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating your datasets\n",
    "\n",
    "**Question 1**\n",
    "\n",
    "The flights dataset for 2015 is not small (~600MB). While you could likely load the entire dataset into Pandas on your laptop, if you wanted to work with more than one year, this would quickly become difficult (the data is available for 1987-2018). Therefore, we will filter down the dataset into two smaller files without ever reading the larger dataset fully into memory. We are going to create two smaller datasets:\n",
    "\n",
    "1. All flights arriving or departing from San Diego International Airport in 2015.\n",
    "    - You can find a list of all the airport codes in the United States [here](https://www.leonardsguide.com/us-airport-codes.shtml).\n",
    "2. All flights flown by either JetBlue or Southwest Airline in 2015.\n",
    "\n",
    "---\n",
    "\n",
    "To do this, you are going to use the `chunksize=N` keyword in Pandas `read_csv` to read the flights dataset in blocks of `N` lines. When you use this keyword argument, `pd.read_csv(fp, chunksize=N)` becomes a *iterator* that iterates through dataframes of length N until you have reached the end of the dataset. A typical pattern looks like:\n",
    "```\n",
    "L = pd.read_csv(filepath, chunksize=1000)\n",
    "for df in L:\n",
    "    process(df)\n",
    "```\n",
    "Where each `df` is a dataframe of length 1000. \n",
    "\n",
    "The processing you are going to do is:\n",
    "1. Iterate through the dataset, chunk-by-chunk,\n",
    "2. Filtering out rows of each chunk\n",
    "3. Incrementally add to a filtered csv file (since the data is perhaps too big to keep in memory). Keep in mind, if you want to keep writing to the same file, the mode='a' keyword in the `.to_csv` method can be helpful when calling it in the loop (a stands for 'append')\n",
    "\n",
    "---\n",
    "\n",
    "Write two functions that create the datasets below, using the 'chunking' pattern described above. Your functions should use `chunksize` of 10000.\n",
    "1. `get_san` which takes in a filepath containing all flights and a filepath where filtered dataset #1 is written. The function should return `None`.\n",
    "1. `get_jb_sw` which takes in a filepath containing all flights and a filepath where filtered dataset #2 is written. The function should return `None`.\n",
    "\n",
    "*Remark 1*: **Gradescope autograding servers are quite small and can't load this dataset into memory** -- so your code that reads in the large `flights.csv` dataset *must* work with chunks of the dataset one at a time to pass!\n",
    "\n",
    "*Remark 2:* You can check your work using the datasets included in the zip file!\n",
    "\n",
    "Remember to close your file properly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_san(infp, outfp):\n",
    "    \"\"\"\n",
    "    get_san takes in a filepath containing all flights and a filepath where\n",
    "    filtered dataset #1 is written (that is, all flights arriving or departing\n",
    "    from San Diego International Airport in 2015).\n",
    "    The function should return None.\n",
    "\n",
    "    :Example:\n",
    "    >>> infp = os.path.join('data', 'flights.test')\n",
    "    >>> outfp = os.path.join('data', 'santest.tmp')\n",
    "    >>> get_san(infp, outfp)\n",
    "    >>> df = pd.read_csv(outfp)\n",
    "    >>> df.shape\n",
    "    (53, 31)\n",
    "    >>> os.remove(outfp)\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    \n",
    "    chunk = pd.read_csv(infp, chunksize=1000)\n",
    "    \n",
    "    for df in chunk:\n",
    "        chunkdf = df.loc[(df['ORIGIN_AIRPORT'] == 'SAN') | (df['DESTINATION_AIRPORT'] == 'SAN')]\n",
    "        dfs.append(chunkdf)\n",
    "        \n",
    "    concatted = pd.concat(dfs)\n",
    "    formatted = concatted.reset_index(drop=True)\n",
    "    formatted.to_csv(outfp,index=False)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "infp = os.path.join('data', 'flights.test')\n",
    "outfp = os.path.join('data', 'santest.tmp')\n",
    "get_san(infp, outfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df=pd.read_csv(infp)\n",
    "#df.loc[(df['ORIGIN_AIRPORT'] == 'SAN') | (df['DESTINATION_AIRPORT'] == 'SAN')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(outfp)\n",
    "#df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(53, 31)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(outfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sw_jb(infp, outfp):\n",
    "    \"\"\"\n",
    "    get_sw_jb takes in a filepath containing all flights and a filepath where\n",
    "    filtered dataset #2 is written (that is, all flights flown by either\n",
    "    JetBlue or Southwest Airline in 2015).\n",
    "    The function should return None.\n",
    "\n",
    "    :Example:\n",
    "    >>> infp = os.path.join('data', 'flights.test')\n",
    "    >>> outfp = os.path.join('data', 'jbswtest.tmp')\n",
    "    >>> get_sw_jb(infp, outfp)\n",
    "    >>> df = pd.read_csv(outfp)\n",
    "    >>> df.shape\n",
    "    (73, 31)\n",
    "    >>> os.remove(outfp)\n",
    "    \"\"\"\n",
    "    \n",
    "    airlines = ['JB','SW']\n",
    "    dfs = []\n",
    "    \n",
    "    chunk = pd.read_csv(infp, chunksize=1000)\n",
    "    \n",
    "    for df in chunk:\n",
    "        chunkdf = df.loc[(df['YEAR'] == 2015)]\n",
    "        chunkdf = df.loc[(chunkdf['AIRLINE'] == 'B6') | (chunkdf['AIRLINE'] == 'WN')]\n",
    "        dfs.append(chunkdf)\n",
    "    \n",
    "    sw_jb = pd.concat(dfs)\n",
    "    sw_jb = sw_jb.reset_index(drop = True)\n",
    "    \n",
    "    chunkdf.to_csv(outfp,index=False)\n",
    "    \n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "infp = os.path.join('data', 'flights.test')\n",
    "outfp = os.path.join('data', 'jbswtest.tmp')\n",
    "get_sw_jb(infp, outfp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(outfp)\n",
    "#df#.AIRLINE.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73, 31)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.remove(outfp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Flight Delays to/from San Diego\n",
    "\n",
    "The department of transportation has all flight delays for listed years on their [website](https://catalog.data.gov/dataset/airline-on-time-performance-and-causes-of-flight-delays-on-time-data). \n",
    "\n",
    "The zip file at the [URL](https://dsc80-fa19-data.s3-us-west-2.amazonaws.com/project02/flight-delays.zip) contains a file `to_from_san.csv` that consists of all flights either to or from SAN (San Diego) in 2015 -- i.e. the output of Question 1. This dataset should match the dataset that your code returned in question 1.\n",
    "\n",
    "Read in `to_from_san.csv` using `read_csv` and inspect the dataframe for an initial assessment about the data quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T01:51:26.403770Z",
     "start_time": "2019-10-14T01:51:26.045071Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "to_from_san_filepath = os.path.join('data', 'to_from_san.csv')\n",
    "flights = pd.read_csv(to_from_san_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>FLIGHT_NUMBER</th>\n",
       "      <th>TAIL_NUMBER</th>\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>DESTINATION_AIRPORT</th>\n",
       "      <th>SCHEDULED_DEPARTURE</th>\n",
       "      <th>...</th>\n",
       "      <th>ARRIVAL_TIME</th>\n",
       "      <th>ARRIVAL_DELAY</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>CANCELLATION_REASON</th>\n",
       "      <th>AIR_SYSTEM_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>AIRLINE_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>DL</td>\n",
       "      <td>978</td>\n",
       "      <td>N693DL</td>\n",
       "      <td>SAN</td>\n",
       "      <td>SLC</td>\n",
       "      <td>615</td>\n",
       "      <td>...</td>\n",
       "      <td>906.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>OO</td>\n",
       "      <td>5608</td>\n",
       "      <td>N930SW</td>\n",
       "      <td>SAN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>615</td>\n",
       "      <td>...</td>\n",
       "      <td>702.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>823</td>\n",
       "      <td>N7707C</td>\n",
       "      <td>SAN</td>\n",
       "      <td>BWI</td>\n",
       "      <td>620</td>\n",
       "      <td>...</td>\n",
       "      <td>1352.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>603</td>\n",
       "      <td>N461WN</td>\n",
       "      <td>SAN</td>\n",
       "      <td>MDW</td>\n",
       "      <td>620</td>\n",
       "      <td>...</td>\n",
       "      <td>1201.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>UA</td>\n",
       "      <td>1192</td>\n",
       "      <td>N69804</td>\n",
       "      <td>SAN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>620</td>\n",
       "      <td>...</td>\n",
       "      <td>936.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140409</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>DL</td>\n",
       "      <td>1792</td>\n",
       "      <td>N1402A</td>\n",
       "      <td>SAN</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2230</td>\n",
       "      <td>...</td>\n",
       "      <td>511.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140410</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>UA</td>\n",
       "      <td>240</td>\n",
       "      <td>N30401</td>\n",
       "      <td>SAN</td>\n",
       "      <td>ORD</td>\n",
       "      <td>2235</td>\n",
       "      <td>...</td>\n",
       "      <td>405.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140411</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>DL</td>\n",
       "      <td>1366</td>\n",
       "      <td>N341NW</td>\n",
       "      <td>SAN</td>\n",
       "      <td>DTW</td>\n",
       "      <td>2245</td>\n",
       "      <td>...</td>\n",
       "      <td>530.0</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140412</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>UA</td>\n",
       "      <td>498</td>\n",
       "      <td>N37267</td>\n",
       "      <td>SFO</td>\n",
       "      <td>SAN</td>\n",
       "      <td>2252</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140413</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>OO</td>\n",
       "      <td>5611</td>\n",
       "      <td>N116SY</td>\n",
       "      <td>LAX</td>\n",
       "      <td>SAN</td>\n",
       "      <td>2300</td>\n",
       "      <td>...</td>\n",
       "      <td>2350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140414 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        YEAR  MONTH  DAY  DAY_OF_WEEK AIRLINE  FLIGHT_NUMBER TAIL_NUMBER  \\\n",
       "0       2015      1    1            4      DL            978      N693DL   \n",
       "1       2015      1    1            4      OO           5608      N930SW   \n",
       "2       2015      1    1            4      WN            823      N7707C   \n",
       "3       2015      1    1            4      WN            603      N461WN   \n",
       "4       2015      1    1            4      UA           1192      N69804   \n",
       "...      ...    ...  ...          ...     ...            ...         ...   \n",
       "140409  2015     12   31            4      DL           1792      N1402A   \n",
       "140410  2015     12   31            4      UA            240      N30401   \n",
       "140411  2015     12   31            4      DL           1366      N341NW   \n",
       "140412  2015     12   31            4      UA            498      N37267   \n",
       "140413  2015     12   31            4      OO           5611      N116SY   \n",
       "\n",
       "       ORIGIN_AIRPORT DESTINATION_AIRPORT  SCHEDULED_DEPARTURE  ...  \\\n",
       "0                 SAN                 SLC                  615  ...   \n",
       "1                 SAN                 LAX                  615  ...   \n",
       "2                 SAN                 BWI                  620  ...   \n",
       "3                 SAN                 MDW                  620  ...   \n",
       "4                 SAN                 DEN                  620  ...   \n",
       "...               ...                 ...                  ...  ...   \n",
       "140409            SAN                 ATL                 2230  ...   \n",
       "140410            SAN                 ORD                 2235  ...   \n",
       "140411            SAN                 DTW                 2245  ...   \n",
       "140412            SFO                 SAN                 2252  ...   \n",
       "140413            LAX                 SAN                 2300  ...   \n",
       "\n",
       "        ARRIVAL_TIME  ARRIVAL_DELAY  DIVERTED  CANCELLED  CANCELLATION_REASON  \\\n",
       "0              906.0          -10.0         0          0                  NaN   \n",
       "1              702.0           -5.0         0          0                  NaN   \n",
       "2             1352.0          -23.0         0          0                  NaN   \n",
       "3             1201.0          -29.0         0          0                  NaN   \n",
       "4              936.0           -9.0         0          0                  NaN   \n",
       "...              ...            ...       ...        ...                  ...   \n",
       "140409         511.0          -13.0         0          0                  NaN   \n",
       "140410         405.0          -38.0         0          0                  NaN   \n",
       "140411         530.0          -34.0         0          0                  NaN   \n",
       "140412           6.0          -15.0         0          0                  NaN   \n",
       "140413        2350.0            0.0         0          0                  NaN   \n",
       "\n",
       "        AIR_SYSTEM_DELAY  SECURITY_DELAY  AIRLINE_DELAY  LATE_AIRCRAFT_DELAY  \\\n",
       "0                    NaN             NaN            NaN                  NaN   \n",
       "1                    NaN             NaN            NaN                  NaN   \n",
       "2                    NaN             NaN            NaN                  NaN   \n",
       "3                    NaN             NaN            NaN                  NaN   \n",
       "4                    NaN             NaN            NaN                  NaN   \n",
       "...                  ...             ...            ...                  ...   \n",
       "140409               NaN             NaN            NaN                  NaN   \n",
       "140410               NaN             NaN            NaN                  NaN   \n",
       "140411               NaN             NaN            NaN                  NaN   \n",
       "140412               NaN             NaN            NaN                  NaN   \n",
       "140413               NaN             NaN            NaN                  NaN   \n",
       "\n",
       "        WEATHER_DELAY  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                 NaN  \n",
       "...               ...  \n",
       "140409            NaN  \n",
       "140410            NaN  \n",
       "140411            NaN  \n",
       "140412            NaN  \n",
       "140413            NaN  \n",
       "\n",
       "[140414 rows x 31 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['YEAR', 'MONTH', 'DAY', 'DAY_OF_WEEK', 'AIRLINE', 'FLIGHT_NUMBER',\n",
       "       'TAIL_NUMBER', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT',\n",
       "       'SCHEDULED_DEPARTURE', 'DEPARTURE_TIME', 'DEPARTURE_DELAY', 'TAXI_OUT',\n",
       "       'WHEELS_OFF', 'SCHEDULED_TIME', 'ELAPSED_TIME', 'AIR_TIME', 'DISTANCE',\n",
       "       'WHEELS_ON', 'TAXI_IN', 'SCHEDULED_ARRIVAL', 'ARRIVAL_TIME',\n",
       "       'ARRIVAL_DELAY', 'DIVERTED', 'CANCELLED', 'CANCELLATION_REASON',\n",
       "       'AIR_SYSTEM_DELAY', 'SECURITY_DELAY', 'AIRLINE_DELAY',\n",
       "       'LATE_AIRCRAFT_DELAY', 'WEATHER_DELAY'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<class 'numpy.dtype[float64]'>\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "str(type(flights['ARRIVAL_TIME'].dtypes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         -4.0\n",
       "1         -1.0\n",
       "2          0.0\n",
       "3         -3.0\n",
       "4         -2.0\n",
       "          ... \n",
       "140409    -7.0\n",
       "140410     5.0\n",
       "140411   -14.0\n",
       "140412    -2.0\n",
       "140413     4.0\n",
       "Name: DEPARTURE_DELAY, Length: 139010, dtype: float64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.DEPARTURE_DELAY[flights.DEPARTURE_DELAY.notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the data types of the columns\n",
    "\n",
    "**Question 2**:\n",
    "\n",
    "* First, classify the *kind* of data each column in `flights` contains. Create a function `data_kinds` of zero variables which outputs a (hard-coded) dictionary of data kinds, keyed by column name, with values `Q`, `O`, `N` (for 'Quantitative', 'Ordinal', or 'Nominal').\n",
    "\n",
    "* Second, decide the best data *type* for each column. Create a function `data_types` of zero variables which outputs a (hard-coded) dictionary of data types, keyed by column name, with values `str`, `int`, `float`, `bool`. \n",
    "\n",
    "*Remark 1*: A column which *should* be `int`s, but contains `NaN`, *must* be a float column. See Lecture 2 notes an explanation of `NaN` and data-types.\n",
    "\n",
    "*Remark 2*: As with real data, some data processing decisions may be ambiguous here. Make the best decision using the information available to you. It may be helpful to (re)read the relevant [section of the textbook](https://afraenkel.github.io/practical-data-science/03/kinds-of-data.html). \n",
    "* Certain answers *may* have more than one correct answer (in these cases, more than one choice gets full credit),\n",
    "* All answers will be graded for partial credit (some wrong answers are more wrong than other).\n",
    "There are many columns, so don't worry about the correctness of any given one; do make sure you are thinking about what's contained in a column critically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_kinds():\n",
    "    \"\"\"\n",
    "    data_kinds outputs a (hard-coded) dictionary of data kinds, keyed by column\n",
    "    name, with values Q, O, N (for 'Quantitative', 'Ordinal', or 'Nominal').\n",
    "\n",
    "    :Example:\n",
    "    >>> out = data_kinds()\n",
    "    >>> isinstance(out, dict)\n",
    "    True\n",
    "    >>> set(out.values()) == {'O', 'N', 'Q'}\n",
    "    True\n",
    "    \"\"\"\n",
    "    #Qtypes = [\"<class 'pandas.core.series.Series'>\", \"<class 'numpy.dtype[float64]'>\"]\n",
    "    #data_dict = {col:'Q' for col in flights.columns if flights.col.dtypes in Qtypes}\n",
    "    return {'YEAR':'O', 'MONTH':'O', 'DAY':'O', 'DAY_OF_WEEK':'O', 'AIRLINE':'N', 'FLIGHT_NUMBER':'Q',\n",
    "       'TAIL_NUMBER':'N', 'ORIGIN_AIRPORT':'N', 'DESTINATION_AIRPORT':'N',\n",
    "       'SCHEDULED_DEPARTURE':'Q', 'DEPARTURE_TIME':'Q', 'DEPARTURE_DELAY':'Q', 'TAXI_OUT':'Q',\n",
    "       'WHEELS_OFF':'Q', 'SCHEDULED_TIME':'Q', 'ELAPSED_TIME':'Q', 'AIR_TIME':'Q', 'DISTANCE':'Q',\n",
    "       'WHEELS_ON':'Q', 'TAXI_IN':'Q', 'SCHEDULED_ARRIVAL':'Q', 'ARRIVAL_TIME':'Q',\n",
    "       'ARRIVAL_DELAY':'Q', 'DIVERTED':'Q', 'CANCELLED':'Q', 'CANCELLATION_REASON':'N',\n",
    "       'AIR_SYSTEM_DELAY':'Q', 'SECURITY_DELAY':'Q', 'AIRLINE_DELAY':'Q',\n",
    "       'LATE_AIRCRAFT_DELAY':'Q', 'WEATHER_DELAY':'Q'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'YEAR': 'O',\n",
       " 'MONTH': 'O',\n",
       " 'DAY': 'O',\n",
       " 'DAY_OF_WEEK': 'O',\n",
       " 'AIRLINE': 'N',\n",
       " 'FLIGHT_NUMBER': 'Q',\n",
       " 'TAIL_NUMBER': 'N',\n",
       " 'ORIGIN_AIRPORT': 'N',\n",
       " 'DESTINATION_AIRPORT': 'N',\n",
       " 'SCHEDULED_DEPARTURE': 'Q',\n",
       " 'DEPARTURE_TIME': 'Q',\n",
       " 'DEPARTURE_DELAY': 'Q',\n",
       " 'TAXI_OUT': 'Q',\n",
       " 'WHEELS_OFF': 'Q',\n",
       " 'SCHEDULED_TIME': 'Q',\n",
       " 'ELAPSED_TIME': 'Q',\n",
       " 'AIR_TIME': 'Q',\n",
       " 'DISTANCE': 'Q',\n",
       " 'WHEELS_ON': 'Q',\n",
       " 'TAXI_IN': 'Q',\n",
       " 'SCHEDULED_ARRIVAL': 'Q',\n",
       " 'ARRIVAL_TIME': 'Q',\n",
       " 'ARRIVAL_DELAY': 'Q',\n",
       " 'DIVERTED': 'Q',\n",
       " 'CANCELLED': 'Q',\n",
       " 'CANCELLATION_REASON': 'N',\n",
       " 'AIR_SYSTEM_DELAY': 'Q',\n",
       " 'SECURITY_DELAY': 'Q',\n",
       " 'AIRLINE_DELAY': 'Q',\n",
       " 'LATE_AIRCRAFT_DELAY': 'Q',\n",
       " 'WEATHER_DELAY': 'Q'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = data_kinds()\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(out, dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(out.values()) == {'O', 'N', 'Q'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19         0.0\n",
       "21         0.0\n",
       "27        88.0\n",
       "35         0.0\n",
       "40         0.0\n",
       "          ... \n",
       "140373    33.0\n",
       "140374    11.0\n",
       "140375    34.0\n",
       "140383     9.0\n",
       "140395     0.0\n",
       "Name: LATE_AIRCRAFT_DELAY, Length: 25257, dtype: float64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.LATE_AIRCRAFT_DELAY[flights.LATE_AIRCRAFT_DELAY.notna()]#.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.SCHEDULED_ARRIVAL.isnull().values.any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def data_types():\n",
    "    \"\"\"\n",
    "    data_types outputs a (hard-coded) dictionary of data types, keyed by column\n",
    "    name, with values str, int, float.\n",
    "\n",
    "    :Example:\n",
    "    >>> out = data_types()\n",
    "    >>> isinstance(out, dict)\n",
    "    True\n",
    "    >>> set(out.values()) == {'int', 'str', 'float', 'bool'}\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    return {'YEAR':'int', 'MONTH':'int', 'DAY':'int', 'DAY_OF_WEEK':'int', 'AIRLINE':'str', 'FLIGHT_NUMBER':'int',\n",
    "       'TAIL_NUMBER':'str', 'ORIGIN_AIRPORT':'str', 'DESTINATION_AIRPORT':'str',\n",
    "       'SCHEDULED_DEPARTURE':'int', 'DEPARTURE_TIME':'float', 'DEPARTURE_DELAY':'float', 'TAXI_OUT':'float',\n",
    "       'WHEELS_OFF':'float', 'SCHEDULED_TIME':'int', 'ELAPSED_TIME':'float', 'AIR_TIME':'float', 'DISTANCE':'int',\n",
    "       'WHEELS_ON':'float', 'TAXI_IN':'float', 'SCHEDULED_ARRIVAL':'int', 'ARRIVAL_TIME':'float',\n",
    "       'ARRIVAL_DELAY':'float', 'DIVERTED':'bool', 'CANCELLED':'bool', 'CANCELLATION_REASON':'str',\n",
    "       'AIR_SYSTEM_DELAY':'float', 'SECURITY_DELAY':'float', 'AIRLINE_DELAY':'float',\n",
    "       'LATE_AIRCRAFT_DELAY':'float', 'WEATHER_DELAY':'float'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'YEAR': 'int',\n",
       " 'MONTH': 'int',\n",
       " 'DAY': 'int',\n",
       " 'DAY_OF_WEEK': 'int',\n",
       " 'AIRLINE': 'str',\n",
       " 'FLIGHT_NUMBER': 'int',\n",
       " 'TAIL_NUMBER': 'str',\n",
       " 'ORIGIN_AIRPORT': 'str',\n",
       " 'DESTINATION_AIRPORT': 'str',\n",
       " 'SCHEDULED_DEPARTURE': 'int',\n",
       " 'DEPARTURE_TIME': 'float',\n",
       " 'DEPARTURE_DELAY': 'float',\n",
       " 'TAXI_OUT': 'float',\n",
       " 'WHEELS_OFF': 'float',\n",
       " 'SCHEDULED_TIME': 'int',\n",
       " 'ELAPSED_TIME': 'float',\n",
       " 'AIR_TIME': 'float',\n",
       " 'DISTANCE': 'int',\n",
       " 'WHEELS_ON': 'float',\n",
       " 'TAXI_IN': 'float',\n",
       " 'SCHEDULED_ARRIVAL': 'int',\n",
       " 'ARRIVAL_TIME': 'float',\n",
       " 'ARRIVAL_DELAY': 'float',\n",
       " 'DIVERTED': 'bool',\n",
       " 'CANCELLED': 'bool',\n",
       " 'CANCELLATION_REASON': 'str',\n",
       " 'AIR_SYSTEM_DELAY': 'float',\n",
       " 'SECURITY_DELAY': 'float',\n",
       " 'AIRLINE_DELAY': 'float',\n",
       " 'LATE_AIRCRAFT_DELAY': 'float',\n",
       " 'WEATHER_DELAY': 'float'}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = data_types()\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(out, dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(out.values()) == {'int', 'str', 'float', 'bool'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the typed flights data\n",
    "\n",
    "Read in the flights data using your dictionary of data-types in `read_csv`. This both speeds up parsing, as well as gives you the correct data-types upon reading (which columns would pandas *parse incorrectly* if you didn't use a `dtype` dictionary?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T01:51:26.410356Z",
     "start_time": "2019-10-14T01:51:24.819Z"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Run this cell\n",
    "dtypes = proj.data_types()\n",
    "flights = pd.read_csv(to_from_san_filepath, dtype=dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEAR</th>\n",
       "      <th>MONTH</th>\n",
       "      <th>DAY</th>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>FLIGHT_NUMBER</th>\n",
       "      <th>TAIL_NUMBER</th>\n",
       "      <th>ORIGIN_AIRPORT</th>\n",
       "      <th>DESTINATION_AIRPORT</th>\n",
       "      <th>SCHEDULED_DEPARTURE</th>\n",
       "      <th>...</th>\n",
       "      <th>ARRIVAL_TIME</th>\n",
       "      <th>ARRIVAL_DELAY</th>\n",
       "      <th>DIVERTED</th>\n",
       "      <th>CANCELLED</th>\n",
       "      <th>CANCELLATION_REASON</th>\n",
       "      <th>AIR_SYSTEM_DELAY</th>\n",
       "      <th>SECURITY_DELAY</th>\n",
       "      <th>AIRLINE_DELAY</th>\n",
       "      <th>LATE_AIRCRAFT_DELAY</th>\n",
       "      <th>WEATHER_DELAY</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>DL</td>\n",
       "      <td>978</td>\n",
       "      <td>N693DL</td>\n",
       "      <td>SAN</td>\n",
       "      <td>SLC</td>\n",
       "      <td>615</td>\n",
       "      <td>...</td>\n",
       "      <td>906.0</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>OO</td>\n",
       "      <td>5608</td>\n",
       "      <td>N930SW</td>\n",
       "      <td>SAN</td>\n",
       "      <td>LAX</td>\n",
       "      <td>615</td>\n",
       "      <td>...</td>\n",
       "      <td>702.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>823</td>\n",
       "      <td>N7707C</td>\n",
       "      <td>SAN</td>\n",
       "      <td>BWI</td>\n",
       "      <td>620</td>\n",
       "      <td>...</td>\n",
       "      <td>1352.0</td>\n",
       "      <td>-23.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>WN</td>\n",
       "      <td>603</td>\n",
       "      <td>N461WN</td>\n",
       "      <td>SAN</td>\n",
       "      <td>MDW</td>\n",
       "      <td>620</td>\n",
       "      <td>...</td>\n",
       "      <td>1201.0</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>UA</td>\n",
       "      <td>1192</td>\n",
       "      <td>N69804</td>\n",
       "      <td>SAN</td>\n",
       "      <td>DEN</td>\n",
       "      <td>620</td>\n",
       "      <td>...</td>\n",
       "      <td>936.0</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140409</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>DL</td>\n",
       "      <td>1792</td>\n",
       "      <td>N1402A</td>\n",
       "      <td>SAN</td>\n",
       "      <td>ATL</td>\n",
       "      <td>2230</td>\n",
       "      <td>...</td>\n",
       "      <td>511.0</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140410</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>UA</td>\n",
       "      <td>240</td>\n",
       "      <td>N30401</td>\n",
       "      <td>SAN</td>\n",
       "      <td>ORD</td>\n",
       "      <td>2235</td>\n",
       "      <td>...</td>\n",
       "      <td>405.0</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140411</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>DL</td>\n",
       "      <td>1366</td>\n",
       "      <td>N341NW</td>\n",
       "      <td>SAN</td>\n",
       "      <td>DTW</td>\n",
       "      <td>2245</td>\n",
       "      <td>...</td>\n",
       "      <td>530.0</td>\n",
       "      <td>-34.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140412</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>UA</td>\n",
       "      <td>498</td>\n",
       "      <td>N37267</td>\n",
       "      <td>SFO</td>\n",
       "      <td>SAN</td>\n",
       "      <td>2252</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140413</th>\n",
       "      <td>2015</td>\n",
       "      <td>12</td>\n",
       "      <td>31</td>\n",
       "      <td>4</td>\n",
       "      <td>OO</td>\n",
       "      <td>5611</td>\n",
       "      <td>N116SY</td>\n",
       "      <td>LAX</td>\n",
       "      <td>SAN</td>\n",
       "      <td>2300</td>\n",
       "      <td>...</td>\n",
       "      <td>2350.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>140414 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        YEAR  MONTH  DAY  DAY_OF_WEEK AIRLINE  FLIGHT_NUMBER TAIL_NUMBER  \\\n",
       "0       2015      1    1            4      DL            978      N693DL   \n",
       "1       2015      1    1            4      OO           5608      N930SW   \n",
       "2       2015      1    1            4      WN            823      N7707C   \n",
       "3       2015      1    1            4      WN            603      N461WN   \n",
       "4       2015      1    1            4      UA           1192      N69804   \n",
       "...      ...    ...  ...          ...     ...            ...         ...   \n",
       "140409  2015     12   31            4      DL           1792      N1402A   \n",
       "140410  2015     12   31            4      UA            240      N30401   \n",
       "140411  2015     12   31            4      DL           1366      N341NW   \n",
       "140412  2015     12   31            4      UA            498      N37267   \n",
       "140413  2015     12   31            4      OO           5611      N116SY   \n",
       "\n",
       "       ORIGIN_AIRPORT DESTINATION_AIRPORT  SCHEDULED_DEPARTURE  ...  \\\n",
       "0                 SAN                 SLC                  615  ...   \n",
       "1                 SAN                 LAX                  615  ...   \n",
       "2                 SAN                 BWI                  620  ...   \n",
       "3                 SAN                 MDW                  620  ...   \n",
       "4                 SAN                 DEN                  620  ...   \n",
       "...               ...                 ...                  ...  ...   \n",
       "140409            SAN                 ATL                 2230  ...   \n",
       "140410            SAN                 ORD                 2235  ...   \n",
       "140411            SAN                 DTW                 2245  ...   \n",
       "140412            SFO                 SAN                 2252  ...   \n",
       "140413            LAX                 SAN                 2300  ...   \n",
       "\n",
       "        ARRIVAL_TIME  ARRIVAL_DELAY  DIVERTED  CANCELLED  CANCELLATION_REASON  \\\n",
       "0              906.0          -10.0     False      False                  NaN   \n",
       "1              702.0           -5.0     False      False                  NaN   \n",
       "2             1352.0          -23.0     False      False                  NaN   \n",
       "3             1201.0          -29.0     False      False                  NaN   \n",
       "4              936.0           -9.0     False      False                  NaN   \n",
       "...              ...            ...       ...        ...                  ...   \n",
       "140409         511.0          -13.0     False      False                  NaN   \n",
       "140410         405.0          -38.0     False      False                  NaN   \n",
       "140411         530.0          -34.0     False      False                  NaN   \n",
       "140412           6.0          -15.0     False      False                  NaN   \n",
       "140413        2350.0            0.0     False      False                  NaN   \n",
       "\n",
       "        AIR_SYSTEM_DELAY  SECURITY_DELAY  AIRLINE_DELAY  LATE_AIRCRAFT_DELAY  \\\n",
       "0                    NaN             NaN            NaN                  NaN   \n",
       "1                    NaN             NaN            NaN                  NaN   \n",
       "2                    NaN             NaN            NaN                  NaN   \n",
       "3                    NaN             NaN            NaN                  NaN   \n",
       "4                    NaN             NaN            NaN                  NaN   \n",
       "...                  ...             ...            ...                  ...   \n",
       "140409               NaN             NaN            NaN                  NaN   \n",
       "140410               NaN             NaN            NaN                  NaN   \n",
       "140411               NaN             NaN            NaN                  NaN   \n",
       "140412               NaN             NaN            NaN                  NaN   \n",
       "140413               NaN             NaN            NaN                  NaN   \n",
       "\n",
       "        WEATHER_DELAY  \n",
       "0                 NaN  \n",
       "1                 NaN  \n",
       "2                 NaN  \n",
       "3                 NaN  \n",
       "4                 NaN  \n",
       "...               ...  \n",
       "140409            NaN  \n",
       "140410            NaN  \n",
       "140411            NaN  \n",
       "140412            NaN  \n",
       "140413            NaN  \n",
       "\n",
       "[140414 rows x 31 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 3 (Basic Stats):**\n",
    "\n",
    "Define a function `basic_stats` that takes a dataframe `flights` and outputs a dataframe that contains statistics for flights arriving/departing for SAN. That is, the output should have two rows, indexed by `ARRIVING` and `DEPARTING`, and have the following columns:\n",
    "\n",
    "1. The number of arriving/departing flights to/from SAN (`count`).\n",
    "    - If a flight scheduled to arrive at SAN never arrives, it still counts as an arriving flight.\n",
    "2. The mean flight (arrival) delay of arriving/departing flights to/from SAN (`mean_delay`).\n",
    "3. The median flight (arrival) delay of arriving/departing flights to/from SAN (`median_delay`).\n",
    "4. The airline code of the airline with the single longest flight (arrival) delay among all flights arriving/departing to/from SAN (`airline`).\n",
    "5. A list of the three months with the greatest number of arriving/departing flights to/from SAN, sorted from greatest to least (`top_months`).\n",
    "\n",
    "*Remark:* Null values should not be considered when computing statistics; however, think about whether e.g. the average flight delay is likely higher or lower that the \"true mean\" by making this choice.\n",
    "\n",
    "*Hint*: Use `groupbby` and the fact that `aggregate` can take in a dictionary as an argument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fromdf = flights.loc[flights['ORIGIN_AIRPORT'] == 'SAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "todf = flights.loc[flights['DESTINATION_AIRPORT'] == 'SAN']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([7, 8, 6], dtype='int64', name='MONTH')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fromdf.groupby('MONTH').count().sort_values('DAY',ascending=False).index[:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def basic_stats(flights):\n",
    "    \"\"\"\n",
    "    basic_stats takes flights and outputs a dataframe that contains statistics\n",
    "    for flights arriving/departing for SAN.\n",
    "    That is, the output should have have two rows, indexed by ARRIVING and\n",
    "    DEPARTING, and have the following columns:\n",
    "\n",
    "    * number of arriving/departing flights to/from SAN (count).\n",
    "    * mean flight (arrival) delay of arriving/departing flights to/from SAN\n",
    "      (mean_delay).\n",
    "    * median flight (arrival) delay of arriving/departing flights to/from SAN\n",
    "      (median_delay).\n",
    "    * the airline code of the airline with the longest flight (arrival) delay\n",
    "      among all flights arriving/departing to/from SAN (airline).\n",
    "    * a list of the three months with the greatest number of arriving/departing\n",
    "      flights to/from SAN, sorted from greatest to least (top_months).\n",
    "\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'to_from_san.csv')\n",
    "    >>> dtypes = data_types()\n",
    "    >>> flights = pd.read_csv(fp, dtype=dtypes)\n",
    "    >>> out = basic_stats(flights)\n",
    "    >>> out.index.tolist() == ['ARRIVING', 'DEPARTING']\n",
    "    True\n",
    "    >>> cols = ['count', 'mean_delay', 'median_delay', 'airline', 'top_months']\n",
    "    >>> out.columns.tolist() == cols\n",
    "    True\n",
    "    \"\"\"\n",
    "    from_sd = flights.loc[flights['ORIGIN_AIRPORT'] == 'SAN']\n",
    "    to_sd = flights.loc[flights['DESTINATION_AIRPORT'] == 'SAN']\n",
    "    \n",
    "    q1_dep = from_sd.shape[0]\n",
    "    q1_arr = to_sd.shape[0]\n",
    "    \n",
    "    q2_dep = from_sd['ARRIVAL_DELAY'].mean()\n",
    "    q2_arr = to_sd['ARRIVAL_DELAY'].mean()\n",
    "    \n",
    "    q3_dep = from_sd['ARRIVAL_DELAY'].median()\n",
    "    q3_arr = to_sd['ARRIVAL_DELAY'].median()\n",
    "    \n",
    "    q4_arr = from_sd.loc[from_sd['ARRIVAL_DELAY'] == from_sd['ARRIVAL_DELAY'].max()]['AIRLINE'].values[0]\n",
    "    q4_dep = to_sd.loc[to_sd['ARRIVAL_DELAY'] == to_sd['ARRIVAL_DELAY'].max()]['AIRLINE'].values[0]\n",
    "    \n",
    "    q5_dep = from_sd.groupby('MONTH').count().sort_values('DAY',ascending=False).index.tolist()[:3]\n",
    "    q5_arr = to_sd.groupby('MONTH').count().sort_values('DAY',ascending=False).index.tolist()[:3]\n",
    "    \n",
    "    df = pd.DataFrame({'count':[q1_arr,q1_dep], 'mean_delay':[q2_arr,q2_dep], 'median_delay':[q3_arr,q3_dep], 'airline':[q4_arr,q4_dep], 'top_months':[q5_dep,q5_arr]},index=['ARRIVING','DEPARTING'])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>mean_delay</th>\n",
       "      <th>median_delay</th>\n",
       "      <th>airline</th>\n",
       "      <th>top_months</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>ARRIVING</th>\n",
       "      <td>70207</td>\n",
       "      <td>3.676826</td>\n",
       "      <td>-4.0</td>\n",
       "      <td>AA</td>\n",
       "      <td>[7, 8, 6]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DEPARTING</th>\n",
       "      <td>70207</td>\n",
       "      <td>3.328988</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>AA</td>\n",
       "      <td>[7, 8, 6]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           count  mean_delay  median_delay airline top_months\n",
       "ARRIVING   70207    3.676826          -4.0      AA  [7, 8, 6]\n",
       "DEPARTING  70207    3.328988          -5.0      AA  [7, 8, 6]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'to_from_san.csv')\n",
    "dtypes = data_types()\n",
    "flights = pd.read_csv(fp, dtype=dtypes)\n",
    "out = basic_stats(flights)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.index.tolist() == ['ARRIVING', 'DEPARTING']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cols = ['count', 'mean_delay', 'median_delay', 'airline', 'top_months']\n",
    "out.columns.tolist() == cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding flight delays: Departures, Arrivals, and everything in-between\n",
    "\n",
    "**Question 4**\n",
    "\n",
    "Often `DEPARTURE_DELAY` is thought to be the main cause of a flight delay -- i.e., when the flight is late pushing off from the gate. \n",
    "\n",
    "However, there are other ways that flights can be late: waiting on the tarmac, headwinds, turbulence, circling a busy airport, and waiting for a gate after landing. First, we will analyze all the ways in which a flight can be delayed.\n",
    "\n",
    "* First, create a function `depart_arrive_stats` that takes in a dataframe like `flights` and calculates the following quantities in a series, indexed by `late1`, `late2`, `late3`:\n",
    "    - `late1`: the proportion of flights from/to SAN that leave late, but arrive early or on-time.\n",
    "    - `late2`: the proportion of flights from/to SAN that leave early, or on-time, but arrive late.\n",
    "    - `late3`: the proportion of flights from/to SAN that both left late and arrived late.\n",
    "    \n",
    "* Second, create a function `depart_arrive_stats_by_month` that takes in a dataframe like `flights` and calculates the quantities above broken down by *month*. That is, the output is a dataframe, indexed by `MONTH`, with columns given by `late1`, `late2`, `late3`.\n",
    "\n",
    "*Remark 1:* Does this question reveal any data quality issues? Can you pinpoint when these issues occur?\n",
    "\n",
    "*Remark 2:* A flight is considered late if it departed/arrived any time later than its planned departure/arrival time.\n",
    "\n",
    "*Remark 3:* You do not need to manually calculate the delay time for those delays that are `NaN`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19         0.0\n",
       "21         0.0\n",
       "27        88.0\n",
       "35         0.0\n",
       "40         0.0\n",
       "          ... \n",
       "140373    33.0\n",
       "140374    11.0\n",
       "140375    34.0\n",
       "140383     9.0\n",
       "140395     0.0\n",
       "Name: LATE_AIRCRAFT_DELAY, Length: 25257, dtype: float64"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.LATE_AIRCRAFT_DELAY[flights.LATE_AIRCRAFT_DELAY.notna()]#.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def depart_arrive_stats(flights):\n",
    "    \"\"\"\n",
    "    depart_arrive_stats takes in a dataframe like flights and calculates the\n",
    "    following quantities in a series (with the index in parentheses):\n",
    "    - The proportion of flights from/to SAN that\n",
    "      leave late, but arrive early or on-time (late1).\n",
    "    - The proportion of flights from/to SAN that\n",
    "      leaves early, or on-time, but arrives late (late2).\n",
    "    - The proportion of flights from/to SAN that\n",
    "      both left late and arrived late (late3).\n",
    "\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'to_from_san.csv')\n",
    "    >>> dtypes = data_types()\n",
    "    >>> flights = pd.read_csv(fp, dtype=dtypes)\n",
    "    >>> out = depart_arrive_stats(flights)\n",
    "    >>> out.index.tolist() == ['late1', 'late2', 'late3']\n",
    "    True\n",
    "    >>> isinstance(out, pd.Series)\n",
    "    True\n",
    "    >>> out.max() < 0.30\n",
    "    True\n",
    "    \"\"\"\n",
    "    \n",
    "    late1 = flights.loc[(flights['DEPARTURE_DELAY'] > 0) & (flights['ARRIVAL_DELAY'] <= 0)].shape[0] / flights.shape[0]\n",
    "    \n",
    "    late2 = flights.loc[(flights['DEPARTURE_DELAY'] <= 0) & (flights['ARRIVAL_DELAY'] > 0)].shape[0] / flights.shape[0]\n",
    "    \n",
    "    late3 = flights.loc[(flights['DEPARTURE_DELAY'] > 0) & (flights['ARRIVAL_DELAY'] > 0)].shape[0] / flights.shape[0]\n",
    "    \n",
    "    df = pd.Series([late1, late2, late3],index=['late1','late2','late3'])\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "late1    0.119853\n",
       "late2    0.089329\n",
       "late3    0.278804\n",
       "dtype: float64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'to_from_san.csv')\n",
    "dtypes = data_types()\n",
    "flights = pd.read_csv(fp, dtype=dtypes)\n",
    "out = depart_arrive_stats(flights)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.index.tolist() == ['late1', 'late2', 'late3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "isinstance(out, pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.max() < 0.30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def depart_arrive_stats_by_month(flights):\n",
    "    \"\"\"\n",
    "    depart_arrive_stats_by_month takes in a dataframe like flights and\n",
    "    calculates the quantities in depart_arrive_stats, broken down by month\n",
    "\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'to_from_san.csv')\n",
    "    >>> dtypes = data_types()\n",
    "    >>> flights = pd.read_csv(fp, dtype=dtypes)\n",
    "    >>> out = depart_arrive_stats_by_month(flights)\n",
    "    >>> out.columns.tolist() == ['late1', 'late2', 'late3']\n",
    "    True\n",
    "    >>> set(out.index) <= set(range(1, 13))\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    return flights.groupby('MONTH').apply(depart_arrive_stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>late1</th>\n",
       "      <th>late2</th>\n",
       "      <th>late3</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MONTH</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.119063</td>\n",
       "      <td>0.095645</td>\n",
       "      <td>0.270501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.118087</td>\n",
       "      <td>0.096915</td>\n",
       "      <td>0.289925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.130521</td>\n",
       "      <td>0.089240</td>\n",
       "      <td>0.258309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.116475</td>\n",
       "      <td>0.095064</td>\n",
       "      <td>0.264326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.114136</td>\n",
       "      <td>0.083498</td>\n",
       "      <td>0.285151</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.121138</td>\n",
       "      <td>0.088248</td>\n",
       "      <td>0.330968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.115371</td>\n",
       "      <td>0.095455</td>\n",
       "      <td>0.335799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.123828</td>\n",
       "      <td>0.086890</td>\n",
       "      <td>0.272450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.110409</td>\n",
       "      <td>0.087890</td>\n",
       "      <td>0.185905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.126393</td>\n",
       "      <td>0.081468</td>\n",
       "      <td>0.243735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.122793</td>\n",
       "      <td>0.082745</td>\n",
       "      <td>0.318700</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          late1     late2     late3\n",
       "MONTH                              \n",
       "1      0.119063  0.095645  0.270501\n",
       "2      0.118087  0.096915  0.289925\n",
       "3      0.130521  0.089240  0.258309\n",
       "4      0.116475  0.095064  0.264326\n",
       "5      0.114136  0.083498  0.285151\n",
       "6      0.121138  0.088248  0.330968\n",
       "7      0.115371  0.095455  0.335799\n",
       "8      0.123828  0.086890  0.272450\n",
       "9      0.110409  0.087890  0.185905\n",
       "11     0.126393  0.081468  0.243735\n",
       "12     0.122793  0.082745  0.318700"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'to_from_san.csv')\n",
    "dtypes = data_types()\n",
    "flights = pd.read_csv(fp, dtype=dtypes)\n",
    "out = depart_arrive_stats_by_month(flights)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.columns.tolist() == ['late1', 'late2', 'late3']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(out.index) <= set(range(1, 13))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flight delays and day of the week\n",
    "\n",
    "**Question 5**\n",
    "\n",
    "Next, we'd like to understand the flight traffic to/from SAN by day of the week. Day of the week is specified by integers 1 through 7; verify for yourself which integer corresponds to which day (hint: you have the *date* for each flight as well!).\n",
    "\n",
    "Next create two functions to understand both the amount of traffic and the average flight delay of flights for each airline by day-of-the week. We both want to understand *presence* each airline has as well as their *performance*.\n",
    "\n",
    "1. Create a function `cnts_by_airline_dow` that takes in a dataframe like `flights` and outputs a dataframe that answers the following question: Given any `AIRLINE` and `DAY_OF_WEEK`, how many flights were there (in 2015)?\n",
    "\n",
    "\n",
    "2. Create a function `mean_by_airline_dow` that takes in a dataframe like `flights` and outputs a dataframe that answers the following question: Given any `AIRLINE` and `DAY_OF_WEEK`, what is the average `ARRIVAL_DELAY` (in 2015)?\n",
    "\n",
    "Both dataframes should have a column for each distinct value of `AIRLINE` and a row for each `DAY_OF_WEEK`.\n",
    "\n",
    "*Hint:* `pivot_table` should be useful here!\n",
    "\n",
    "Your output should have the *form* of the table below (not the entries themselves!)\n",
    "\n",
    "<img src=\"data/pivot.png\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">AIRLINE_DELAY</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">YEAR</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AIRLINE</th>\n",
       "      <th>AA</th>\n",
       "      <th>AS</th>\n",
       "      <th>B6</th>\n",
       "      <th>DL</th>\n",
       "      <th>F9</th>\n",
       "      <th>HA</th>\n",
       "      <th>NK</th>\n",
       "      <th>OO</th>\n",
       "      <th>UA</th>\n",
       "      <th>US</th>\n",
       "      <th>...</th>\n",
       "      <th>B6</th>\n",
       "      <th>DL</th>\n",
       "      <th>F9</th>\n",
       "      <th>HA</th>\n",
       "      <th>NK</th>\n",
       "      <th>OO</th>\n",
       "      <th>UA</th>\n",
       "      <th>US</th>\n",
       "      <th>VX</th>\n",
       "      <th>WN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>347</td>\n",
       "      <td>168</td>\n",
       "      <td>74</td>\n",
       "      <td>180</td>\n",
       "      <td>34</td>\n",
       "      <td>25</td>\n",
       "      <td>124</td>\n",
       "      <td>393</td>\n",
       "      <td>411</td>\n",
       "      <td>77</td>\n",
       "      <td>...</td>\n",
       "      <td>384</td>\n",
       "      <td>1753</td>\n",
       "      <td>218</td>\n",
       "      <td>96</td>\n",
       "      <td>531</td>\n",
       "      <td>1859</td>\n",
       "      <td>2369</td>\n",
       "      <td>495</td>\n",
       "      <td>536</td>\n",
       "      <td>9238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>296</td>\n",
       "      <td>120</td>\n",
       "      <td>87</td>\n",
       "      <td>183</td>\n",
       "      <td>44</td>\n",
       "      <td>23</td>\n",
       "      <td>124</td>\n",
       "      <td>350</td>\n",
       "      <td>471</td>\n",
       "      <td>64</td>\n",
       "      <td>...</td>\n",
       "      <td>359</td>\n",
       "      <td>1647</td>\n",
       "      <td>210</td>\n",
       "      <td>96</td>\n",
       "      <td>529</td>\n",
       "      <td>1829</td>\n",
       "      <td>2211</td>\n",
       "      <td>463</td>\n",
       "      <td>544</td>\n",
       "      <td>9300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>290</td>\n",
       "      <td>130</td>\n",
       "      <td>73</td>\n",
       "      <td>196</td>\n",
       "      <td>45</td>\n",
       "      <td>25</td>\n",
       "      <td>109</td>\n",
       "      <td>327</td>\n",
       "      <td>407</td>\n",
       "      <td>59</td>\n",
       "      <td>...</td>\n",
       "      <td>359</td>\n",
       "      <td>1719</td>\n",
       "      <td>227</td>\n",
       "      <td>96</td>\n",
       "      <td>530</td>\n",
       "      <td>1814</td>\n",
       "      <td>2293</td>\n",
       "      <td>472</td>\n",
       "      <td>542</td>\n",
       "      <td>9328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>355</td>\n",
       "      <td>165</td>\n",
       "      <td>92</td>\n",
       "      <td>222</td>\n",
       "      <td>40</td>\n",
       "      <td>32</td>\n",
       "      <td>116</td>\n",
       "      <td>382</td>\n",
       "      <td>473</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>380</td>\n",
       "      <td>1729</td>\n",
       "      <td>220</td>\n",
       "      <td>96</td>\n",
       "      <td>531</td>\n",
       "      <td>1835</td>\n",
       "      <td>2328</td>\n",
       "      <td>510</td>\n",
       "      <td>531</td>\n",
       "      <td>9108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>267</td>\n",
       "      <td>182</td>\n",
       "      <td>80</td>\n",
       "      <td>173</td>\n",
       "      <td>41</td>\n",
       "      <td>30</td>\n",
       "      <td>111</td>\n",
       "      <td>356</td>\n",
       "      <td>400</td>\n",
       "      <td>89</td>\n",
       "      <td>...</td>\n",
       "      <td>376</td>\n",
       "      <td>1701</td>\n",
       "      <td>208</td>\n",
       "      <td>94</td>\n",
       "      <td>518</td>\n",
       "      <td>1813</td>\n",
       "      <td>2279</td>\n",
       "      <td>505</td>\n",
       "      <td>523</td>\n",
       "      <td>9006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>259</td>\n",
       "      <td>177</td>\n",
       "      <td>44</td>\n",
       "      <td>133</td>\n",
       "      <td>30</td>\n",
       "      <td>26</td>\n",
       "      <td>107</td>\n",
       "      <td>314</td>\n",
       "      <td>241</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>270</td>\n",
       "      <td>1433</td>\n",
       "      <td>195</td>\n",
       "      <td>94</td>\n",
       "      <td>518</td>\n",
       "      <td>1837</td>\n",
       "      <td>1743</td>\n",
       "      <td>496</td>\n",
       "      <td>365</td>\n",
       "      <td>7201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>298</td>\n",
       "      <td>194</td>\n",
       "      <td>72</td>\n",
       "      <td>161</td>\n",
       "      <td>49</td>\n",
       "      <td>23</td>\n",
       "      <td>124</td>\n",
       "      <td>419</td>\n",
       "      <td>351</td>\n",
       "      <td>85</td>\n",
       "      <td>...</td>\n",
       "      <td>387</td>\n",
       "      <td>1726</td>\n",
       "      <td>214</td>\n",
       "      <td>96</td>\n",
       "      <td>532</td>\n",
       "      <td>1889</td>\n",
       "      <td>2172</td>\n",
       "      <td>503</td>\n",
       "      <td>443</td>\n",
       "      <td>8587</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7 rows × 348 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            AIRLINE_DELAY                                           ... YEAR  \\\n",
       "AIRLINE                AA   AS  B6   DL  F9  HA   NK   OO   UA  US  ...   B6   \n",
       "DAY_OF_WEEK                                                         ...        \n",
       "1                     347  168  74  180  34  25  124  393  411  77  ...  384   \n",
       "2                     296  120  87  183  44  23  124  350  471  64  ...  359   \n",
       "3                     290  130  73  196  45  25  109  327  407  59  ...  359   \n",
       "4                     355  165  92  222  40  32  116  382  473  85  ...  380   \n",
       "5                     267  182  80  173  41  30  111  356  400  89  ...  376   \n",
       "6                     259  177  44  133  30  26  107  314  241  69  ...  270   \n",
       "7                     298  194  72  161  49  23  124  419  351  85  ...  387   \n",
       "\n",
       "                                                             \n",
       "AIRLINE        DL   F9  HA   NK    OO    UA   US   VX    WN  \n",
       "DAY_OF_WEEK                                                  \n",
       "1            1753  218  96  531  1859  2369  495  536  9238  \n",
       "2            1647  210  96  529  1829  2211  463  544  9300  \n",
       "3            1719  227  96  530  1814  2293  472  542  9328  \n",
       "4            1729  220  96  531  1835  2328  510  531  9108  \n",
       "5            1701  208  94  518  1813  2279  505  523  9006  \n",
       "6            1433  195  94  518  1837  1743  496  365  7201  \n",
       "7            1726  214  96  532  1889  2172  503  443  8587  \n",
       "\n",
       "[7 rows x 348 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#pd.DataFrame(flights.groupby(['DAY_OF_WEEK','AIRLINE'],as_index=False)['AIRLINE'].count())#.pivot(index='DAY_OF_WEEK',columns='AIRLINE')\n",
    "flights.pivot_table(index='DAY_OF_WEEK',columns='AIRLINE',aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>AIRLINE</th>\n",
       "      <th>AA</th>\n",
       "      <th>AS</th>\n",
       "      <th>B6</th>\n",
       "      <th>DL</th>\n",
       "      <th>F9</th>\n",
       "      <th>HA</th>\n",
       "      <th>NK</th>\n",
       "      <th>OO</th>\n",
       "      <th>UA</th>\n",
       "      <th>US</th>\n",
       "      <th>VX</th>\n",
       "      <th>WN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.245981</td>\n",
       "      <td>-2.652286</td>\n",
       "      <td>0.928571</td>\n",
       "      <td>-3.096904</td>\n",
       "      <td>3.233945</td>\n",
       "      <td>5.842105</td>\n",
       "      <td>9.222656</td>\n",
       "      <td>7.405257</td>\n",
       "      <td>3.081280</td>\n",
       "      <td>1.764344</td>\n",
       "      <td>12.804878</td>\n",
       "      <td>6.355997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.791037</td>\n",
       "      <td>-4.535474</td>\n",
       "      <td>4.507123</td>\n",
       "      <td>-2.988408</td>\n",
       "      <td>4.975728</td>\n",
       "      <td>7.385417</td>\n",
       "      <td>10.669903</td>\n",
       "      <td>5.109574</td>\n",
       "      <td>5.617431</td>\n",
       "      <td>1.354626</td>\n",
       "      <td>4.645522</td>\n",
       "      <td>5.394194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.811808</td>\n",
       "      <td>-4.030899</td>\n",
       "      <td>2.735043</td>\n",
       "      <td>-2.437098</td>\n",
       "      <td>5.634361</td>\n",
       "      <td>16.833333</td>\n",
       "      <td>6.304264</td>\n",
       "      <td>5.566741</td>\n",
       "      <td>3.686344</td>\n",
       "      <td>-2.145299</td>\n",
       "      <td>0.631970</td>\n",
       "      <td>3.556762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.076552</td>\n",
       "      <td>-2.180995</td>\n",
       "      <td>3.152406</td>\n",
       "      <td>-2.339721</td>\n",
       "      <td>4.531818</td>\n",
       "      <td>7.552083</td>\n",
       "      <td>7.931298</td>\n",
       "      <td>7.971901</td>\n",
       "      <td>4.957124</td>\n",
       "      <td>1.198397</td>\n",
       "      <td>8.277040</td>\n",
       "      <td>6.582300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.235679</td>\n",
       "      <td>-1.040887</td>\n",
       "      <td>3.329759</td>\n",
       "      <td>-5.699528</td>\n",
       "      <td>4.830918</td>\n",
       "      <td>8.021505</td>\n",
       "      <td>7.242718</td>\n",
       "      <td>5.920156</td>\n",
       "      <td>1.756997</td>\n",
       "      <td>3.017928</td>\n",
       "      <td>9.325536</td>\n",
       "      <td>7.961504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.427912</td>\n",
       "      <td>-3.283673</td>\n",
       "      <td>-1.854478</td>\n",
       "      <td>-3.608726</td>\n",
       "      <td>0.119171</td>\n",
       "      <td>7.159574</td>\n",
       "      <td>6.943026</td>\n",
       "      <td>3.746961</td>\n",
       "      <td>-1.338924</td>\n",
       "      <td>-2.227926</td>\n",
       "      <td>0.101370</td>\n",
       "      <td>1.684625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1.611924</td>\n",
       "      <td>-2.318213</td>\n",
       "      <td>2.422043</td>\n",
       "      <td>-4.857392</td>\n",
       "      <td>6.112150</td>\n",
       "      <td>5.229167</td>\n",
       "      <td>8.754753</td>\n",
       "      <td>8.570806</td>\n",
       "      <td>-0.190121</td>\n",
       "      <td>2.257545</td>\n",
       "      <td>12.594533</td>\n",
       "      <td>6.867543</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "AIRLINE            AA        AS        B6        DL        F9         HA  \\\n",
       "DAY_OF_WEEK                                                                \n",
       "1            2.245981 -2.652286  0.928571 -3.096904  3.233945   5.842105   \n",
       "2            0.791037 -4.535474  4.507123 -2.988408  4.975728   7.385417   \n",
       "3            1.811808 -4.030899  2.735043 -2.437098  5.634361  16.833333   \n",
       "4            4.076552 -2.180995  3.152406 -2.339721  4.531818   7.552083   \n",
       "5            1.235679 -1.040887  3.329759 -5.699528  4.830918   8.021505   \n",
       "6           -0.427912 -3.283673 -1.854478 -3.608726  0.119171   7.159574   \n",
       "7            1.611924 -2.318213  2.422043 -4.857392  6.112150   5.229167   \n",
       "\n",
       "AIRLINE             NK        OO        UA        US         VX        WN  \n",
       "DAY_OF_WEEK                                                                \n",
       "1             9.222656  7.405257  3.081280  1.764344  12.804878  6.355997  \n",
       "2            10.669903  5.109574  5.617431  1.354626   4.645522  5.394194  \n",
       "3             6.304264  5.566741  3.686344 -2.145299   0.631970  3.556762  \n",
       "4             7.931298  7.971901  4.957124  1.198397   8.277040  6.582300  \n",
       "5             7.242718  5.920156  1.756997  3.017928   9.325536  7.961504  \n",
       "6             6.943026  3.746961 -1.338924 -2.227926   0.101370  1.684625  \n",
       "7             8.754753  8.570806 -0.190121  2.257545  12.594533  6.867543  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.pivot_table(values='ARRIVAL_DELAY',index='DAY_OF_WEEK',columns='AIRLINE',aggfunc='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def cnts_by_airline_dow(flights):\n",
    "    \"\"\"\n",
    "    mean_by_airline_dow takes in a dataframe like flights and outputs a\n",
    "    dataframe that answers the question:\n",
    "    Given any AIRLINE and DAY_OF_WEEK, how many flights were there (in 2015)?\n",
    "\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'to_from_san.csv')\n",
    "    >>> flights = pd.read_csv(fp, nrows=100)\n",
    "    >>> out = cnts_by_airline_dow(flights)\n",
    "    >>> set(out.columns) == set(flights['AIRLINE'].unique())\n",
    "    True\n",
    "    >>> set(out.index) == set(flights['DAY_OF_WEEK'].unique())\n",
    "    True\n",
    "    >>> (out >= 0).all().all()\n",
    "    True\n",
    "    \"\"\"\n",
    "    df = flights.pivot_table(values='DAY',index='DAY_OF_WEEK',columns='AIRLINE',aggfunc='count')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>AIRLINE</th>\n",
       "      <th>AA</th>\n",
       "      <th>AS</th>\n",
       "      <th>B6</th>\n",
       "      <th>DL</th>\n",
       "      <th>F9</th>\n",
       "      <th>HA</th>\n",
       "      <th>NK</th>\n",
       "      <th>OO</th>\n",
       "      <th>UA</th>\n",
       "      <th>US</th>\n",
       "      <th>VX</th>\n",
       "      <th>WN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>11</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "AIRLINE      AA  AS  B6  DL  F9  HA  NK  OO  UA  US  VX  WN\n",
       "DAY_OF_WEEK                                                \n",
       "4             8  12   2  11   2   1   4  15  11   4   2  28"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'to_from_san.csv')\n",
    "flights = pd.read_csv(fp, nrows=100)\n",
    "out = cnts_by_airline_dow(flights)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(flights['AIRLINE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set(out.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(out.columns) == set(flights['AIRLINE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(out.index) == set(flights['DAY_OF_WEEK'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(out >= 0).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_by_airline_dow(flights):\n",
    "    \"\"\"\n",
    "    mean_by_airline_dow takes in a dataframe like flights and outputs a\n",
    "    dataframe that answers the question:\n",
    "    Given any AIRLINE and DAY_OF_WEEK, what is the average ARRIVAL_DELAY (in\n",
    "    2015)?\n",
    "\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'to_from_san.csv')\n",
    "    >>> flights = pd.read_csv(fp, nrows=100)\n",
    "    >>> out = mean_by_airline_dow(flights)\n",
    "    >>> set(out.columns) == set(flights['AIRLINE'].unique())\n",
    "    True\n",
    "    >>> set(out.index) == set(flights['DAY_OF_WEEK'].unique())\n",
    "    True\n",
    "    \"\"\"\n",
    "    df = flights.pivot_table(values='ARRIVAL_DELAY',index='DAY_OF_WEEK',columns='AIRLINE',aggfunc='mean')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>AIRLINE</th>\n",
       "      <th>AA</th>\n",
       "      <th>AS</th>\n",
       "      <th>B6</th>\n",
       "      <th>DL</th>\n",
       "      <th>F9</th>\n",
       "      <th>HA</th>\n",
       "      <th>NK</th>\n",
       "      <th>OO</th>\n",
       "      <th>UA</th>\n",
       "      <th>US</th>\n",
       "      <th>VX</th>\n",
       "      <th>WN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DAY_OF_WEEK</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-20.857143</td>\n",
       "      <td>-3.416667</td>\n",
       "      <td>-3.5</td>\n",
       "      <td>-10.636364</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>-6.75</td>\n",
       "      <td>20.285714</td>\n",
       "      <td>-14.363636</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>-5.0</td>\n",
       "      <td>-1.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "AIRLINE             AA        AS   B6         DL   F9   HA    NK         OO  \\\n",
       "DAY_OF_WEEK                                                                   \n",
       "4           -20.857143 -3.416667 -3.5 -10.636364 -8.0  9.0 -6.75  20.285714   \n",
       "\n",
       "AIRLINE             UA   US   VX   WN  \n",
       "DAY_OF_WEEK                            \n",
       "4           -14.363636 -6.0 -5.0 -1.5  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'to_from_san.csv')\n",
    "flights = pd.read_csv(fp, nrows=100)\n",
    "out = mean_by_airline_dow(flights)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(out.columns) == set(flights['AIRLINE'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(out.index) == set(flights['DAY_OF_WEEK'].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#flights[flights['CANCELLED'] == 1]### Understanding null values in the flights data\n",
    "\n",
    "**Question 6 (Missing by Design)**\n",
    "\n",
    "Now we would like to understand how data is missing in the flights data. First, compute the proportion of each column of `flights` which are non-null. Do not turn this in, but it will be useful information in doing the next few problems.\n",
    "\n",
    "Recall that a column is *missing by design* if you can determine when the entry of a column is missing based solely on other data in the same row. That is\n",
    "* there is *no randomness* in determining when an entry is missing.\n",
    "* you can describe when the column is missing a value with a logical (not random) condition.\n",
    "* you can express which rows will have missing values in terms of logical statements about the *other* columns in the same row.\n",
    "\n",
    "For this question, verify the following columns are *missing by design*:\n",
    "* The column `ARRIVAL_DELAY` is *missing by design*. Create a function `predict_null_arrival_delay` that doesn't depend on the values of `ARRIVAL_DELAY`, that:\n",
    "    - Takes in a row of the flights data (that is, a Series)\n",
    "    - Returns `True` if and only if the `ARRIVAL_DELAY` is null; otherwise it returns `False`.\n",
    "    - Since the function doesn't depend on `ARRIVAL_DELAY`, it should work on a row even if the `ARRIVAL_DELAY` index is dropped.\n",
    "    - You can check your function by using `flights.drop('ARRIVAL_DELAY', axis=1).apply(predict_null, axis=1)` and compare it to the `ARRIVAL_DELAY` column!\n",
    "\n",
    "\n",
    "* The column `AIRLINE_DELAY` is *missing by design*. As above, create a function `predict_null_airline_delay` that doesn't depend on the values of `AIRLINE_DELAY`, that:\n",
    "    - Takes in a row of the flights data (that is, a Series)\n",
    "    - Returns `True` if and only if the `AIRLINE_DELAY` is null; otherwise it returns `False`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flights[flights['CANCELLED'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_null_arrival_delay(row):\n",
    "    \"\"\"\n",
    "    predict_null takes in a row of the flights data (that is, a Series) and\n",
    "    returns True if the ARRIVAL_DELAY is null and otherwise False.\n",
    "\n",
    "    :param row: a Series that represents a row of `flights`\n",
    "    :returns: a boolean representing when `ARRIVAL_DELAY` is null.\n",
    "\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'to_from_san.csv')\n",
    "    >>> flights = pd.read_csv(fp, nrows=100)\n",
    "    >>> out = flights.drop('ARRIVAL_DELAY', axis=1).apply(predict_null_arrival_delay, axis=1)\n",
    "    >>> set(out.unique()) - set([True, False]) == set()\n",
    "    True\n",
    "    \"\"\"\n",
    "    if row['CANCELLED'] == True | row['DIVERTED'] == True:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     False\n",
       "1     False\n",
       "2     False\n",
       "3     False\n",
       "4     False\n",
       "      ...  \n",
       "95    False\n",
       "96    False\n",
       "97    False\n",
       "98    False\n",
       "99    False\n",
       "Length: 100, dtype: bool"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'to_from_san.csv')\n",
    "flights = pd.read_csv(fp, nrows=100)\n",
    "out = flights.drop('ARRIVAL_DELAY', axis=1).apply(predict_null_arrival_delay, axis=1)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(out.unique()) - set([True, False]) == set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.drop('ARRIVAL_DELAY',axis=1).apply(predict_null_arrival_delay,axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights['ARRIVAL_DELAY'].isnull().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#flights[flights['AIRLINE_DELAY'].isna() == False]#.head(60)\n",
    "#flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def predict_null_airline_delay(row):\n",
    "    \"\"\"\n",
    "    predict_null takes in a row of the flights data (that is, a Series) and\n",
    "    returns True if the AIRLINE_DELAY is null and otherwise False. Since the\n",
    "    function doesn't depend on AIRLINE_DELAY, it should work a row even if that\n",
    "    index is dropped.\n",
    "\n",
    "    :param row: a Series that represents a row of `flights`\n",
    "    :returns: a boolean representing when `AIRLINE_DELAY` is null.\n",
    "\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'to_from_san.csv')\n",
    "    >>> flights = pd.read_csv(fp, nrows=100)\n",
    "    >>> out = flights.drop('AIRLINE_DELAY', axis=1).apply(predict_null_airline_delay, axis=1)\n",
    "    >>> set(out.unique()) - set([True, False]) == set()\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    #return row['AIR_SYSTEM_DELAY'] + row['SECURITY_DELAY'] +  row['LATE_AIRCRAFT_DELAY'] + row['WEATHER_DELAY'] != 0\n",
    "    if row['ARRIVAL_DELAY'] < 15 or row['CANCELLED'] == True or row['DIVERTED'] == True:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1      True\n",
       "2      True\n",
       "3      True\n",
       "4      True\n",
       "      ...  \n",
       "95     True\n",
       "96     True\n",
       "97     True\n",
       "98     True\n",
       "99    False\n",
       "Length: 100, dtype: bool"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'to_from_san.csv')\n",
    "flights = pd.read_csv(fp, nrows=100)\n",
    "out = flights.drop('AIRLINE_DELAY', axis=1).apply(predict_null_airline_delay, axis=1)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(out.unique()) - set([True, False]) == set()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights.drop('AIRLINE_DELAY',axis=1).apply(predict_null_airline_delay,axis=1).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flights['AIRLINE_DELAY'].isnull().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 7 (Missingness Types)**\n",
    "\n",
    "Now we'd like to determine missingness of the column `DEPARTURE_DELAY`. In particular, we'd like to perform a permutation test to determine the missingness of `DEPARTURE_DELAY` dependent on the column `AIRLINE`.\n",
    "\n",
    "* Create a function `perm4missing`:\n",
    "    - that takes in `flights`, a column `col`, and a number `N` and \n",
    "    - returns the p-value of the test (using `N` simulations) that determines if `DEPARTURE_DELAY` is MAR dependent on `col`. That is `perm4missing(flights, 'AIRLINE', N)` should return the p-value for the test above.\n",
    "    - *Remark*: to help your work, create helper functions whose output you can plot, to assess the correctness of your p-value!\n",
    "    \n",
    "* Use your function above to determine the columns `col` for which \"`DEPARTURE_DELAY` is MAR dependent on `col`\" using a significance level of 0.01. Only consider the categorical columns `YEAR`,`DAY_OF_WEEK`, `AIRLINE`,`DIVERTED`, `CANCELLATION_REASON`. Return your answer in a (hard-coded) list returned by a function called `dependent_cols`.\n",
    "\n",
    "* Create a function `missing_types` of zero variables, which:\n",
    "    - Returns a Series, indexed by the following columns of `flights`: `CANCELLED`, `CANCELLATION_REASON`, `TAIL_NUMBER`, `ARRIVAL_TIME`.\n",
    "    - The values should contain the most-likely missingness type of each column. \n",
    "    - The values of this Series should be `MD, MCAR, MAR, MNAR, NaN` (use `NaN` if there are no missing values). \n",
    "\n",
    "\n",
    "*Hint:* for missingness permutation tests, try using TVD as a test statistic! You are taking the TVD between the distributions of `True` and `False` for those non-numerical columns; `True` being the proportions of null values, `False` being the proportions of non-null values. Check the lecture slides for more information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ts_calc(data, col):\n",
    "    df = data[['DEPARTURE_DELAY',col,'SHUFFLED']]\n",
    "    #pivotted = pd.DataFrame(df.pivot_table(index='DEPARTURE_DELAY',columns=col,aggfunc='size'))\n",
    "    pivotted = pd.DataFrame(df.pivot_table(columns=col,aggfunc='size'))\n",
    "    distr = pivotted / pivotted.sum(axis=0)\n",
    "    ts = distr.diff(axis=0).iloc[-1].abs().sum() / 2\n",
    "    return ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIVERTED</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "DIVERTED     \n",
       "0         100"
      ]
     },
     "execution_count": 166,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_flights = flights.copy()\n",
    "test_flights['SHUFFLED'] = np.random.permutation(flights['DIVERTED'].values)\n",
    "df = test_flights[['DEPARTURE_DELAY','DIVERTED','SHUFFLED']]\n",
    "pivotted = pd.DataFrame(df.pivot_table(columns='DIVERTED',aggfunc='size'))\n",
    "pivotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DIVERTED</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "DIVERTED     \n",
       "0         1.0"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distr = pivotted / pivotted.sum(axis=0)\n",
    "distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ts = distr.diff(axis=0).iloc[-1].abs().sum() / 2\n",
    "ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_null(flights, 'DIVERTED')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_flights = flights.copy()\n",
    "#test_flights['SHUFFLED'] = np.random.permutation(flights['AIRLINE'].values)\n",
    "#pivotted = pd.DataFrame(test_flights[['DEPARTURE_DELAY','AIRLINE','SHUFFLED']].pivot_table(index='AIRLINE',columns='DEPARTURE_DELAY',aggfunc='size'))\n",
    "#distr = pivotted / pivotted.sum(axis=0)\n",
    "#distr\n",
    "#ts = distr.diff(axis=0).iloc[-1]#.abs().sum() / 2\n",
    "#ts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distr = pivotted / pivotted.sum(axis=0)\n",
    "#distr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#obs = distr.diff(axis=0)#.iloc[:].abs().sum() / 2\n",
    "#obs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim_null(data, col):\n",
    "    shuffled = np.random.permutation(data[col].values)\n",
    "    data['SHUFFLED'] = shuffled\n",
    "    test_stat = ts_calc(data,col)\n",
    "    return test_stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def perm4missing(flights, col, N):\n",
    "    \"\"\"\n",
    "    perm4missing takes in flights, a column col, and a number N and returns the\n",
    "    p-value of the test (using N simulations) that determines if\n",
    "    DEPARTURE_DELAY is MAR dependent on col.\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'to_from_san.csv')\n",
    "    >>> flights = pd.read_csv(fp, nrows=100)\n",
    "    >>> out = perm4missing(flights, 'AIRLINE', 100)\n",
    "    >>> 0 <= out <= 1\n",
    "    True\n",
    "    \"\"\"\n",
    "  \n",
    "    pivotted = pd.DataFrame(flights[['DEPARTURE_DELAY',col]].pivot_table(columns=col,aggfunc='size'))\n",
    "    distr = pivotted / pivotted.sum(axis=0)\n",
    "    obs = distr.diff(axis=0).iloc[:,-1].abs().sum() / 2\n",
    "    differences = []\n",
    "    \n",
    "    for trial in range(N):\n",
    "        trial_null = sim_null(flights,col)\n",
    "        differences.append(trial_null)\n",
    "\n",
    "    return np.count_nonzero(differences >= obs) / N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43000000000000005\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp = os.path.join('data', 'to_from_san.csv')\n",
    "flights = pd.read_csv(fp, nrows=100)\n",
    "out = perm4missing(flights, 'AIRLINE', 100)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm4missing(flights, 'DIVERTED', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0 <= out <= 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "#to_from_san_filepath = os.path.join('data', 'to_from_san.csv')\n",
    "#flights = pd.read_csv(to_from_san_filepath)\n",
    "#flights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 169,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm4missing(flights, 'CANCELLATION_REASON', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm4missing(flights, 'YEAR', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm4missing(flights, 'DAY_OF_WEEK', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm4missing(flights, 'DIVERTED', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43000000000000005\n",
      "[0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13, 0.13]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perm4missing(flights, 'AIRLINE', 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def dependent_cols():\n",
    "    \"\"\"\n",
    "    dependent_cols gives a list of columns on which DEPARTURE_DELAY is MAR\n",
    "    dependent on.\n",
    "\n",
    "    :Example:\n",
    "    >>> out = dependent_cols()\n",
    "    >>> isinstance(out, list)\n",
    "    True\n",
    "    >>> cols = 'YEAR DAY_OF_WEEK AIRLINE DIVERTED CANCELLATION_REASON'.split()\n",
    "    >>> set(out) <= set(cols)\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    return ['AIRLINE','DAY_OF_WEEK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "out = dependent_cols()\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(out, list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = 'YEAR DAY_OF_WEEK AIRLINE DIVERTED CANCELLATION_REASON'.split()\n",
    "set(out) <= set(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_types():\n",
    "    \"\"\"\n",
    "    missing_types returns a Series\n",
    "    - indexed by the following columns of flights:\n",
    "    CANCELLED, CANCELLATION_REASON, TAIL_NUMBER, ARRIVAL_TIME.\n",
    "    - The values contain the most-likely missingness type of each column.\n",
    "    - The unique values of this Series should be MD, MCAR, MAR, MNAR, NaN.\n",
    "\n",
    "    :param:\n",
    "    :returns: A series with index and values as described above.\n",
    "\n",
    "    :Example:\n",
    "    >>> out = missing_types()\n",
    "    >>> isinstance(out, pd.Series)\n",
    "    True\n",
    "    >>> set(out.unique()) - set(['MD', 'MCAR', 'MAR', 'NMAR', np.NaN]) == set()\n",
    "    True\n",
    "    \"\"\"\n",
    "    indexes = 'CANCELLED CANCELLATION_REASON TAIL_NUMBER ARRIVAL_TIME'.split()\n",
    "    return pd.Series([np.NaN, 'MD', 'MCAR', 'MD'],index=indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = missing_types()\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(out, pd.Series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(out.unique()) - set(['MD', 'MCAR', 'MAR', 'NMAR', np.NaN]) == set()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simpson's Paradox: JetBlue vs Southwest\n",
    "\n",
    "The remainder of the questions investigates the presence of Simpson's paradox in the flights dataset. Read through the final slides of lecture 05, as well as [the book](https://afraenkel.github.io/practical-data-science/05/understanding-aggregations.html#simpsons-paradox) for a summary of Simpson's Paradox and related links.\n",
    "\n",
    "The csv file `southwest_vs_jetblue.csv` contains all Southwest and JetBlue flights in 2015.\n",
    "\n",
    "In this dataset, we are going to verify the following occurrences of Simpson's Paradox: For a given set of airports,\n",
    "* The average departure delay of Southwest is greater than (or less than) the average departure delay of JetBlue.\n",
    "* Airport by airport, the average departure delay of Southwest is *less* than (or greater than) the average departure delay of JetBlue.\n",
    "\n",
    "That is, the inequalities of the average flight delays between the two airlines are reversed when viewed at the level of each airport. In fact this reversal holds for *every* airport being considered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-14T01:51:26.412337Z",
     "start_time": "2019-10-14T01:51:24.838Z"
    }
   },
   "outputs": [],
   "source": [
    "jb_sw_filepath = os.path.join('data', 'jetblue_or_sw.csv')\n",
    "dtype = proj.data_types()\n",
    "\n",
    "# The `usecols` keyword:\n",
    "# choose *only* the columns you need to reduce your memory footprint!\n",
    "usecols = ['ORIGIN_AIRPORT','AIRLINE','DEPARTURE_DELAY','CANCELLED']\n",
    "\n",
    "jb_sw = pd.read_csv(jb_sw_filepath, dtype=dtype, usecols=usecols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jb_sw[jb_sw.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jb_sw[jb_sw['DEPARTURE_DELAY']==0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 8**\n",
    "\n",
    "Filter the dataset `jb_sw` to flights *originating* from the following 10 airports: ABQ, BDL, BUR, DCA, MSY, PBI, PHX, RNO, SJC, SLC.\n",
    "\n",
    "Illustrate Simpson's paradox with this table:\n",
    "* Calculate the proportion of each airline's flights that are delayed (at each of the 10 airports):\n",
    "    - Create a function `prop_delayed_by_airline` that takes in a dataframe like `jb_sw` and returns a DataFrame indexed by airline that contains the proportion of each airline's flights that are delayed.\n",
    "* Calculate these proportions across all airports in the dataset (at each of the 10 airports):\n",
    "    - Create a function `prop_delayed_by_airline_airport` that takes in a dataframe like `jb_sw` and returns a DataFrame, with columns given by airports, indexed by airline, that contains the proportion of each airline's flights that are delayed at each airport.\n",
    "\n",
    "*Remark 1:* For the purpose of this question, a canceled flight is **not** considered delayed.\n",
    "\n",
    "*Remark 2:* Make sure that the functions only work with the columns that are absolutely necessary for the question to avoid out of memory errors!\n",
    "\n",
    "Verify that Simpson's paradox is present in this output! \n",
    "\n",
    "Can you explain *why* Simpson's paradox is occurring? (Hint: where are these airports located? Which have the most flights?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "airports = ['ABQ', 'BDL', 'BUR', 'DCA', 'MSY', 'PBI', 'PHX', 'RNO', 'SJC', 'SLC']\n",
    "jb_sw = jb_sw[jb_sw['ORIGIN_AIRPORT'].isin(airports)]\n",
    "jb_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#jb_sw[jb_sw.isnull().any(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#non_null = jb_sw.pivot_table(index='AIRLINE',columns='ORIGIN_AIRPORT',aggfunc='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with_null = jb_sw.pivot_table(index='AIRLINE',columns='ORIGIN_AIRPORT',aggfunc='size')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#prop_null = 1 - non_null / with_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(prop_null.mean(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jb_sw['DELAYED'] = (jb_sw['DEPARTURE_DELAY'] > 0) & (jb_sw['CANCELLED'] == False)\n",
    "pivotted = jb_sw.pivot_table(index='AIRLINE',columns='ORIGIN_AIRPORT',aggfunc='mean')\n",
    "pivotted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def prop_delayed_by_airline(jb_sw):\n",
    "    \"\"\"\n",
    "    prop_delayed_by_airline takes in a dataframe like jb_sw and returns a\n",
    "    DataFrame indexed by airline that contains the proportion of each airline's\n",
    "    flights that are delayed.\n",
    "\n",
    "    :param jb_sw: a dataframe similar to jb_sw\n",
    "    :returns: a dataframe as above\n",
    "\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'jetblue_or_sw.csv')\n",
    "    >>> jb_sw = pd.read_csv(fp, nrows=100)\n",
    "    >>> out = prop_delayed_by_airline(jb_sw)\n",
    "    >>> isinstance(out, pd.DataFrame)\n",
    "    True\n",
    "    >>> (out >= 0).all().all() and (out <= 1).all().all()\n",
    "    True\n",
    "    >>> len(out.columns) == 1\n",
    "    True\n",
    "    \"\"\"\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "    \n",
    "    codes = 'ABQ BDL BUR DCA MSY PBI PHX RNO SJC SLC'.split()\n",
    "    \n",
    "    jb_sw = jb_sw[['ORIGIN_AIRPORT','AIRLINE','DEPARTURE_DELAY','CANCELLED']]\n",
    "    jb_sw = jb_sw.query(\"\"\"ORIGIN_AIRPORT in @codes\"\"\")\n",
    "    \n",
    "    jb_sw['DELAYED'] = (jb_sw['DEPARTURE_DELAY'] > 0) & (jb_sw['CANCELLED'] == False)\n",
    "    jb_sw = jb_sw.drop(['DEPARTURE_DELAY','CANCELLED'],axis=1)\n",
    "    #pivotted = jb_sw.pivot_table(index='AIRLINE',columns='ORIGIN_AIRPORT',values='DELAYED',aggfunc='mean')\n",
    "    result = jb_sw.groupby(\"AIRLINE\").mean()['DELAYED'].to_frame()\n",
    "    \n",
    "    #return pd.DataFrame(pivotted.mean(axis=1))\n",
    "    #return pivotted\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'jetblue_or_sw.csv')\n",
    "jb_sw = pd.read_csv(fp, nrows=100)\n",
    "out = prop_delayed_by_airline(jb_sw)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "isinstance(out, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "(out >= 0).all().all() and (out <= 1).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(out.columns) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jb_sw = pd.read_csv(fp, nrows=100)\n",
    "jb_sw = jb_sw[['ORIGIN_AIRPORT','AIRLINE','DEPARTURE_DELAY','CANCELLED']]\n",
    "jb_sw['DELAYED'] = (jb_sw['DEPARTURE_DELAY'] > 0) & (jb_sw['CANCELLED'] == False)\n",
    "jb_sw = jb_sw.drop(['DEPARTURE_DELAY','CANCELLED'],axis=1)\n",
    "jb_sw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jb_sw[jb_sw['ORIGIN_AIRPORT'] == 'ABQ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jb_sw = pd.read_csv(fp, nrows=100)\n",
    "jb_sw = jb_sw[['ORIGIN_AIRPORT','AIRLINE','DEPARTURE_DELAY','CANCELLED']]\n",
    "jb_sw['DELAYED'] = (jb_sw['DEPARTURE_DELAY'] > 0) & (jb_sw['CANCELLED'] == False)\n",
    "jb_sw = jb_sw.drop(['DEPARTURE_DELAY','CANCELLED'],axis=1)\n",
    "\n",
    "totals = jb_sw.pivot_table(index='AIRLINE',columns='ORIGIN_AIRPORT',aggfunc='size')#.sum(axis=0)\n",
    "totals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jb_sw = pd.read_csv(fp, nrows=100)\n",
    "jb_sw = jb_sw[['ORIGIN_AIRPORT','AIRLINE','DEPARTURE_DELAY','CANCELLED']]\n",
    "jb_sw['DELAYED'] = (jb_sw['DEPARTURE_DELAY'] > 0) & (jb_sw['CANCELLED'] == False)\n",
    "jb_sw = jb_sw.drop(['DEPARTURE_DELAY','CANCELLED'],axis=1)\n",
    "\n",
    "delayed = jb_sw.pivot_table(index='AIRLINE',columns='ORIGIN_AIRPORT',aggfunc='sum')#.sum(axis=1)\n",
    "delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totals/delayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jb_sw = pd.read_csv(fp, nrows=100)\n",
    "jb_sw = jb_sw[['ORIGIN_AIRPORT','AIRLINE','DEPARTURE_DELAY','CANCELLED']]\n",
    "jb_sw['DELAYED'] = (jb_sw['DEPARTURE_DELAY'] > 0) & (jb_sw['CANCELLED'] == False)\n",
    "jb_sw = jb_sw.drop(['DEPARTURE_DELAY','CANCELLED'],axis=1)\n",
    "\n",
    "mean = jb_sw.pivot_table(index='AIRLINE',columns='ORIGIN_AIRPORT', values='DELAYED',aggfunc='mean')\n",
    "mean.dropna(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prop_delayed_by_airline_airport(jb_sw):\n",
    "    \"\"\"\n",
    "    prop_delayed_by_airline_airport that takes in a dataframe like jb_sw and\n",
    "    returns a DataFrame, with columns given by airports, indexed by airline,\n",
    "    that contains the proportion of each airline's flights that are delayed at\n",
    "    each airport.\n",
    "\n",
    "    :param jb_sw: a dataframe similar to jb_sw\n",
    "    :returns: a dataframe as above.\n",
    "\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'jetblue_or_sw.csv')\n",
    "    >>> jb_sw = pd.read_csv(fp, nrows=100)\n",
    "    >>> out = prop_delayed_by_airline_airport(jb_sw)\n",
    "    >>> isinstance(out, pd.DataFrame)\n",
    "    True\n",
    "    >>> ((out >= 0) | (out <= 1) | (out.isnull())).all().all()\n",
    "    True\n",
    "    >>> len(out.columns) == 6\n",
    "    True\n",
    "    \"\"\"\n",
    "    pd.options.mode.chained_assignment = None  # default='warn'\n",
    "    \n",
    "    codes = 'ABQ BDL BUR DCA MSY PBI PHX RNO SJC SLC'.split()\n",
    "    \n",
    "    jb_sw = jb_sw[['ORIGIN_AIRPORT','AIRLINE','DEPARTURE_DELAY','CANCELLED']]\n",
    "    jb_sw = jb_sw.query(\"\"\"ORIGIN_AIRPORT in @codes\"\"\")\n",
    "    \n",
    "    jb_sw['DELAYED'] = (jb_sw['DEPARTURE_DELAY'] > 0) & (jb_sw['CANCELLED'] == False)\n",
    "    jb_sw = jb_sw.drop(['DEPARTURE_DELAY','CANCELLED'],axis=1)\n",
    "\n",
    "    result = jb_sw.pivot_table(index='AIRLINE',columns='ORIGIN_AIRPORT', values='DELAYED',aggfunc='mean')\n",
    "    #result = mean#.dropna(axis=1)\n",
    "    \n",
    "    return result#.dropna()#[result['DELAY_PROP'] > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'jetblue_or_sw.csv')\n",
    "jb_sw = pd.read_csv(fp, nrows=100)\n",
    "out = prop_delayed_by_airline_airport(jb_sw)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "isinstance(out, pd.DataFrame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((out >= 0) | (out <= 1) | (out.isnull())).all().all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(out.columns) == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jb_sw_filepath = os.path.join('data', 'jetblue_or_sw.csv')\n",
    "dtype = proj.data_types()\n",
    "\n",
    "# The `usecols` keyword:\n",
    "# choose *only* the columns you need to reduce your memory footprint!\n",
    "usecols = ['ORIGIN_AIRPORT','AIRLINE','DEPARTURE_DELAY','CANCELLED']\n",
    "\n",
    "jb_sw = pd.read_csv(jb_sw_filepath, dtype=dtype, usecols=usecols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_delayed_by_airline(jb_sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prop_delayed_by_airline_airport(jb_sw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Question 9**\n",
    "\n",
    "Your work above illustrates Simpson's paradox on the specific dataset of flights originating from 10 specific airports. However, this still requires you to look at two dataframe to see if the paradox is present. Now, you will create a function that verifies Simpson's paradox in general. You will do this by writing code to compare the two dataframes, instead of inspecting them manually.\n",
    "\n",
    "Create a function `verify_simpson` that returns a boolean output regarding if the paradox is present.\n",
    "```\n",
    "verify_simpson(df, group1, group2, occur)\n",
    "```\n",
    "- df is a dataframe (e.g. jb_sw),\n",
    "- group1 is the first group being aggregated against (e.g. `AIRLINE`),\n",
    "- group2 is the second group being aggregated against (e.g. `ORIGIN_AIRPORT`),\n",
    "- occur is a column with values {0, 1}, denoting if an event occurred for that individual.\n",
    "  (e.g. \"1 if flight was delayed\" and \"0 if flight was not delayed\")\n",
    "\n",
    "`verify_simpson` should return `True` only if there is a reversal for *every* value of `group2` (e.g. for every airport).\n",
    "\n",
    "Example:\n",
    "\n",
    "Consider the following dataframe `df` with columns `treatment`, `stone_size`, and `success`:\n",
    "\n",
    "|treatment|stone_size|success|\n",
    "|---|---|---|\n",
    "|A|small|1|\n",
    "|B|small|1|\n",
    "|...|...|...|\n",
    "|A|large|0|\n",
    "|B|small|0|\n",
    "|B|small|1|\n",
    "\n",
    "`df` corresponds to the following diagram:\n",
    "<img src=\"https://miro.medium.com/max/996/1*IfVjfdGD7RPwLDC6WzT9Uw.png\" style=\"width: 300px\"/>\n",
    "\n",
    "Here, `verify_simpson(df, 'treatment', 'stone_size', 'success')` should return `True`.\n",
    "\n",
    "Verify that you function works on the previous question!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_simpson(df, group1, group2, occur):\n",
    "    \"\"\"\n",
    "    verify_simpson verifies whether a dataset displays Simpson's Paradox.\n",
    "\n",
    "    :param df: a dataframe\n",
    "    :param group1: the first group being aggregated\n",
    "    :param group2: the second group being aggregated\n",
    "    :param occur: a column of df with values {0,1}, denoting\n",
    "    if an event occurred.\n",
    "    :returns: a boolean. True if simpson's paradox is present,\n",
    "    otherwise False.\n",
    "\n",
    "    :Example:\n",
    "    >>> df = pd.DataFrame([[4,2,1], [1,2,0], [1,4,0], [4,4,1]], columns=[1,2,3])\n",
    "    >>> verify_simpson(df, 1, 2, 3) in [True, False]\n",
    "    True\n",
    "    >>> verify_simpson(df, 1, 2, 3)\n",
    "    False\n",
    "    \"\"\"\n",
    "\n",
    "    group1_values = df.groupby(group1).mean()[occur].diff().iloc[-1] < 0\n",
    "    \n",
    "    group2 = df.pivot_table(index=group1, columns=group2, aggfunc='mean',values=occur)\n",
    "    group2_values = group2.diff().iloc[-1] < 0\n",
    "    \n",
    "    if all(group2_values):\n",
    "        return group1_values != all(group2_values)\n",
    "    elif all(group2_values == False):\n",
    "        return group1_values != all(group2_values)\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame([[4,2,1], [1,2,0], [1,4,0], [4,4,1]], columns=[1,2,3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_simpson(df, 1, 2, 3) in [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "verify_simpson(df, 1, 2, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus problem (worth zero points)\n",
    "\n",
    "This question is for fun and explores a very data-science type problem: can we automate finding examples of Simpson's Paradox? This is an active area of research (see for example: https://arxiv.org/pdf/1801.04385.pdf), but is a very accessible problem. While totally optional, this question can lead to pretty interesting self-driven projects!\n",
    "\n",
    "**Question 10 (Searching for Simpson's Paradox):**\n",
    "\n",
    "As you observed from the reading in the lecture notes, Simpson's Paradox often occurs due to some confounding factor among the columns of a dataset. In the case of gender balance in student admissions to academic departments at UC Berkeley, the confounding factor was the admission rate (i.e. how hard it is to gain admission to a department).\n",
    "\n",
    "What might be a confounding factor be for flight delays among airports in question 8? Now you are going to write code to discover instances of Simpson's Paradox; that is, you will programmatically find interesting relationships present in the data.\n",
    "\n",
    "Given the dataset `jb_sw`, we'd like to find new groups of airports, as in question 8, for which the statistics of flight delays between JetBlue and Southwest satisfy Simpson's Paradox.\n",
    "\n",
    "Create a function `search_simpsons` that takes in the `jb_sw` dataset and a number `N`, and returns a list of `N` airports for which the proportion of flight delays between JetBlue and Southwest satisfies Simpson's Paradox.\n",
    "- Only consider airports that have '3 letter codes',\n",
    "- Only consider airports that have at least one JetBlue *and* Southwest flight.\n",
    "\n",
    "*Remark 1:* Iterate through groups of airports of size `N` using `itertools.combinations` until you find a group that works. Make sure your function finishes, even if it doesn't find something.\n",
    "\n",
    "*Remark 2:* You should be using your work from Question 9!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_simpsons(jb_sw, N):\n",
    "    \"\"\"\n",
    "    search_simpsons takes in the jb_sw dataset and a number N, and returns a\n",
    "    list of N airports for which the proportion of flight delays between\n",
    "    JetBlue and Southwest satisfies Simpson's Paradox.\n",
    "\n",
    "    Only consider airports that have '3 letter codes',\n",
    "    Only consider airports that have at least one JetBlue and Southwest flight.\n",
    "\n",
    "    :Example:\n",
    "    >>> fp = os.path.join('data', 'jetblue_or_sw.csv')\n",
    "    >>> jb_sw = pd.read_csv(fp, nrows=1000)\n",
    "    >>> pair = search_simpsons(jb_sw, 2)\n",
    "    >>> len(pair) == 2\n",
    "    True\n",
    "    \"\"\"\n",
    "\n",
    "    return ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fp = os.path.join('data', 'jetblue_or_sw.csv')\n",
    "jb_sw = pd.read_csv(fp, nrows=1000)\n",
    "pair = search_simpsons(jb_sw, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(pair) == 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Congratulations, you finished the project!\n",
    "\n",
    "### Before you submit:\n",
    "* Be sure you run the doctests on all your code in project02.py\n",
    "\n",
    "### To submit:\n",
    "* **Upload the .py file to gradescope**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
